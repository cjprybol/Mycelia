{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"ncbi-taxonomy\"\n",
    "DATE = \"2022-02-05\"\n",
    "DIR = \"$(homedir())/workspace/$(DATE)-$(TASK)\"\n",
    "if !isdir(DIR)\n",
    "    mkdir(DIR)\n",
    "end\n",
    "cd(DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"neo4j\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEO4J_BIN_DIR = \"/home/jupyter-cjprybol/software/neo4j-community-4.4.3/bin\"\n",
    "if !occursin(NEO4J_BIN_DIR, ENV[\"PATH\"])\n",
    "    ENV[\"PATH\"] = \"$(NEO4J_BIN_DIR):\" * ENV[\"PATH\"]\n",
    "end \n",
    "DOMAIN = \"ncbi-taxonomy.cjp.garden\"\n",
    "NODES_FILE = \"$(DIR)/ncbi_taxonomy.nodes.tsv\"\n",
    "EDGES_FILE = \"$(DIR)/ncbi_taxonomy.edges.tsv\"\n",
    "USERNAME=\"neo4j\"\n",
    "PASSWORD=readline(joinpath(homedir(), \".config\", \"neo4j\", \"ncbi-taxonomy.password.txt\"));\n",
    "ADDRESS=\"neo4j://$(DOMAIN):7687\"\n",
    "NEO4J_IMPORT_DIRECTORY=\"/var/lib/neo4j/import\"\n",
    "DATABASE = \"neo4j\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list_databases (generic function with 1 method)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function list_databases(;address, username, password)\n",
    "    cmd = \"show databases\"\n",
    "    database = \"system\"\n",
    "    cmd = cypher(;address, username, password, database, cmd)\n",
    "    return DataFrames.DataFrame(uCSV.read(open(cmd), header=1, quotes='\"', encodings=Dict(\"FALSE\" => false, \"TRUE\" => true))...)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_database (generic function with 1 method)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_database(;database, address, username, password)\n",
    "    current_databases = list_databases(;address, username, password)\n",
    "    if database in current_databases[!, \"name\"]\n",
    "        return\n",
    "    else\n",
    "        f = run\n",
    "        cmd = \"create database $(database)\"\n",
    "        # switch database to system, so that we can create the user-specific database in the system\n",
    "        database = \"system\"\n",
    "        run(cypher(;address, username, password, database, cmd, f))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cypher (generic function with 1 method)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cypher(;address, username, password, database, cmd)\n",
    "    return `cypher-shell --address $address --username $username --password $password --database $(database) --format auto $(cmd)`\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/dev/Mycelia/docs/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/dev/Mycelia/docs/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/dev/Mycelia/docs/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/dev/Mycelia/docs/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/dev/Mycelia/docs/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/dev/Mycelia/docs/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/dev/Mycelia/docs/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/dev/Mycelia/docs/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/dev/Mycelia/docs/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/dev/Mycelia/docs/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg\n",
    "pkgs = [\n",
    "    \"DataFrames\",\n",
    "    \"ProgressMeter\",\n",
    "    \"Graphs\",\n",
    "    \"MetaGraphs\",\n",
    "    \"uCSV\"\n",
    "]\n",
    "\n",
    "for pkg in pkgs\n",
    "    try\n",
    "        Pkg.add(pkg)\n",
    "    catch\n",
    "#         # tried to install an unregistered local package\n",
    "    end\n",
    "    eval(Meta.parse(\"import $pkg\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already done\n"
     ]
    }
   ],
   "source": [
    "if !((NODES_FILE in readdir(DIR, join=true)) && (EDGES_FILE in readdir(DIR, join=true)))\n",
    "    taxdump_url = \"https://ftp.ncbi.nih.gov/pub/taxonomy/taxdump.tar.gz\"\n",
    "    taxdump_local_tarball = \"$(DIR)/$(basename(taxdump_url))\"\n",
    "\n",
    "    if !isfile(taxdump_local_tarball)\n",
    "        download(taxdump_url, taxdump_local_tarball)\n",
    "    end\n",
    "\n",
    "    taxdump_out = replace(taxdump_local_tarball, \".tar.gz\" => \"\")\n",
    "    if !isdir(taxdump_out)\n",
    "        mkpath(taxdump_out)\n",
    "        run(`tar -xvzf $(taxdump_local_tarball) -C $(taxdump_out)`)\n",
    "    end\n",
    "\n",
    "    readdir(taxdump_out)\n",
    "\n",
    "#     Here we will create an in-memory dataframe to capture the contents of the names.dmp file\n",
    "\n",
    "    # Taxonomy names file (names.dmp):\n",
    "    # \ttax_id\t\t\t\t\t-- the id of node associated with this name\n",
    "    # \tname_txt\t\t\t\t-- name itself\n",
    "    # \tunique name\t\t\t\t-- the unique variant of this name if name not unique\n",
    "    # \tname class\t\t\t\t-- (synonym, common name, ...)\n",
    "\n",
    "    names_dmp = DataFrames.DataFrame(\n",
    "        tax_id = Int[],\n",
    "        name_txt = String[],\n",
    "        unique_name = String[],\n",
    "        name_class = String[]\n",
    "    )\n",
    "    ProgressMeter.@showprogress for line in split(read(open(\"$(taxdump_out)/names.dmp\"), String), \"\\t|\\n\")\n",
    "        if isempty(line)\n",
    "            continue\n",
    "        else\n",
    "            (tax_id_string, name_txt, unique_name, name_class) = split(line, \"\\t|\\t\")\n",
    "            tax_id = parse(Int, tax_id_string)\n",
    "            row = (;tax_id, name_txt, unique_name, name_class)\n",
    "            push!(names_dmp, row)\n",
    "        end\n",
    "    end\n",
    "    names_dmp\n",
    "\n",
    "#     We can see that there are sometimes multiple entries for each tax_id, the unique identifier that we will be using\n",
    "\n",
    "    unique_tax_ids = unique(names_dmp[!, \"tax_id\"])\n",
    "\n",
    "#     Here we will group the names.dmp data by tax_id, create a node in the graph for each tax_id, and sanitize and merge information appropriately\n",
    "\n",
    "    ncbi_taxonomy = MetaGraphs.MetaDiGraph(length(unique_tax_ids))\n",
    "    ProgressMeter.@showprogress for (index, group) in enumerate(collect(DataFrames.groupby(names_dmp, \"tax_id\")))\n",
    "        MetaGraphs.set_prop!(ncbi_taxonomy, index, :tax_id, group[1, \"tax_id\"])\n",
    "        for row in DataFrames.eachrow(group)\n",
    "            unique_name = isempty(row[\"unique_name\"]) ? row[\"name_txt\"] : row[\"unique_name\"]\n",
    "            # remove quotes since neo4j doesn't like them\n",
    "            unique_name = replace(unique_name, '\"' => \"\")\n",
    "            # replace spaces and dashes with underscores\n",
    "            name_class = Symbol(replace(replace(row[\"name_class\"], r\"\\s+\" => \"-\"), \"-\" => \"_\"))\n",
    "    #         name_class = Symbol(row[\"name_class\"])\n",
    "            if haskey(MetaGraphs.props(ncbi_taxonomy, index), name_class)\n",
    "                current_value = MetaGraphs.get_prop(ncbi_taxonomy, index, name_class)\n",
    "                if (current_value isa Array) && !(unique_name in current_value)\n",
    "                    new_value = [current_value..., unique_name]\n",
    "                    MetaGraphs.set_prop!(ncbi_taxonomy, index, name_class, new_value)\n",
    "                elseif !(current_value isa Array) && (current_value != unique_name)\n",
    "                    new_value = [current_value, unique_name]\n",
    "                    MetaGraphs.set_prop!(ncbi_taxonomy, index, name_class, new_value)\n",
    "                else\n",
    "                    continue\n",
    "                end\n",
    "            else\n",
    "                MetaGraphs.set_prop!(ncbi_taxonomy, index, name_class, unique_name)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "#     Here we can see that there are divisions projected onto the tree that will allow easy grouping by taxonomic \"group\"s such as primates, viruses, phages, etc.\n",
    "\n",
    "    divisions = Dict()\n",
    "    for line in split(read(open(\"$(taxdump_out)/division.dmp\"), String), \"\\t|\\n\")\n",
    "        if !isempty(line)\n",
    "            (id_string, shorthand, full_name, notes) = split(line, \"\\t|\\t\")\n",
    "            id = parse(Int, id_string)\n",
    "            divisions[id] = Dict(:division_cde => shorthand, :division_name => full_name)\n",
    "        end\n",
    "    end\n",
    "    divisions\n",
    "\n",
    "#     And finally for the data import, here we will read in the nodes.dmp file which contains lots of other metadata about each node in the NCBI taxonomic tree. We will cross-reference the division information above to add the rest of the division information. It could be helpful to make divisions their own nodes and then create relationships between taxonomic nodes and division nodes, but we'll go with the metadata in the taxonomic nodes for now\n",
    "\n",
    "    node_2_taxid_map = map(index -> ncbi_taxonomy.vprops[index][:tax_id], Graphs.vertices(ncbi_taxonomy))\n",
    "    ProgressMeter.@showprogress for line in split(read(open(\"$(taxdump_out)/nodes.dmp\"), String), \"\\t|\\n\")\n",
    "        if isempty(line)\n",
    "            continue\n",
    "        else\n",
    "            (tax_id_string, parent_tax_id_string, rank, embl_code, division_id_string) = split(line, \"\\t|\\t\")\n",
    "\n",
    "\n",
    "            division_id = parse(Int, division_id_string)\n",
    "\n",
    "            tax_id = parse(Int, tax_id_string)\n",
    "            graph_tax_ids = searchsorted(node_2_taxid_map, tax_id)\n",
    "            @assert length(graph_tax_ids) == 1\n",
    "            graph_tax_id = first(graph_tax_ids)\n",
    "\n",
    "            parent_tax_id = parse(Int, parent_tax_id_string)\n",
    "            graph_parent_tax_ids = searchsorted(node_2_taxid_map, parent_tax_id)\n",
    "            @assert length(graph_parent_tax_ids) == 1\n",
    "            graph_parent_tax_id = first(graph_parent_tax_ids)\n",
    "\n",
    "            Graphs.add_edge!(ncbi_taxonomy, graph_tax_id, graph_parent_tax_id)\n",
    "            MetaGraphs.set_prop!(ncbi_taxonomy, graph_tax_id, :rank, rank)\n",
    "            # these should probably be broken out as independent nodes!\n",
    "            MetaGraphs.set_prop!(ncbi_taxonomy, graph_tax_id, :division_id, division_id)\n",
    "            MetaGraphs.set_prop!(ncbi_taxonomy, graph_tax_id, :division_cde, divisions[division_id][:division_cde])\n",
    "            MetaGraphs.set_prop!(ncbi_taxonomy, graph_tax_id, :division_name, divisions[division_id][:division_name])\n",
    "        end\n",
    "    end\n",
    "\n",
    "#     Here we can see that there are an equal number of edges as their are nodes\n",
    "\n",
    "    Graphs.ne(ncbi_taxonomy) == Graphs.nv(ncbi_taxonomy)\n",
    "\n",
    "#     Here we'll produce a list of all of the metadata fields that are associated with our taxonomic nodes. Not every node will have all of these values, but this will allow us to write our in-memory graph to .tsv files for importing into neo4j\n",
    "\n",
    "    column_names = Set(k for vertex in Graphs.vertices(ncbi_taxonomy) for k in keys(ncbi_taxonomy.vprops[vertex]))\n",
    "    column_names = sort(collect(column_names))\n",
    "    # column_names = filter(x -> string(x) != \"in-part\", column_names)\n",
    "\n",
    "#     Here in the next 2 steps we write out .tsv files for our nodes + metadata and our edges\n",
    "\n",
    "    open(NODES_FILE, \"w\") do io\n",
    "        header = [\"node\", string.(column_names)...]\n",
    "        println(io, join(header, '\\t'))\n",
    "        ProgressMeter.@showprogress for vertex in Graphs.vertices(ncbi_taxonomy)\n",
    "            fields = String[]\n",
    "            for k in column_names\n",
    "                field = get(ncbi_taxonomy.vprops[vertex], k, \"\")\n",
    "                field = string.(field)\n",
    "                if field isa Array\n",
    "                    field = join(field, ';')\n",
    "                end\n",
    "                push!(fields, field)\n",
    "            end\n",
    "            row = [\"$(vertex)\", fields...]\n",
    "            println(io, join(row, '\\t'))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    open(EDGES_FILE, \"w\") do io\n",
    "        header = [\"src\", \"dst\"]\n",
    "        println(io, join(header, '\\t'))\n",
    "        ProgressMeter.@showprogress for edge in Graphs.edges(ncbi_taxonomy)\n",
    "            src_tax_id = ncbi_taxonomy.vprops[edge.src][:tax_id]\n",
    "            dst_tax_id = ncbi_taxonomy.vprops[edge.dst][:tax_id]\n",
    "            println(io, join(string.([src_tax_id, dst_tax_id]), \"\\t\"))\n",
    "        end\n",
    "    end\n",
    "else\n",
    "    println(\"already done\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run me in a google cloud shell attached to an account with GCE enabled\n",
    "```bash\n",
    "# gcloud config set project [PROJECT_ID]\n",
    "gcloud config set project genomics-290313\n",
    "gcloud compute firewall-rules create allow-neo4j-bolt-https --allow tcp:7473,tcp:7474,tcp:7687 --source-ranges 0.0.0.0/0 --target-tags neo4j\n",
    "# gcloud compute images list --project launcher-public | grep --extended-regexp \"neo4j-(community|enterprise)-1-4-.*\"\n",
    "# neo4j-community-1-4-3-2-gds-apoc\n",
    "gcloud compute instances create neo4j-taxonomy --image-project launcher-public --image neo4j-community-1-4-3-2-gds-apoc --tags neo4j\n",
    "# ^ should add more to this. Disk size? instance size?\n",
    "```\n",
    "\n",
    "Notes from the neo4j.conf file\n",
    "```bash\n",
    "# Paths of directories in the installation.\n",
    "dbms.directories.data=/var/lib/neo4j/data\n",
    "#dbms.directories.plugins=/var/lib/neo4j/plugins\n",
    "dbms.directories.logs=/var/lib/neo4j/logs\n",
    "dbms.directories.lib=/usr/share/neo4j/lib\n",
    "dbms.directories.run=/var/run/neo4j\n",
    "#dbms.directories.metrics=/var/lib/neo4j/metrics\n",
    "#dbms.directories.dumps.root=data/dumps\n",
    "\n",
    "# This setting constrains all `LOAD CSV` import files to be under the `import` directory. Remove or comment it out to\n",
    "# allow files to be loaded from anywhere in the filesystem; this introduces possible security problems. See the\n",
    "# `LOAD CSV` section of the manual for details.\n",
    "dbms.directories.import=/var/lib/neo4j/import\n",
    "```\n",
    "\n",
    "```bash\n",
    "# The address at which this server can be reached by its clients. This may be the server's IP address or DNS name, or\n",
    "# it may be the address of a reverse proxy which sits in front of the server. This setting may be overridden for\n",
    "# individual connectors below.\n",
    "#dbms.default_advertised_address=35.231.208.227\n",
    "dbms.default_advertised_address=ncbi-taxonomy.cjp.garden\n",
    "```\n",
    "\n",
    "have to run `sudo neo4j start` on remote machine!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>2 rows × 8 columns (omitted printing of 2 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>name</th><th> address</th><th> role</th><th> requestedStatus</th><th> currentStatus</th><th> error</th></tr><tr><th></th><th title=\"String\">String</th><th title=\"String\">String</th><th title=\"String\">String</th><th title=\"String\">String</th><th title=\"String\">String</th><th title=\"String\">String</th></tr></thead><tbody><tr><th>1</th><td>neo4j</td><td>35.231.208.227:7687</td><td>standalone</td><td>online</td><td>online</td><td></td></tr><tr><th>2</th><td>system</td><td>35.231.208.227:7687</td><td>standalone</td><td>online</td><td>online</td><td></td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& name &  address &  role &  requestedStatus &  currentStatus &  error & \\\\\n",
       "\t\\hline\n",
       "\t& String & String & String & String & String & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & neo4j & 35.231.208.227:7687 & standalone & online & online &  & $\\dots$ \\\\\n",
       "\t2 & system & 35.231.208.227:7687 & standalone & online & online &  & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m2×8 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m name   \u001b[0m\u001b[1m  address            \u001b[0m\u001b[1m  role      \u001b[0m\u001b[1m  requestedStatus \u001b[0m\u001b[1m  currentStat\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String \u001b[0m\u001b[90m String              \u001b[0m\u001b[90m String     \u001b[0m\u001b[90m String           \u001b[0m\u001b[90m String      \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ neo4j   35.231.208.227:7687  standalone  online            online       ⋯\n",
       "   2 │ system  35.231.208.227:7687  standalone  online            online\n",
       "\u001b[36m                                                               4 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_databases(address = ADDRESS, username = USERNAME, password = PASSWORD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see a list of databases that we already have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neo4j database name that we will use for this ncbi taxonomic tree is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create the database if it doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_database(address = ADDRESS, username = USERNAME, password = PASSWORD, database = DATABASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will set constrains that no two nodes have the same taxonomic id and no two nodes have the same scientific name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll import some helpful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.023436 seconds (229 allocations: 15.594 KiB, 98.37% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mcypher-shell\u001b[24m \u001b[4m--address\u001b[24m \u001b[4mneo4j://ncbi-taxonomy.cjp.garden:7687\u001b[24m \u001b[4m--username\u001b[24m \u001b[4mneo4j\u001b[24m \u001b[4m--password\u001b[24m \u001b[4mtempo-athlete-news-info-fresh-4482\u001b[24m \u001b[4m--database\u001b[24m \u001b[4mneo4j\u001b[24m \u001b[4m--format\u001b[24m \u001b[4mauto\u001b[24m \u001b[4m'CREATE CONSTRAINT ON (t:Taxonomy) ASSERT t.tax_id IS UNIQUE'\u001b[24m`, ProcessRunning)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An equivalent constraint already exists, 'Constraint( id=4, name='constraint_53f0c26a', type='UNIQUENESS', schema=(:Taxonomy {tax_id}), ownedIndex=3 )'.\n"
     ]
    }
   ],
   "source": [
    "cmd = \"CREATE CONSTRAINT ON (t:Taxonomy) ASSERT t.tax_id IS UNIQUE\"\n",
    "@time cypher(address = ADDRESS, username = USERNAME, password = PASSWORD, database = DATABASE, cmd = cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000368 seconds (92 allocations: 6.516 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mcypher-shell\u001b[24m \u001b[4m--address\u001b[24m \u001b[4mneo4j://ncbi-taxonomy.cjp.garden:7687\u001b[24m \u001b[4m--username\u001b[24m \u001b[4mneo4j\u001b[24m \u001b[4m--password\u001b[24m \u001b[4mtempo-athlete-news-info-fresh-4482\u001b[24m \u001b[4m--database\u001b[24m \u001b[4mneo4j\u001b[24m \u001b[4m--format\u001b[24m \u001b[4mauto\u001b[24m \u001b[4m'CREATE CONSTRAINT ON (t:Taxonomy) ASSERT t.\\`scientific name\\` IS UNIQUE'\u001b[24m`, ProcessRunning)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An equivalent constraint already exists, 'Constraint( id=6, name='constraint_f16727de', type='UNIQUENESS', schema=(:Taxonomy {scientific name}), ownedIndex=5 )'.\n"
     ]
    }
   ],
   "source": [
    "cmd = \"CREATE CONSTRAINT ON (t:Taxonomy) ASSERT t.`scientific name` IS UNIQUE\"\n",
    "@time cypher(address = ADDRESS, username = USERNAME, password = PASSWORD, database = DATABASE, cmd = cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will create the nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://linuxize.com/post/how-to-use-scp-command-to-securely-transfer-files/\n",
    "https://linuxize.com/post/how-to-setup-passwordless-ssh-login/\n",
    "\n",
    "run me on remote neo4j server\n",
    "```bash\n",
    "ssh-keygen -t rsa -b 4096 -C \"cameron.prybol@gmail.com\"\n",
    "```\n",
    "add the .pub keys from each machine to the `~/.ssh/authorized_keys` on the other machine\n",
    "\n",
    "on neo4j machine, use sudo to make an symlink between `/var/lib/neo4j/import` and `neo4j-import`\n",
    "\n",
    "```bash\n",
    "mkdir -p neo4j-import\n",
    "sudo ln -s /var/lib/neo4j/import neo4j-import\n",
    "```\n",
    "\n",
    "sudo chmod 777 /var/lib/neo4j/import/\n",
    "\n",
    "scp ncbi_taxonomy.* cameron_prybol@ncbi-taxonomy.cjp.garden:/var/lib/neo4j/import\n",
    "\n",
    "scp ncbi_taxonomy.edges.tsv cameron_prybol@ncbi-taxonomy.cjp.garden:/var/lib/neo4j/import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mscp\u001b[24m \u001b[4m/home/jupyter-cjprybol/workspace/2022-02-05-ncbi-taxonomy/ncbi_taxonomy.nodes.tsv\u001b[24m \u001b[4mcameron_prybol@ncbi-taxonomy.cjp.garden:/var/lib/neo4j/import\u001b[24m`, ProcessExited(0))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(`scp $NODES_FILE cameron_prybol@$(DOMAIN):$(NEO4J_IMPORT_DIRECTORY)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mscp\u001b[24m \u001b[4m/home/jupyter-cjprybol/workspace/2022-02-05-ncbi-taxonomy/ncbi_taxonomy.edges.tsv\u001b[24m \u001b[4mcameron_prybol@ncbi-taxonomy.cjp.garden:/var/lib/neo4j/import\u001b[24m`, ProcessExited(0))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(`scp $EDGES_FILE cameron_prybol@$(DOMAIN):$(NEO4J_IMPORT_DIRECTORY)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000518 seconds (94 allocations: 6.938 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Process(`\u001b[4mcypher-shell\u001b[24m \u001b[4m--address\u001b[24m \u001b[4mneo4j://ncbi-taxonomy.cjp.garden:7687\u001b[24m \u001b[4m--username\u001b[24m \u001b[4mneo4j\u001b[24m \u001b[4m--password\u001b[24m \u001b[4mtempo-athlete-news-info-fresh-4482\u001b[24m \u001b[4m--database\u001b[24m \u001b[4mneo4j\u001b[24m \u001b[4m--format\u001b[24m \u001b[4mauto\u001b[24m \u001b[4m\"USING PERIODIC COMMIT LOAD CSV WITH HEADERS FROM 'file:///ncbi_taxonomy.nodes.tsv' AS row FIELDTERMINATOR '\t' MERGE (t:Taxonomy {tax_id: row.tax_id})\"\u001b[24m`, ProcessRunning)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = \n",
    "\"\"\"\n",
    "USING PERIODIC COMMIT\n",
    "LOAD CSV WITH HEADERS FROM\n",
    "'file:///$(basename(NODES_FILE))' AS row\n",
    "FIELDTERMINATOR '\\t'\n",
    "MERGE (t:Taxonomy {tax_id: row.tax_id})\n",
    "\"\"\"\n",
    "cmd = rstrip(replace(cmd, '\\n' => ' '))\n",
    "@time cypher(address = ADDRESS, username = USERNAME, password = PASSWORD, database = DATABASE, cmd = cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these both work for running locally\n",
    "#cypher-shell --address neo4j://10.142.0.13:7687 --username neo4j --password tempo-athlete-news-info-fresh-4482 --database neo4j --format auto \"USING PERIODIC COMMIT LOAD CSV WITH HEADERS FROM 'file:///ncbi_taxonomy.nodes.tsv' AS row FIELDTERMINATOR '\\t' MERGE (t:Taxonomy {tax_id: row.tax_id})\"\n",
    "#cypher-shell --address neo4j://0.0.0.0:7687 --username neo4j --password tempo-athlete-news-info-fresh-4482 --database neo4j --format auto \"USING PERIODIC COMMIT LOAD CSV WITH HEADERS FROM 'file:///ncbi_taxonomy.nodes.tsv' AS row FIELDTERMINATOR '\\t' MERGE (t:Taxonomy {tax_id: row.tax_id})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following commands, we will add metadata to the nodes in a piece-meal (column by column) fashion that will allow us to skip over null fields. Storing null pointers in Neo4j is discouraged (impossible?) and we will get errors if we try and set metadata properties to null values.\n",
    "\n",
    "I tried to do this all in one command on the initial import by handling all of the nulls using the technique in [this post](https://markhneedham.com/blog/2014/08/22/neo4j-load-csv-handling-empty-columns/) but I kept getting Java errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not enough memory to perform the current task. Please try increasing 'dbms.memory.heap.max_size' in the neo4j configuration (normally in 'conf/neo4j.conf' or, if you are using Neo4j Desktop, found through the user interface) or if you are running an embedded installation increase the heap by using '-Xmx' command line flag, and then restart the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS FROM\n",
      "'file:///ncbi_taxonomy.nodes.tsv' AS row\n",
      "FIELDTERMINATOR '\\t'\n",
      "CREATE (t:Taxonomy {\n",
      "    tax_id: row.tax_id,\n",
      "    scientific_name: row.scientific_name,\n",
      "    division_cde: row.division_cde,\n",
      "    division_id: row.division_id,\n",
      "    division_name: row.division_name,\n",
      "    rank: row.rank,\n",
      "    acronym: row.acronym,\n",
      "    in_part: row.in_part,\n",
      "    includes: row.includes,\n",
      "    common_name: row.common_name,\n",
      "    genbank_common_name: row.genbank_common_name,\n",
      "    blast_name: row.blast_name,\n",
      "    synonym: row.synonym,\n",
      "    genbank_synonym: row.genbank_synonym,\n",
      "    type_material: row.type_material,\n",
      "    authority: row.authority,\n",
      "    genbank_acronym: row.genbank_acronym,\n",
      "    equivalent_name: row.equivalent_name})\n",
      "RETURN t LIMIT 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "`\u001b[4mcypher-shell\u001b[24m \u001b[4m--address\u001b[24m \u001b[4mneo4j://0.0.0.0:7687\u001b[24m \u001b[4m--username\u001b[24m \u001b[4mneo4j\u001b[24m \u001b[4m--password\u001b[24m \u001b[4mtempo-athlete-news-info-fresh-4482\u001b[24m \u001b[4m--database\u001b[24m \u001b[4mneo4j\u001b[24m \u001b[4m--format\u001b[24m \u001b[4mauto\u001b[24m \u001b[4m\"USING PERIODIC COMMIT LOAD CSV WITH HEADERS FROM 'file:///ncbi_taxonomy.nodes.tsv' AS row FIELDTERMINATOR '\\t' CREATE (t:Taxonomy {     tax_id: row.tax_id,     scientific_name: row.scientific_name,     division_cde: row.division_cde,     division_id: row.division_id,     division_name: row.division_name,     rank: row.rank,     acronym: row.acronym,     in_part: row.in_part,     includes: row.includes,     common_name: row.common_name,     genbank_common_name: row.genbank_common_name,     blast_name: row.blast_name,     synonym: row.synonym,     genbank_synonym: row.genbank_synonym,     type_material: row.type_material,     authority: row.authority,     genbank_acronym: row.genbank_acronym,     equivalent_name: row.equivalent_name}) RETURN t LIMIT 10\"\u001b[24m`"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note to self, I should be able to programmatically generate this long list of metadata fields\n",
    "\n",
    "# need to start over?\n",
    "# match (n) delete n\n",
    "\n",
    "# need to develop little by little over time?\n",
    "# WITH row LIMIT 10\n",
    "\n",
    "cmd = \n",
    "\"\"\"\n",
    "USING PERIODIC COMMIT\n",
    "LOAD CSV WITH HEADERS FROM\n",
    "'file:///$(basename(NODES_FILE))' AS row\n",
    "FIELDTERMINATOR '\\\\t'\n",
    "CREATE (t:Taxonomy {\n",
    "    tax_id: row.tax_id,\n",
    "    scientific_name: row.scientific_name,\n",
    "    division_cde: row.division_cde,\n",
    "    division_id: row.division_id,\n",
    "    division_name: row.division_name,\n",
    "    rank: row.rank,\n",
    "    acronym: row.acronym,\n",
    "    in_part: row.in_part,\n",
    "    includes: row.includes,\n",
    "    common_name: row.common_name,\n",
    "    genbank_common_name: row.genbank_common_name,\n",
    "    blast_name: row.blast_name,\n",
    "    synonym: row.synonym,\n",
    "    genbank_synonym: row.genbank_synonym,\n",
    "    type_material: row.type_material,\n",
    "    authority: row.authority,\n",
    "    genbank_acronym: row.genbank_acronym,\n",
    "    equivalent_name: row.equivalent_name})\n",
    "RETURN t LIMIT 10\n",
    "\"\"\"\n",
    "println(cmd)\n",
    "cmd = rstrip(replace(cmd, '\\n' => ' '))\n",
    "cyper_cmd = cypher(address = \"neo4j://0.0.0.0:7687\", username = USERNAME, password = PASSWORD, database = DATABASE, cmd = cmd)\n",
    "\n",
    "# ready to start consuming query after 61 ms, results consumed after another 86607 ms\n",
    "# Added 2396777 nodes, Set 15244183 properties, Added 2396777 labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here in the final step we create the relationships between taxa and their parent nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS FROM\n",
      "'file:///ncbi_taxonomy.edges.tsv' AS row\n",
      "FIELDTERMINATOR '\\t'\n",
      "MATCH (src:Taxonomy {tax_id: row.src})\n",
      "MATCH (dst:Taxonomy {tax_id: row.dst})\n",
      "MERGE (src)-[p:PARENT]->(dst)\n",
      "\n",
      "  0.000049 seconds (58 allocations: 5.234 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "`\u001b[4mcypher-shell\u001b[24m \u001b[4m--address\u001b[24m \u001b[4mneo4j://0.0.0.0:7687\u001b[24m \u001b[4m--username\u001b[24m \u001b[4mneo4j\u001b[24m \u001b[4m--password\u001b[24m \u001b[4mtempo-athlete-news-info-fresh-4482\u001b[24m \u001b[4m--database\u001b[24m \u001b[4mneo4j\u001b[24m \u001b[4m--format\u001b[24m \u001b[4mauto\u001b[24m \u001b[4m\"USING PERIODIC COMMIT LOAD CSV WITH HEADERS FROM 'file:///ncbi_taxonomy.edges.tsv' AS row FIELDTERMINATOR '\\t' MATCH (src:Taxonomy {tax_id: row.src}) MATCH (dst:Taxonomy {tax_id: row.dst}) MERGE (src)-[p:PARENT]->(dst)\"\u001b[24m`"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to obtain connection towards WRITE server. Known routing table is: Ttl 1644089305934, currentTime 1644089035978, routers [], writers [], readers [], database 'neo4j'\n",
      "Failed to obtain connection towards WRITE server. Known routing table is: Ttl 1644089316828, currentTime 1644089046883, routers [], writers [], readers [], database 'neo4j'\n",
      "Failed to obtain connection towards WRITE server. Known routing table is: Ttl 1644089334913, currentTime 1644089089649, routers [], writers [], readers [], database 'neo4j'\n",
      "Failed to obtain connection towards WRITE server. Known routing table is: Ttl 1644089382426, currentTime 1644089125683, routers [], writers [], readers [], database 'neo4j'\n",
      "Failed to obtain connection towards WRITE server. Known routing table is: Ttl 1644089486990, currentTime 1644089217065, routers [], writers [], readers [], database 'neo4j'\n"
     ]
    }
   ],
   "source": [
    "cmd = \n",
    "\"\"\"\n",
    "USING PERIODIC COMMIT\n",
    "LOAD CSV WITH HEADERS FROM\n",
    "'file:///$(basename(EDGES_FILE))' AS row\n",
    "FIELDTERMINATOR '\\\\t'\n",
    "MATCH (src:Taxonomy {tax_id: row.src})\n",
    "MATCH (dst:Taxonomy {tax_id: row.dst})\n",
    "MERGE (src)-[p:PARENT]->(dst)\n",
    "\"\"\"\n",
    "println(cmd)\n",
    "cmd = rstrip(replace(cmd, '\\n' => ' '))\n",
    "cypher(address = \"neo4j://0.0.0.0:7687\", username = USERNAME, password = PASSWORD, database = DATABASE, cmd = cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ready to start consuming query after 99517 ms, results consumed after another 0 ms\n",
    "# Created 2396777 relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that is it! We've just rebuilt the NCBI taxonomy in neo4j to allow us to do downstream work in a taxonomy-aware way"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
