#!/bin/bash
# TEMPLATE_ID=slurm/nersc/gpu_regular_1gpu_1task.sbatch
# Generated by Mycelia JobSpec template renderer.
# Site profile: nersc
#SBATCH --job-name=fixture-nersc
#SBATCH --mail-user=user@example.org
#SBATCH --mail-type=END,FAIL
#SBATCH --error=/Users/cameronprybol/workspace/slurmlogs/%j.%x.err
#SBATCH --output=/Users/cameronprybol/workspace/slurmlogs/%j.%x.out
#SBATCH --qos=regular
#SBATCH --account=m1234_g
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --time=04:00:00
#SBATCH --cpus-per-task=16
#SBATCH --mem=64G
#SBATCH --constraint=gpu
#SBATCH --gpus-per-node=1

set -euo pipefail

# No module or environment setup requested

JOB_CMD='python train.py --epochs 1'
bash -lc "$JOB_CMD"

# Monitoring hints:
#   squeue -u $USER
#   scontrol show job <jobid>
#   sacct -j <jobid> --format=JobID,JobName,AllocCPUS,Elapsed,State,ExitCode,MaxRSS
#   sstat -j <jobid>.batch --format=JobID,MaxRSS,MaxVMSize,AvgCPU
#   seff <jobid>  # if seff is available
#   nvidia-smi
#   nvidia-smi topo -m  # optional topology check
# NERSC note: use --gpu-bind=none when all tasks should see all GPUs
