{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f670684-0b08-4679-b2bd-f5851ec0d2d8",
   "metadata": {},
   "source": [
    "The objective of this notebook is to:\n",
    "- join all of the kraken results with the sample metadata\n",
    "- subset to samples with metadata\n",
    "- collapse P3+ into Other\n",
    "- do PCA, coloring by metadata\n",
    "- do GLM modelling to determine if any have significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28afd0da-a1e3-48ad-a12a-8bbb3a8d19c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# don't try and install plotting libraries without this\n",
    "# can set in ~/.local/share/jupyter/kernels/\n",
    "@assert ENV[\"LD_LIBRARY_PATH\"] == \"\"\n",
    "import Pkg\n",
    "pkgs = [\n",
    "    \"Revise\",\n",
    "    \"DataFrames\",\n",
    "    \"StatsBase\",\n",
    "    \"StatsPlots\",\n",
    "    \"uCSV\",\n",
    "    \"ProgressMeter\",\n",
    "    \"Distances\",\n",
    "    \"Clustering\",\n",
    "    \"Colors\",\n",
    "    \"MultivariateStats\",\n",
    "    \"Dates\",\n",
    "    \"CategoricalArrays\",\n",
    "    \"GLM\",\n",
    "    \"Statistics\",\n",
    "    \"DelimitedFiles\",\n",
    "    \"PlotlyJS\"\n",
    "]\n",
    "# Pkg.add(pkgs)\n",
    "for pkg in pkgs\n",
    "    eval(Meta.parse(\"import $pkg\"))\n",
    "end\n",
    "import Mycelia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc54d53-21ec-4098-b1c9-8c8e67d4193a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = joinpath(dirname(pwd()), \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c29934-2fb9-44fb-968e-1cf5a8c907ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dir = joinpath(data_dir, \"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d349c0-1a92-4233-8ef5-a27b6b6af185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in metadata\n",
    "metadata_dir = joinpath(dirname(pwd()), \"metadata\")\n",
    "\n",
    "exposome_environmental_data = DataFrames.DataFrame(uCSV.read(\n",
    "    joinpath(metadata_dir, \"metadata_exposome.rds.tsv\"),\n",
    "    delim='\\t',\n",
    "    header=1,\n",
    "    typedetectrows=300\n",
    "))\n",
    "\n",
    "joint_sample_metadata = DataFrames.DataFrame(uCSV.read(\n",
    "    joinpath(metadata_dir, \"exposome/joint_sample_metadata.tsv\"),\n",
    "    delim='\\t',\n",
    "    header=1,\n",
    "    typedetectrows=300\n",
    "))\n",
    "\n",
    "@assert joint_sample_metadata[!, \"Library Name\"] == joint_sample_metadata[!, \"LibraryName\"]\n",
    "joint_metadata = DataFrames.innerjoin(\n",
    "    joint_sample_metadata,\n",
    "    exposome_environmental_data,\n",
    "    on=\"Library Name\" => \"samplenames\");\n",
    "\n",
    "\n",
    "# # recode P3 and beyond to Other, since they don't have enough samples to do much analysis on\n",
    "# joint_metadata[!, \"aownership\"] = map(x -> x in Set([\"P1\", \"P2\"]) ? x : \"Others\", joint_metadata[!, \"aownership\"])\n",
    "\n",
    "joint_metadata[!, \"date.start\"] = Dates.Date.(joint_metadata[!, \"date.start\"], \"yyyy-mm-dd\")\n",
    "joint_metadata[!, \"date.end\"] = Dates.Date.(joint_metadata[!, \"date.end\"], \"yyyy-mm-dd\")\n",
    "# use this if we want to unified axis across all participants, which I don't think we do\n",
    "# joint_metadata[!, \"date.start_relative\"] = joint_metadata[!, \"date.start\"] .- first(joint_metadata[!, \"date.start\"])\n",
    "# joint_metadata[!, \"date.end_relative\"] = joint_metadata[!, \"date.end\"] .- first(joint_metadata[!, \"date.start\"])\n",
    "joint_metadata[!, \"duration\"] = joint_metadata[!, \"date.end\"] .- joint_metadata[!, \"date.start\"]\n",
    "\n",
    "joint_metadata[!, \"temperature\"] = something.(tryparse.(Float64, joint_metadata[!, \"temperature\"]), missing)\n",
    "joint_metadata[!, \"humid\"] = something.(tryparse.(Float64, joint_metadata[!, \"humid\"]), missing)\n",
    "joint_metadata[!, \"particle\"] = something.(tryparse.(Float64, joint_metadata[!, \"particle\"]), missing)\n",
    "joint_metadata[!, \"latitude\"] = something.(tryparse.(Float64, joint_metadata[!, \"latitude\"]), missing)\n",
    "joint_metadata[!, \"longitude\"] = something.(tryparse.(Float64, joint_metadata[!, \"longitude\"]), missing)\n",
    "\n",
    "joint_metadata = DataFrames.dropmissing(joint_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cbe00-1abc-4289-a05a-3c7f3b62225e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_paths = sort(joinpath.(data_dir, \"SRA\", joint_metadata[!, \"Run\"]))\n",
    "kraken_db = \"k2_pluspfp\"\n",
    "kraken_db_regex = Regex(\"$(kraken_db)_\\\\d{8}\")\n",
    "kraken_reports = map(path ->\n",
    "    first(filter(x -> occursin(kraken_db_regex, x) && occursin(r\"kraken-report\\.tsv$\", x), readdir(joinpath(path, \"kraken\"), join=true))),\n",
    "    sample_paths)\n",
    "\n",
    "# create a full joint table so that we can subset dynamically down below without needing to re-read all of them over and over again\n",
    "joint_report_table = DataFrames.DataFrame()\n",
    "ProgressMeter.@showprogress for kraken_report in kraken_reports\n",
    "    report_table = Mycelia.read_kraken_report(kraken_report)\n",
    "    report_table[!, \"report\"] .= basename(kraken_report)\n",
    "    append!(joint_report_table, report_table)\n",
    "end\n",
    "joint_report_table[!, \"taxon\"] = map(row -> string(row[\"ncbi_taxonid\"]) * \"_\" * row[\"scientific_name\"], DataFrames.eachrow(joint_report_table))\n",
    "joint_report_table[!, \"sample_identifier\"] = string.(first.(split.(joint_report_table[!, \"report\"], '.')))\n",
    "joint_report_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b607ee4f-7cf7-499e-866b-6d771b9358ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StatsPlots.plotlyjs()\n",
    "#default\n",
    "# StatsPlots.gr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9220d5a8-5e29-4f68-bc85-9c5f767c7932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxon_levels = Mycelia.list_ranks()\n",
    "viral_tax_ids = Mycelia.list_subtaxa(10239)\n",
    "\n",
    "for rank_level in 3:8\n",
    "\n",
    "    (taxon_index, taxon_level) = collect(enumerate(taxon_levels))[rank_level]\n",
    "    println(\"$(taxon_index) - $(taxon_level)\")\n",
    "    rank_table = Mycelia.list_rank(taxon_level)\n",
    "\n",
    "    # filter the kraken results to only those at this level\n",
    "    taxids_at_this_rank = Set(rank_table[!, \"taxid\"])\n",
    "    rank_report_table = joint_report_table[map(x -> x in taxids_at_this_rank, joint_report_table[!, \"ncbi_taxonid\"]), :]\n",
    "    rank_joint_table = DataFrames.innerjoin(joint_metadata, rank_report_table, on=\"Run\" => \"sample_identifier\")\n",
    "    # find all columns with invariant metadata, and drop them\n",
    "    rank_joint_table = rank_joint_table[!, [n for n in names(rank_joint_table) if length(unique(rank_joint_table[!, n])) > 1]]\n",
    "\n",
    "    # println(\"[\")\n",
    "    # for n in names(rank_joint_table)\n",
    "    #     println(\"\\t\\\"$(n)\\\",\")\n",
    "    # end\n",
    "    # println(\"]\")\n",
    "\n",
    "    columns_of_interest = [\n",
    "        \"Run\",\n",
    "        \"altitude\",\n",
    "        \"geo_loc_name\",\n",
    "        \"location\",\n",
    "        \"geo\",\n",
    "        \"geo2\",\n",
    "        \"duration\",\n",
    "        \"date.month\",\n",
    "        \"season\",\n",
    "        \"particle\",\n",
    "        \"temperature\",\n",
    "        \"humid\",\n",
    "        \"weekend\",\n",
    "        \"aownership\",\n",
    "        \"latitude\",\n",
    "        \"longitude\",\n",
    "        \"ncbi_taxonid\",\n",
    "        \"scientific_name\",\n",
    "        \"taxon\",\n",
    "        \"number_of_fragments_at_or_below_taxon\",\n",
    "    ]\n",
    "\n",
    "    rank_joint_table = rank_joint_table[!, columns_of_interest]\n",
    "\n",
    "    # viral only\n",
    "    rank_joint_viral_table = rank_joint_table[map(x -> x in viral_tax_ids, rank_joint_table[!, \"ncbi_taxonid\"]), :]\n",
    "    # require at least 3 reads of support\n",
    "    rank_joint_viral_table = rank_joint_viral_table[rank_joint_viral_table[!, \"number_of_fragments_at_or_below_taxon\"] .>= 3, :]\n",
    "\n",
    "    unique_samples = unique(sort(rank_joint_viral_table[!, \"Run\"]))\n",
    "    unique_taxa = unique(sort(rank_joint_viral_table[!, \"taxon\"]))\n",
    "    sample2index = Dict(s => i for (i, s) in enumerate(unique_samples))\n",
    "    taxa2index = Dict(t => i for (i, t) in enumerate(unique_taxa))\n",
    "    counts_matrix = zeros(length(unique_taxa), length(unique_samples))\n",
    "\n",
    "    for row in DataFrames.eachrow(rank_joint_viral_table)\n",
    "        x = taxa2index[row[\"taxon\"]]\n",
    "        y = sample2index[row[\"Run\"]]\n",
    "        counts_matrix[x, y] = row[\"number_of_fragments_at_or_below_taxon\"]\n",
    "    end\n",
    "    counts_matrix\n",
    "    relative_abundance_matrix = zeros(length(unique_taxa), length(unique_samples))\n",
    "    for (i, col) in enumerate(eachcol(counts_matrix))\n",
    "        relative_abundance_matrix[:, i] .= counts_matrix[:, i] ./ sum(counts_matrix[:, i])\n",
    "    end\n",
    "    relative_abundance_matrix\n",
    "\n",
    "    fit_pca = MultivariateStats.fit(MultivariateStats.PCA, relative_abundance_matrix)\n",
    "    transformed_observations = MultivariateStats.predict(fit_pca, relative_abundance_matrix)\n",
    "\n",
    "    rank_joint_viral_table = DataFrames.rename(rank_joint_viral_table, \n",
    "        [\n",
    "            \"geo_loc_name\" => \"geo_location\",\n",
    "            \"geo2\" => \"region\",\n",
    "            \"date.month\" => \"month(1-12)\",\n",
    "            \"aownership\" => \"participant\"\n",
    "        ]\n",
    "\n",
    "    )\n",
    "\n",
    "    feature_columns = [\n",
    "        # \"geo_location\",\n",
    "        # \"location\",\n",
    "        \"region\",\n",
    "        # \"month(1-12)\",\n",
    "        \"season\",\n",
    "        # \"weekend\",\n",
    "        \"participant\"\n",
    "    ]\n",
    "\n",
    "    for feature in feature_columns\n",
    "        sample2feature_table = sort(unique(rank_joint_viral_table[!, [\"Run\", feature]]))\n",
    "\n",
    "        unique_features = sort(unique(rank_joint_viral_table[!, feature]))\n",
    "        colorscheme = Colors.distinguishable_colors(length(unique_features), [Colors.RGB(1,1,1), Colors.RGB(0,0,0)], dropseed=true)\n",
    "        feature2index = Dict(f => i for (i, f) in enumerate(unique_features))\n",
    "\n",
    "        xs = [Float64[] for i in 1:length(unique_features)]\n",
    "        ys = [Float64[] for i in 1:length(unique_features)]\n",
    "        zs = [Float64[] for i in 1:length(unique_features)]\n",
    "\n",
    "        for (i, row) in enumerate(DataFrames.eachrow(sample2feature_table))\n",
    "            feature_index = feature2index[row[feature]]\n",
    "            sample_index = sample2index[row[\"Run\"]]\n",
    "            push!(xs[feature_index], transformed_observations[1, i])\n",
    "            push!(ys[feature_index], transformed_observations[2, i])\n",
    "            push!(zs[feature_index], transformed_observations[3, i])\n",
    "        end\n",
    "\n",
    "        plot = \n",
    "        StatsPlots.scatter(\n",
    "            xs,\n",
    "            ys,\n",
    "            # zs,\n",
    "            xlabel = \"PC1\",\n",
    "            ylabel = \"PC2\",\n",
    "            # zlabel = \"PC3\",\n",
    "            labels = hcat(unique_features...),\n",
    "            title = \"Viral abundance profiles - kraken - $(kraken_db) - $(taxon_level) - $(feature)\",\n",
    "            # legend = :outertopright,\n",
    "            size = (1920/2, 1080/2),\n",
    "            margins = 10StatsPlots.px,\n",
    "            seriescolor = hcat(colorscheme...),\n",
    "            # alpha=0.5,\n",
    "            # size=1,\n",
    "            markersize=3,\n",
    "            dpi=300\n",
    "        )\n",
    "\n",
    "        display(plot)\n",
    "        for extension in [\".png\"]\n",
    "            file = joinpath(results_dir, \"taxonomic-breakdowns.kraken.$(kraken_db).$(taxon_index).$(taxon_level).$(feature).2d.pca\") * extension\n",
    "            StatsPlots.savefig(plot, file)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.7",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
