{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28afd0da-a1e3-48ad-a12a-8bbb3a8d19c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\".\")\n",
    "# Pkg.add(\"Revise\")\n",
    "# import Revise\n",
    "\n",
    "# Pkg.develop(path=\"../../..\")\n",
    "# import Mycelia\n",
    "\n",
    "pkgs = [\n",
    "\"DataFrames\",\n",
    "\"uCSV\",\n",
    "\"ProgressMeter\",\n",
    "]\n",
    "Pkg.add(pkgs)\n",
    "for pkg in pkgs\n",
    "    eval(Meta.parse(\"import $pkg\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc54d53-21ec-4098-b1c9-8c8e67d4193a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = joinpath(dirname(pwd()), \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9282e23-ea48-4be0-8acb-67d044e0ca48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SRR_paths = filter(x -> !occursin(\".ipynb_checkpoints\", x), readdir(joinpath(data_dir, \"SRA\"), join=true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57aa1ac-b661-45e3-95c9-da7d2426d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function parse_mmseqs_easy_taxonomy_lca_tsv(lca_tsv)\n",
    "    data, header = uCSV.read(lca_tsv, delim='\\t')\n",
    "    # contig\n",
    "    # (1) a single taxonomy numeric identifier\n",
    "    # (2) a taxonomic rank column\n",
    "    # (3) taxonomic name column\n",
    "    # fragments retained\n",
    "    # fragments taxonomically assigned\n",
    "    # fragments in agreement with the contig label (i.e. same taxid or have it as an ancestor)\n",
    "    # the support received -log(E-value)\n",
    "    header = [\n",
    "        \"contig_id\",\n",
    "        \"taxon_id\",\n",
    "        \"taxon_rank\",\n",
    "        \"taxon_name\",\n",
    "        \"fragments_retained\",\n",
    "        \"fragments_taxonomically_assigned\",\n",
    "        \"fragments_in_agreement_with_assignment\",\n",
    "        \"support -log(E-value)\"\n",
    "    ]\n",
    "    table = DataFrames.DataFrame(data, header)\n",
    "    table[!, \"contig_id\"] = string.(table[!, \"contig_id\"])\n",
    "    return table\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9ab21-7882-4173-b234-f64c2341fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "function parse_qualimap_contig_coverage(qualimap_report_txt)\n",
    "    coverage_line_regex = r\"\\t.*?\\t\\d+\\t\\d+\\t[\\d\\.]+\\t[\\d\\.]+$\"\n",
    "    lines = filter(x -> occursin(coverage_line_regex, x), readlines(\"$(qualimap_report_txt)\"))\n",
    "    io = IOBuffer(join(map(x -> join(split(x, '\\t')[2:end], '\\t'), lines), '\\n'))\n",
    "    header = [\"Contig\", \"Length\", \"Mapped bases\", \"Mean coverage\", \"Standard Deviation\"]\n",
    "    types = [String, Int, Int, Float64, Float64]\n",
    "    data, _ = uCSV.read(io, delim='\\t', types=types)\n",
    "    qualimap_results = DataFrames.DataFrame(data, header)\n",
    "    qualimap_results[!, \"% Mapped bases\"] = qualimap_results[!, \"Mapped bases\"] ./ sum(qualimap_results[!, \"Mapped bases\"]) .* 100\n",
    "    return qualimap_results\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b225c1a6-9a0f-4690-b2b2-19d01024b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function parse_blast_report(blast_report)\n",
    "#     # example header line \n",
    "#     # \"# Fields: query id, subject id, subject acc., subject acc.ver, subject title, query length, subject length, q. start, q. end, s. start, s. end, evalue, bit score, score, alignment length, % identity, identical, mismatches, subject tax id\"\n",
    "#     header_lines = collect(Iterators.filter(x -> occursin(r\"# Fields:\", x), eachline(blast_report)))\n",
    "#     if isempty(header_lines)\n",
    "#         @info \"no hits found, returning empty table\"\n",
    "#         return DataFrames.DataFrame()\n",
    "#     end\n",
    "#     header_line = first(header_lines)\n",
    "#     header = split(last(split(header_line, \": \")), \", \")\n",
    "#     blast_col_types = Dict(\n",
    "#         \"query id\" => String,\n",
    "#         \"query title\" => String,\n",
    "#         \"subject id\" => String,\n",
    "#         \"subject gi\" => String,\n",
    "#         \"subject acc.\" => String,\n",
    "#         \"subject acc.ver\" => String,\n",
    "#         \"subject title\" => String,\n",
    "#         \"query length\" => Int,\n",
    "#         \"subject length\" => Int,\n",
    "#         \"q. start\" => Int,\n",
    "#         \"q. end\" => Int,\n",
    "#         \"s. start\" => Int,\n",
    "#         \"s. end\" => Int,\n",
    "#         \"evalue\" => Float64,\n",
    "#         \"bit score\" => Float64,\n",
    "#         \"score\" => Float64,\n",
    "#         \"alignment length\" => Int,\n",
    "#         \"% identity\" => Float64,\n",
    "#         \"identical\" => Int,\n",
    "#         \"mismatches\" => Int,\n",
    "#         \"subject tax id\" => Int,\n",
    "#         \"subject sci name\" => String,\n",
    "#         \"subject com names\" => String,\n",
    "#         \"subject blast name\" => String,\n",
    "#         \"subject super kingdom\" => String,\n",
    "#         \"subject tax ids\" => String,\n",
    "#         \"subject sci names\" => String,\n",
    "#         \"subject com names\" => String,\n",
    "#         \"subject blast names\" => String,\n",
    "#         \"subject super kingdoms\" => String,\n",
    "#         \"subject title\" => String,\n",
    "#         \"subject titles\" => String\n",
    "#     )\n",
    "#     data, _ = uCSV.read(\n",
    "#         blast_report,\n",
    "#         delim='\\t',\n",
    "#         comment='#',\n",
    "#         # skipmalformed=true,\n",
    "#         allowmissing=true,\n",
    "#         encodings=Dict(\"N/A\" => missing),\n",
    "#         types=[blast_col_types[h] for h in header])\n",
    "#     return DataFrames.DataFrame(data, header, makeunique=true)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5adf216-3ed2-4bdc-b278-e70879676e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "function parse_blast_report(blast_report, top_n = 1)\n",
    "    top_n_contig_hits = Dict{String, Vector{String}}()\n",
    "    # example header line \n",
    "    # \"# Fields: query id, subject id, subject acc., subject acc.ver, subject title, query length, subject length, q. start, q. end, s. start, s. end, evalue, bit score, score, alignment length, % identity, identical, mismatches, subject tax id\"\n",
    "    header_line = first(Iterators.filter(x -> occursin(r\"# Fields:\", x), eachline(blast_report)))\n",
    "    header = split(last(split(header_line, \": \")), \", \")\n",
    "    blast_col_types = Dict(\n",
    "        \"query id\" => String,\n",
    "        \"query title\" => String,\n",
    "        \"subject id\" => String,\n",
    "        \"subject gi\" => String,\n",
    "        \"subject acc.\" => String,\n",
    "        \"subject acc.ver\" => String,\n",
    "        \"subject title\" => String,\n",
    "        \"query length\" => Int,\n",
    "        \"subject length\" => Int,\n",
    "        \"q. start\" => Int,\n",
    "        \"q. end\" => Int,\n",
    "        \"s. start\" => Int,\n",
    "        \"s. end\" => Int,\n",
    "        \"evalue\" => Float64,\n",
    "        \"bit score\" => Float64,\n",
    "        \"score\" => Float64,\n",
    "        \"alignment length\" => Int,\n",
    "        \"% identity\" => Float64,\n",
    "        \"identical\" => Int,\n",
    "        \"mismatches\" => Int,\n",
    "        \"subject tax id\" => Int,\n",
    "        \"subject sci name\" => String,\n",
    "        \"subject com names\" => String,\n",
    "        \"subject blast name\" => String,\n",
    "        \"subject super kingdom\" => String,\n",
    "        \"subject tax ids\" => String,\n",
    "        \"subject sci names\" => String,\n",
    "        \"subject com names\" => String,\n",
    "        \"subject blast names\" => String,\n",
    "        \"subject super kingdoms\" => String,\n",
    "        \"subject title\" => String,\n",
    "        \"subject titles\" => String\n",
    "    )\n",
    "    for line in Iterators.filter(x -> !occursin(r\"^#\", x), eachline(blast_report))\n",
    "        contig = first(split(line, '\\t'))\n",
    "        if !haskey(top_n_contig_hits, contig)\n",
    "            top_n_contig_hits[contig] = [line]\n",
    "        elseif length(top_n_contig_hits[contig]) < top_n\n",
    "            push!(top_n_contig_hits[contig], line)\n",
    "        end\n",
    "    end\n",
    "    reconstructed_file = join([join(value, '\\n') for value in values(top_n_contig_hits)], '\\n')\n",
    "    data, _ = uCSV.read(\n",
    "        IOBuffer(reconstructed_file),\n",
    "        delim='\\t',\n",
    "        # comment='#',\n",
    "        # skipmalformed=true,\n",
    "        allowmissing=true,\n",
    "        encodings=Dict(\"N/A\" => missing),\n",
    "        types=[blast_col_types[h] for h in header])\n",
    "    return DataFrames.DataFrame(data, header, makeunique=true)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c1458a-c8cb-4006-8596-125f7bbd4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProgressMeter.@showprogress for SRR_path in SRR_paths\n",
    "#     # SRR_path = first(SRR_paths)\n",
    "#     qualimap_coverage_table = parse_qualimap_contig_coverage(joinpath(SRR_path, \"megahit\", \"qualimap\", \"genome_results.txt\"))\n",
    "#     mmseqs_lca_files = filter(x -> occursin(\"_lca.tsv\", x) && occursin(\"final.contigs.fastg.gfa.fna.mmseqs_easy_taxonomy\", x), readdir(joinpath(SRR_path, \"mmseqs_easy_taxonomy\"), join=true))\n",
    "\n",
    "#     # mmseqs_lca_file = first(mmseqs_lca_files)\n",
    "#     for mmseqs_lca_file in mmseqs_lca_files\n",
    "\n",
    "#         parse_mmseqs_easy_taxonomy_lca_tsv(mmseqs_lca_file)\n",
    "#         lca_table = parse_mmseqs_easy_taxonomy_lca_tsv(mmseqs_lca_file)\n",
    "#         contig_coverage_and_classification_table = DataFrames.leftjoin(qualimap_coverage_table, lca_table, on=\"Contig\" => \"contig_id\")\n",
    "#         contig_coverage_and_classification_table[!, \"taxon_id\"] = map(x -> ismissing(x) ? 0 : x, contig_coverage_and_classification_table[!, \"taxon_id\"])\n",
    "#         contig_coverage_and_classification_table = ifelse.(ismissing.(contig_coverage_and_classification_table), \"\", contig_coverage_and_classification_table)\n",
    "\n",
    "#         uCSV.write(\n",
    "#             replace(mmseqs_lca_file, r\"\\.tsv$\" => \".coverage-and-classification.tsv\"),\n",
    "#             contig_coverage_and_classification_table,\n",
    "#             delim='\\t'\n",
    "#         )\n",
    "#     end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d84ac5-c946-4765-a7e5-b4c2520b58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "nt_blast_report = \"final.contigs.fastg.gfa.fna.blastn.nt.megablast.txt\"\n",
    "ProgressMeter.@showprogress for (i, SRR_path) in enumerate(SRR_paths)\n",
    "    # @show i, SRR_path\n",
    "    \n",
    "    nt_blast_report_path = joinpath(SRR_path, \"blastn\", nt_blast_report)\n",
    "    outfile = replace(nt_blast_report_path, r\"\\.txt$\" => \".coverage-and-classification.tsv\")\n",
    "    if !isfile(nt_blast_report_path)\n",
    "        @info \"need to run blast $(basename(SRR_path))\"\n",
    "        # /oak/stanford/scg/lab_mpsnyder/cjprybol/Mycelia/projects/viral-exposome-discovery/data/SRA/SRR6399589/blastn/final.contigs.fastg.gfa.fna.blastn.nt.megablast.txt\n",
    "    elseif !isfile(outfile)\n",
    "        # try\n",
    "        qualimap_coverage_table = parse_qualimap_contig_coverage(joinpath(SRR_path, \"megahit\", \"qualimap\", \"genome_results.txt\"))\n",
    "\n",
    "        blast_table = parse_blast_report(joinpath(SRR_path, \"blastn\", nt_blast_report))\n",
    "\n",
    "        contig_coverage_and_classification_table = DataFrames.leftjoin(qualimap_coverage_table, blast_table, on=\"Contig\" => \"query id\")\n",
    "\n",
    "        if \"subject tax id\" in names(contig_coverage_and_classification_table)\n",
    "            contig_coverage_and_classification_table[!, \"subject tax id\"] = map(x -> ismissing(x) ? 0 : x, contig_coverage_and_classification_table[!, \"subject tax id\"])\n",
    "        else\n",
    "            contig_coverage_and_classification_table[!, \"subject tax id\"] = map(x -> (ismissing(x) || isempty(x)) ? 0 : parse(Int, first(split(x, ';'))), contig_coverage_and_classification_table[!, \"subject tax ids\"])\n",
    "        end\n",
    "        contig_coverage_and_classification_table = ifelse.(ismissing.(contig_coverage_and_classification_table), \"\", contig_coverage_and_classification_table)\n",
    "\n",
    "        uCSV.write(\n",
    "            replace(nt_blast_report_path, r\"\\.txt$\" => \".coverage-and-classification.tsv\"),\n",
    "            contig_coverage_and_classification_table,\n",
    "            delim='\\t'\n",
    "        )\n",
    "        # catch e\n",
    "        #     println(e)\n",
    "        #     println(SRR_path)\n",
    "        # end\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
