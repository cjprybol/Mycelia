{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f670684-0b08-4679-b2bd-f5851ec0d2d8",
   "metadata": {},
   "source": [
    "The objective of this notebook is to intersect the sample metadata with the taxonomic profiling information to see the top 20-25 groups for each individual over the time series of the sampling.\n",
    "\n",
    "- load sample metadata\n",
    "- order metadata by sample timestamp\n",
    "- group sample metadata by participant\n",
    "- for each participant, plot the relative abundances of their top 20-25 taxons (at each level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28afd0da-a1e3-48ad-a12a-8bbb3a8d19c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Pkg\n",
    "pkgs = [\n",
    "    \"Revise\",\n",
    "    \"DataFrames\",\n",
    "    \"StatsBase\",\n",
    "    \"StatsPlots\",\n",
    "    \"uCSV\",\n",
    "    \"ProgressMeter\",\n",
    "    \"Distances\",\n",
    "    \"Clustering\",\n",
    "    \"Colors\",\n",
    "    \"MultivariateStats\",\n",
    "    \"Dates\",\n",
    "    \"CategoricalArrays\",\n",
    "    \"GLM\",\n",
    "    \"MLJ\",\n",
    "    \"Statistics\"\n",
    "]\n",
    "# Pkg.add(pkgs)\n",
    "for pkg in pkgs\n",
    "    eval(Meta.parse(\"import $pkg\"))\n",
    "end\n",
    "import Mycelia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc54d53-21ec-4098-b1c9-8c8e67d4193a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = joinpath(dirname(pwd()), \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9282e23-ea48-4be0-8acb-67d044e0ca48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_paths = filter(x -> !occursin(\".ipynb_checkpoints\", x), readdir(joinpath(data_dir, \"SRA\"), join=true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c29934-2fb9-44fb-968e-1cf5a8c907ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dir = joinpath(data_dir, \"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15de5d9-b246-4f84-9fef-dcd1cf224918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in metadata\n",
    "metadata_dir = joinpath(dirname(pwd()), \"metadata\")\n",
    "\n",
    "exposome_environmental_data = DataFrames.DataFrame(uCSV.read(\n",
    "    joinpath(metadata_dir, \"metadata_exposome.rds.tsv\"),\n",
    "    delim='\\t',\n",
    "    header=1,\n",
    "    typedetectrows=300\n",
    "))\n",
    "\n",
    "joint_sample_metadata = DataFrames.DataFrame(uCSV.read(\n",
    "    joinpath(metadata_dir, \"exposome/joint_sample_metadata.tsv\"),\n",
    "    delim='\\t',\n",
    "    header=1,\n",
    "    typedetectrows=300\n",
    "))\n",
    "\n",
    "@assert joint_sample_metadata[!, \"Library Name\"] == joint_sample_metadata[!, \"LibraryName\"]\n",
    "joint_metadata = DataFrames.innerjoin(\n",
    "    joint_sample_metadata,\n",
    "    exposome_environmental_data,\n",
    "    on=\"Library Name\" => \"samplenames\");\n",
    "\n",
    "# aownership\n",
    "metadata_by_owner = DataFrames.groupby(joint_metadata, \"aownership\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d3c0d-6ca1-47f9-802b-d352ee889822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxon_levels = Mycelia.list_ranks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee437d-22df-4a8a-815f-da6b0d744d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "viral_tax_ids = Mycelia.list_subtaxa(10239)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05038e6-a117-46f6-ae0a-3c70770ac539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NCBI host metadata\n",
    "# ncbi_metadata_file = joinpath(dirname(pwd()), \"metadata\", \"NCBI-virus-refseq.transformed.tsv\")\n",
    "# ncbi_host_metadata = DataFrames.DataFrame(uCSV.read(ncbi_metadata_file, header=1, delim='\\t', encodings=Dict(\"false\" => false, \"true\" => true)))\n",
    "\n",
    "# # ICTV host metadata\n",
    "# ictv_metadata_file = joinpath(dirname(pwd()), \"metadata\", \"VMR_MSL38_v1 - VMR MSL38 v1.transformed.tsv\")\n",
    "# ictv_host_metadata = DataFrames.DataFrame(uCSV.read(ictv_metadata_file, header=1, delim='\\t', typedetectrows=100))\n",
    "# ictv_host_metadata = ictv_host_metadata[.!isempty.(ictv_host_metadata[!, \"taxid\"]), :]\n",
    "# ictv_host_metadata[!, \"taxid\"] = parse.(Int, ictv_host_metadata[!, \"taxid\"])\n",
    "\n",
    "# # # # VirusHostDB metadata\n",
    "# # virushostdb_metadata_file = joinpath(dirname(pwd()), \"metadata\", \"virushostdb.transformed.tsv\")\n",
    "# # virushostdb_metadata = DataFrames.DataFrame(uCSV.read(virushostdb_metadata_file, header=1, delim='\\t', typedetectrows=1086, encodings=Dict(\"missing\" => missing, \"false\" => false, \"true\" => true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6be592-0df7-49ea-ba1c-ab66b5ff7ea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i = 1\n",
    "# i = 2\n",
    "# i = 3\n",
    "# i = 4\n",
    "# i = 5\n",
    "# i = 6\n",
    "# needed subsetting from here\n",
    "# i = 7\n",
    "# i = 8\n",
    "# DONT DO 9\n",
    "# i = 9\n",
    "\n",
    "(taxon_index, taxon_level) = collect(enumerate(taxon_levels))[i]\n",
    "println(\"$(taxon_index) - $(taxon_level)\")\n",
    "rank_table = Mycelia.list_rank(taxon_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62513c7-b88c-4cc1-98df-4f6bbecc79cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all viral taxids across the databases\n",
    "if i == 2\n",
    "    filtered_tax_ids = Set(rank_table[!, \"taxid\"])\n",
    "elseif i > 2\n",
    "    filtered_tax_ids = Set(viral_tax_ids)\n",
    "    filtered_rank_table = rank_table[map(taxid -> taxid in filtered_tax_ids, rank_table[!, \"taxid\"]), :]\n",
    "    filtered_tax_ids = Set(filtered_rank_table[!, \"taxid\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477dcf28-6921-467f-b36f-7e1be885160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kraken_db = \"k2_pluspfp\"\n",
    "kraken_db_regex = Regex(\"$(kraken_db)_\\\\d{8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707ef57-5cf6-4878-a84a-12277dc6f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sample_taxon_report = joinpath(results_dir, \"$(kraken_db).$(taxon_level).ictv.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7936cf77-b694-456c-8582-016f2f6022f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sample_taxon_figure_png = joinpath(results_dir, \"$(kraken_db).$(taxon_level).ictv.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4db5e8-1be2-4bc2-9cc2-658220673e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "exposome_kraken_reports = map(path ->\n",
    "    first(filter(x -> occursin(kraken_db_regex, x) && occursin(r\"kraken-report\\.tsv$\", x), readdir(joinpath(path, \"kraken\"), join=true))),\n",
    "    sample_paths)\n",
    "# kraken_dirs = filter(x -> occursin(r\"Kraken2\", x), readdir(joinpath(data_dir, \"ultimagen-snyder\"), join=true))\n",
    "# ultima_kraken_reports = reduce(vcat, [readdir(kraken_dir, join=true) for kraken_dir in kraken_dirs])\n",
    "# ipop_kraken_reports = readdir(joinpath(data_dir, \"ultimagen-snyder/ipop/kraken2\"), join=true)\n",
    "# joint_kraken_reports = vcat(exposome_kraken_reports, ultima_kraken_reports, ipop_kraken_reports)\n",
    "joint_kraken_reports = exposome_kraken_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863e742-0010-4108-82a2-cb5eff68f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sample_taxon_report_table = DataFrames.DataFrame()\n",
    "# sample_path = first(sample_paths)\n",
    "ProgressMeter.@showprogress for kraken_report in joint_kraken_reports\n",
    "    report_table = Mycelia.read_kraken_report(kraken_report)\n",
    "    taxon_level_report = report_table[map(x -> x in filtered_tax_ids, report_table[!, \"ncbi_taxonid\"]), :]\n",
    "    taxon_level_report[!, \"sample_identifier\"] .= basename(kraken_report)\n",
    "    append!(cross_sample_taxon_report_table, taxon_level_report)\n",
    "end\n",
    "cross_sample_taxon_report_summary = cross_sample_taxon_report_table[!, DataFrames.Not([\"percentage_of_fragments_at_or_below_taxon\", \"number_of_fragments_assigned_directly_to_taxon\", \"rank\"])]\n",
    "# uCSV.write(cross_sample_taxon_report, cross_sample_taxon_report_table, delim='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d655bf-141e-44ae-b499-15e330b65d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sample_taxon_report_summary[!, \"taxon\"] = map(row -> string(row[\"ncbi_taxonid\"]) * \"_\" * row[\"scientific_name\"], DataFrames.eachrow(cross_sample_taxon_report_summary))\n",
    "# cross_sample_taxon_report_summary = cross_sample_taxon_report_summary[!, DataFrames.Not([\n",
    "#             \"ncbi_taxonid\",\n",
    "#             \"scientific_name\"\n",
    "#         ])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e327e1d-78bd-411c-9bc3-5798b0138812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert sortedness & uniqueness (should be a no-op)\n",
    "unique!(DataFrames.sort!(cross_sample_taxon_report_summary, [\"sample_identifier\", \"taxon\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aecc598-32af-43f2-9b94-cc3182c40639",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sample_taxon_report_summary = cross_sample_taxon_report_summary[cross_sample_taxon_report_summary[!, \"number_of_fragments_at_or_below_taxon\"] .> 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fcce3b-37ae-4c1f-8ade-5ec48643ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "StatsPlots.histogram(log2.(cross_sample_taxon_report_summary[!, \"number_of_fragments_at_or_below_taxon\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580571d-4312-40d0-95b0-43047e1331e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sample_taxon_report_summary = cross_sample_taxon_report_summary[cross_sample_taxon_report_summary[!, \"number_of_fragments_at_or_below_taxon\"] .>= 3, :]\n",
    "cross_sample_taxon_report_summary[!, \"sample_identifier\"] = string.(first.(split.(cross_sample_taxon_report_summary[!, \"sample_identifier\"], '.')))\n",
    "\n",
    "# sort(DataFrames.combine(\n",
    "#     DataFrames.groupby(\n",
    "#         cross_sample_taxon_report_summary[!, \n",
    "#             [\"number_of_fragments_at_or_below_taxon\", \"taxon\"]], \"taxon\"), \n",
    "#     \"number_of_fragments_at_or_below_taxon\" => Statistics.median), \"number_of_fragments_at_or_below_taxon_median\", rev=true)\n",
    "\n",
    "sorted_taxa_counts_table = sort(DataFrames.combine(\n",
    "    DataFrames.groupby(\n",
    "        cross_sample_taxon_report_summary[!, \n",
    "            [\"number_of_fragments_at_or_below_taxon\", \"taxon\"]], \"taxon\"),\n",
    "    \"number_of_fragments_at_or_below_taxon\" => Statistics.mean), \"number_of_fragments_at_or_below_taxon_mean\", rev=true)\n",
    "\n",
    "# sort(DataFrames.combine(\n",
    "#     DataFrames.groupby(\n",
    "#         cross_sample_taxon_report_summary[!, \n",
    "#             [\"number_of_fragments_at_or_below_taxon\", \"taxon\"]], \"taxon\"), \n",
    "#     \"number_of_fragments_at_or_below_taxon\" => sum), \"number_of_fragments_at_or_below_taxon_sum\", rev=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52bb8f-90d0-4954-867d-b101c5ff57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_taxa = sorted_taxa_counts_table[!, \"taxon\"]\n",
    "colorscheme = Colors.distinguishable_colors(length(unique_taxa), [Colors.RGB(1,1,1), Colors.RGB(0,0,0)], dropseed=true)\n",
    "taxa_to_color = Dict(t => c for (t, c) in zip(unique_taxa, colorscheme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36926b64-a58e-4847-80c4-977dbb9333a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 60\n",
    "\n",
    "for i in 1:9\n",
    "# for i in 1:1\n",
    "\n",
    "    participant_table = DataFrames.innerjoin(\n",
    "        metadata_by_owner[i],\n",
    "        cross_sample_taxon_report_summary,\n",
    "        on=\"Run\" => \"sample_identifier\"\n",
    "    )\n",
    "\n",
    "    participant_table = participant_table[!, [\n",
    "        \"aownership\",\n",
    "        \"season\",\n",
    "        \"geo_loc_name\",\n",
    "        \"weekend\",\n",
    "        \"temperature\",\n",
    "        \"humid\",\n",
    "        \"particle\",\n",
    "        \"Run\",\n",
    "        \"date.start\",\n",
    "        \"date.end\",\n",
    "        \"ncbi_taxonid\",\n",
    "        \"scientific_name\",\n",
    "        \"taxon\",\n",
    "        \"number_of_fragments_at_or_below_taxon\",\n",
    "        ]]\n",
    "\n",
    "    participant_table[!, \"date.start\"] = Dates.Date.(participant_table[!, \"date.start\"], \"yyyy-mm-dd\")\n",
    "    participant_table[!, \"date.end\"] = Dates.Date.(participant_table[!, \"date.end\"], \"yyyy-mm-dd\")\n",
    "\n",
    "    sort!(participant_table, \"date.start\")\n",
    "\n",
    "    participant_table[!, \"date.start_relative\"] = participant_table[!, \"date.start\"] .- first(participant_table[!, \"date.start\"])\n",
    "\n",
    "    participant_table[!, \"date.end_relative\"] = participant_table[!, \"date.end\"] .- first(participant_table[!, \"date.start\"])\n",
    "\n",
    "    participant_table[!, \"duration\"] = participant_table[!, \"date.end\"] .- participant_table[!, \"date.start\"]\n",
    "\n",
    "    participant = participant_table[1, \"aownership\"]\n",
    "\n",
    "    participant_table\n",
    "\n",
    "    samples = sort(unique(participant_table[!, \"Run\"]))\n",
    "    taxon = sort(unique(participant_table[!, \"taxon\"]))\n",
    "    samples_map = Dict(sample => i for (i, sample) in enumerate(samples))\n",
    "    counts = zeros(length(samples), length(taxon))\n",
    "    for (column_index, taxon_table) in enumerate(DataFrames.groupby(sort(participant_table, \"taxon\"), \"taxon\"))\n",
    "        for sample_table in DataFrames.groupby(taxon_table, \"Run\")\n",
    "            sample = sample_table[1, \"Run\"]\n",
    "            row_index = samples_map[sample]\n",
    "            @assert DataFrames.nrow(sample_table) == 1\n",
    "            counts[row_index, column_index] = sum(sample_table[!, \"number_of_fragments_at_or_below_taxon\"])\n",
    "        end\n",
    "    end\n",
    "    counts\n",
    "\n",
    "    # sort taxa so largest single group is at the bottom\n",
    "    frequency_ordering = sortperm(maximum.(eachcol(counts)))\n",
    "    counts = counts[:, frequency_ordering]\n",
    "    taxon = taxon[frequency_ordering]\n",
    "    # find taxa that have no representation, and filter them out\n",
    "    is_detected = [sum(col) >= 1 for col in eachcol(counts)]\n",
    "    counts = counts[:, is_detected]\n",
    "    taxon = taxon[is_detected]\n",
    "\n",
    "    # # drop samples that have no data, not sure this is relevant now that we dropped negative control samples\n",
    "    # sample_has_classifications = [sum(row) > 0 for row in eachrow(counts)]\n",
    "    # counts = counts[sample_has_classifications, :]\n",
    "    # samples = samples[sample_has_classifications]\n",
    "    \n",
    "    if size(counts, 2) > top_n\n",
    "        counts = counts[:, (end-top_n+1):end]\n",
    "    end\n",
    "    \n",
    "    # unique_taxa = sort(unique(participant_table[!, \"ncbi_taxonid\"]))\n",
    "    # colorscheme = Colors.distinguishable_colors(length(unique_taxa), [Colors.RGB(1,1,1), Colors.RGB(0,0,0)], dropseed=true)\n",
    "\n",
    "    normalized_counts = counts ./ sum(counts, dims=2)\n",
    "\n",
    "    bottommargin = (maximum(length.(samples)) * 5)\n",
    "    leftmargin = 150\n",
    "    rightmargin = 25\n",
    "    topmargin = 25\n",
    "\n",
    "    width = max(1920, (size(counts, 1) * 12) + 300)\n",
    "    height = max(1080, bottommargin + 600)\n",
    "    height = max(height, size(counts, 2)*11)\n",
    "    \n",
    "    legendfontsize=12\n",
    "\n",
    "    xtickdates = sort(unique(participant_table[!, [\"date.end\", \"Run\"]]))[!, \"date.end\"]\n",
    "\n",
    "    plot = StatsPlots.groupedbar(\n",
    "        log10.(counts .+ 1),\n",
    "        title = \"read-classification - $(participant) - kraken - $(kraken_db) - $(taxon_level)\",\n",
    "        xticks = (1:length(samples), xtickdates),\n",
    "        xlims = (0, length(samples)+1),\n",
    "        size=(width, height),\n",
    "        xrotation=90,\n",
    "        ylabel = \"log10(number of reads)\",\n",
    "        labels = hcat(taxon...),\n",
    "        leftmargin = (leftmargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        topmargin = (topmargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        rightmargin = (rightmargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        bottommargin = (bottommargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        legendmargins = 0,\n",
    "        legend = :outertopright,\n",
    "        bar_position = :stack,\n",
    "        bar_width=0.7,\n",
    "        seriescolor = hcat([taxa_to_color[t] for t in taxon]...),\n",
    "    )\n",
    "    display(plot)\n",
    "    for extension in [\".png\"]\n",
    "        file = joinpath(results_dir, \"taxonomic-breakdowns.kraken.$(kraken_db).$(taxon_index).$(taxon_level).by-participant.$(participant).total-reads\") * extension\n",
    "        StatsPlots.savefig(plot, file)\n",
    "    end\n",
    "\n",
    "    plot = StatsPlots.groupedbar(\n",
    "        normalized_counts,\n",
    "        title = \"read-classification - $(participant) - kraken - $(kraken_db) - $(taxon_level)\",\n",
    "        xticks = (1:length(samples), xtickdates),\n",
    "        xlims = (0, length(samples)+1),\n",
    "        size= (width, height),\n",
    "        xrotation=90,\n",
    "        ylabel = \"proportion of reads\",\n",
    "        labels = hcat(taxon...),\n",
    "        leftmargin = (leftmargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        topmargin = (topmargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        rightmargin = (rightmargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        bottommargin = (bottommargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        legendmargins = 0,\n",
    "        legend = :outertopright,\n",
    "        bar_position = :stack,\n",
    "        bar_width=0.7,\n",
    "        seriescolor = hcat([taxa_to_color[t] for t in taxon]...),\n",
    "    )\n",
    "    display(plot)\n",
    "    for extension in [\".png\"]\n",
    "        file = joinpath(results_dir, \"taxonomic-breakdowns.kraken.$(kraken_db).$(taxon_index).$(taxon_level).by-participant.$(participant).normalized-reads\") * extension\n",
    "        StatsPlots.savefig(plot, file)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685b633a-dc40-4864-b9f6-409af6666526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_table = DataFrames.innerjoin(joint_metadata, cross_sample_taxon_report_summary, on=\"Run\" => \"sample_identifier\")\n",
    "\n",
    "# # \"date.start\",\n",
    "# # \"date.end\",\n",
    "# # \"ncbi_taxonid\",\n",
    "# # \"scientific_name\",\n",
    "# full_table = full_table[!, [\n",
    "#     # \"aownership\", # categorical\n",
    "#     \"season\", # categorical\n",
    "#     # \"geo_loc_name\", # categorical\n",
    "#     # \"weekend\", # categorical\n",
    "#     \"temperature\",\n",
    "#     \"humid\",\n",
    "#     \"particle\",\n",
    "#     \"Run\",\n",
    "#     \"taxon\", # categorical\n",
    "#     \"number_of_fragments_at_or_below_taxon\",\n",
    "#     ]]\n",
    "\n",
    "# for col in [\n",
    "#     # \"aownership\", # categorical\n",
    "#     \"season\", # categorical\n",
    "#     # \"geo_loc_name\", # categorical\n",
    "#     # \"weekend\", # categorical\n",
    "#     \"taxon\", # categorical\n",
    "#     ]\n",
    "#     full_table[!, col] = CategoricalArrays.categorical(full_table[!, col])\n",
    "# end\n",
    "\n",
    "# full_table[!, \"temperature\"] = something.(tryparse.(Float64, full_table[!, \"temperature\"]), missing)\n",
    "# full_table[!, \"humid\"] = something.(tryparse.(Float64, full_table[!, \"humid\"]), missing)\n",
    "# full_table[!, \"particle\"] = something.(tryparse.(Float64, full_table[!, \"particle\"]), missing)\n",
    "\n",
    "# full_table = DataFrames.dropmissing(full_table)\n",
    "\n",
    "\n",
    "# # get virus table\n",
    "# # for future levels, need to do all of these\n",
    "# taxon_table = first(DataFrames.groupby(full_table, \"taxon\"))\n",
    "\n",
    "# # could use MLJ for this?\n",
    "# # Splitting the data\n",
    "# # train_indices, test_indices = split_indices(1:DataFrames.nrow(full_table), 0.8)\n",
    "# # train_data = full_table[train_indices, :]\n",
    "# # test_data = full_table[test_indices, :]\n",
    "\n",
    "# # Define the model\n",
    "# # geo_loc_name\n",
    "# # weekend\n",
    "# # aownership\n",
    "# model = GLM.lm(GLM.@formula(number_of_fragments_at_or_below_taxon ~ particle + humid + temperature + season ), taxon_table)\n",
    "\n",
    "# # Train the model\n",
    "# # GLM.fit!(model)\n",
    "\n",
    "# # Evaluate the model\n",
    "# # predictions = GLM.predict(model, taxon_table)/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cabe60-70e1-4426-bb02-099f3b7bf0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_table = DataFrames.innerjoin(joint_metadata, cross_sample_taxon_report_summary, on=\"Run\" => \"sample_identifier\")\n",
    "\n",
    "# # \"date.start\",\n",
    "# # \"date.end\",\n",
    "# # \"ncbi_taxonid\",\n",
    "# # \"scientific_name\",\n",
    "# full_table = full_table[!, [\n",
    "#     # \"aownership\", # categorical\n",
    "#     \"geo_loc_name\", # categorical\n",
    "#     \"weekend\", # categorical\n",
    "#     \"season\", #categorical\n",
    "#     \"taxon\", # categorical\n",
    "#     \"number_of_fragments_at_or_below_taxon\",\n",
    "#     ]]\n",
    "\n",
    "# for col in [\n",
    "#     # \"aownership\", # categorical\n",
    "#     \"season\", # categorical\n",
    "#     \"geo_loc_name\", # categorical\n",
    "#     \"weekend\", # categorical\n",
    "#     \"taxon\", # categorical\n",
    "#     ]\n",
    "#     full_table[!, col] = CategoricalArrays.categorical(full_table[!, col])\n",
    "# end\n",
    "\n",
    "# # full_table[!, \"temperature\"] = something.(tryparse.(Float64, full_table[!, \"temperature\"]), missing)\n",
    "# # full_table[!, \"humid\"] = something.(tryparse.(Float64, full_table[!, \"humid\"]), missing)\n",
    "# # full_table[!, \"particle\"] = something.(tryparse.(Float64, full_table[!, \"particle\"]), missing)\n",
    "\n",
    "# full_table = DataFrames.dropmissing(full_table)\n",
    "\n",
    "\n",
    "# # get virus table\n",
    "# # for future levels, need to do all of these\n",
    "# taxon_table = first(DataFrames.groupby(full_table, \"taxon\"))\n",
    "\n",
    "# # could use MLJ for this?\n",
    "# # Splitting the data\n",
    "# # train_indices, test_indices = split_indices(1:DataFrames.nrow(full_table), 0.8)\n",
    "# # train_data = full_table[train_indices, :]\n",
    "# # test_data = full_table[test_indices, :]\n",
    "\n",
    "# # Define the model\n",
    "# # geo_loc_name\n",
    "# # weekend\n",
    "# # aownership\n",
    "# model = GLM.lm(GLM.@formula(number_of_fragments_at_or_below_taxon ~ geo_loc_name + weekend + season), taxon_table)\n",
    "\n",
    "# # Train the model\n",
    "# # GLM.fit!(model)\n",
    "\n",
    "# # Evaluate the model\n",
    "# # predictions = GLM.predict(model, taxon_table)/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
