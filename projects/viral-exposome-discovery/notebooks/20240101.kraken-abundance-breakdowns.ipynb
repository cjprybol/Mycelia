{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f670684-0b08-4679-b2bd-f5851ec0d2d8",
   "metadata": {},
   "source": [
    "The objective of this notebook is to:\n",
    "- join all of the kraken results with the sample metadata\n",
    "- subset to samples with metadata\n",
    "- collapse P3+ into Other\n",
    "- show the time series at each level for each participant (P1, P2, and Other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28afd0da-a1e3-48ad-a12a-8bbb3a8d19c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Pkg\n",
    "pkgs = [\n",
    "    \"Revise\",\n",
    "    \"DataFrames\",\n",
    "    \"StatsBase\",\n",
    "    \"StatsPlots\",\n",
    "    \"uCSV\",\n",
    "    \"ProgressMeter\",\n",
    "    \"Distances\",\n",
    "    \"Colors\",\n",
    "    \"MultivariateStats\",\n",
    "    \"Dates\",\n",
    "    \"CategoricalArrays\",\n",
    "    \"Statistics\"\n",
    "]\n",
    "# Pkg.add(pkgs)\n",
    "for pkg in pkgs\n",
    "    eval(Meta.parse(\"import $pkg\"))\n",
    "end\n",
    "import Mycelia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc54d53-21ec-4098-b1c9-8c8e67d4193a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = joinpath(dirname(pwd()), \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c29934-2fb9-44fb-968e-1cf5a8c907ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dir = joinpath(data_dir, \"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15de5d9-b246-4f84-9fef-dcd1cf224918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in metadata\n",
    "metadata_dir = joinpath(dirname(pwd()), \"metadata\")\n",
    "\n",
    "exposome_environmental_data = DataFrames.DataFrame(uCSV.read(\n",
    "    joinpath(metadata_dir, \"metadata_exposome.rds.tsv\"),\n",
    "    delim='\\t',\n",
    "    header=1,\n",
    "    typedetectrows=300\n",
    "))\n",
    "\n",
    "joint_sample_metadata = DataFrames.DataFrame(uCSV.read(\n",
    "    joinpath(metadata_dir, \"exposome/joint_sample_metadata.tsv\"),\n",
    "    delim='\\t',\n",
    "    header=1,\n",
    "    typedetectrows=300\n",
    "))\n",
    "\n",
    "@assert joint_sample_metadata[!, \"Library Name\"] == joint_sample_metadata[!, \"LibraryName\"]\n",
    "joint_metadata = DataFrames.innerjoin(\n",
    "    joint_sample_metadata,\n",
    "    exposome_environmental_data,\n",
    "    on=\"Library Name\" => \"samplenames\");\n",
    "\n",
    "\n",
    "# recode P3 and beyond to Other, since they don't have enough samples to do much analysis on\n",
    "joint_metadata[!, \"aownership\"] = map(x -> x in Set([\"P1\", \"P2\"]) ? x : \"Others\", joint_metadata[!, \"aownership\"])\n",
    "\n",
    "# aownership\n",
    "metadata_by_owner = DataFrames.groupby(joint_metadata, \"aownership\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cbe00-1abc-4289-a05a-3c7f3b62225e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_paths = sort(joinpath.(data_dir, \"SRA\", joint_metadata[!, \"Run\"]))\n",
    "kraken_db = \"k2_pluspfp\"\n",
    "kraken_db_regex = Regex(\"$(kraken_db)_\\\\d{8}\")\n",
    "kraken_reports = map(path ->\n",
    "    first(filter(x -> occursin(kraken_db_regex, x) && occursin(r\"kraken-report\\.tsv$\", x), readdir(joinpath(path, \"kraken\"), join=true))),\n",
    "    sample_paths)\n",
    "\n",
    "# create a full joint table so that we can subset dynamically down below without needing to re-read all of them over and over again\n",
    "joint_report_table = DataFrames.DataFrame()\n",
    "ProgressMeter.@showprogress for kraken_report in kraken_reports\n",
    "    report_table = Mycelia.read_kraken_report(kraken_report)\n",
    "    report_table[!, \"report\"] .= basename(kraken_report)\n",
    "    append!(joint_report_table, report_table)\n",
    "end\n",
    "joint_report_table[!, \"taxon\"] = map(row -> string(row[\"ncbi_taxonid\"]) * \"_\" * row[\"scientific_name\"], DataFrames.eachrow(joint_report_table))\n",
    "joint_report_table[!, \"sample_identifier\"] = string.(first.(split.(joint_report_table[!, \"report\"], '.')))\n",
    "joint_report_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6be592-0df7-49ea-ba1c-ab66b5ff7ea2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# taxon_levels = Mycelia.list_ranks()\n",
    "viral_tax_ids = Mycelia.list_subtaxa(10239)\n",
    "\n",
    "# rank_level = 1\n",
    "# rank_level = 2\n",
    "# rank_level = 3\n",
    "# rank_level = 4\n",
    "# rank_level = 5\n",
    "# rank_level = 6\n",
    "# rank_level = 7\n",
    "rank_level = 8\n",
    "\n",
    "(taxon_index, taxon_level) = collect(enumerate(taxon_levels))[rank_level]\n",
    "println(\"$(taxon_index) - $(taxon_level)\")\n",
    "rank_table = Mycelia.list_rank(taxon_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62513c7-b88c-4cc1-98df-4f6bbecc79cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of all viral taxids across the databases\n",
    "if rank_level <= 2\n",
    "    filtered_tax_ids = Set(rank_table[!, \"taxid\"])\n",
    "elseif rank_level > 2\n",
    "    filtered_tax_ids = Set(viral_tax_ids)\n",
    "    filtered_rank_table = rank_table[map(taxid -> taxid in filtered_tax_ids, rank_table[!, \"taxid\"]), :]\n",
    "    filtered_tax_ids = Set(filtered_rank_table[!, \"taxid\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ded1fa-f738-4ca2-8932-66ace4a28002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_sample_taxon_report = joinpath(results_dir, \"$(kraken_db).$(taxon_level).ictv.tsv\")\n",
    "# cross_sample_taxon_figure_png = joinpath(results_dir, \"$(kraken_db).$(taxon_level).ictv.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6449551d-c175-4f06-bcd4-7ec85cfc8724",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sample_taxon_report_summary = joint_report_table[map(x -> x in filtered_tax_ids, joint_report_table[!, \"ncbi_taxonid\"]), DataFrames.Not([\"percentage_of_fragments_at_or_below_taxon\", \"number_of_fragments_assigned_directly_to_taxon\", \"rank\"])]\n",
    "# assert sortedness & uniqueness (should be a no-op)\n",
    "unique!(DataFrames.sort!(cross_sample_taxon_report_summary, [\"sample_identifier\", \"taxon\"]))\n",
    "# filter out zero hits\n",
    "cross_sample_taxon_report_summary = cross_sample_taxon_report_summary[cross_sample_taxon_report_summary[!, \"number_of_fragments_at_or_below_taxon\"] .> 0, :]\n",
    "StatsPlots.histogram(log2.(cross_sample_taxon_report_summary[!, \"number_of_fragments_at_or_below_taxon\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580571d-4312-40d0-95b0-43047e1331e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_sample_taxon_report_summary = cross_sample_taxon_report_summary[cross_sample_taxon_report_summary[!, \"number_of_fragments_at_or_below_taxon\"] .>= 3, :]\n",
    "cross_sample_taxon_report_summary[!, \"sample_identifier\"] = string.(first.(split.(cross_sample_taxon_report_summary[!, \"sample_identifier\"], '.')))\n",
    "\n",
    "sorted_taxa_counts_table = sort(DataFrames.combine(\n",
    "    DataFrames.groupby(\n",
    "        cross_sample_taxon_report_summary[!, \n",
    "            [\"number_of_fragments_at_or_below_taxon\", \"taxon\"]], \"taxon\"),\n",
    "    \"number_of_fragments_at_or_below_taxon\" => Statistics.mean), \"number_of_fragments_at_or_below_taxon_mean\", rev=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52bb8f-90d0-4954-867d-b101c5ff57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_taxa = sorted_taxa_counts_table[!, \"taxon\"]\n",
    "colorscheme = Colors.distinguishable_colors(length(unique_taxa), [Colors.RGB(1,1,1), Colors.RGB(0,0,0)], dropseed=true)\n",
    "taxa_to_color = Dict(t => c for (t, c) in zip(unique_taxa, colorscheme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36926b64-a58e-4847-80c4-977dbb9333a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 60\n",
    "\n",
    "for participant in 1:3\n",
    "\n",
    "    participant_table = DataFrames.innerjoin(\n",
    "        metadata_by_owner[participant],\n",
    "        cross_sample_taxon_report_summary,\n",
    "        on=\"Run\" => \"sample_identifier\"\n",
    "    )\n",
    "\n",
    "    participant_table = participant_table[!, [\n",
    "        \"aownership\",\n",
    "        \"season\",\n",
    "        \"geo_loc_name\",\n",
    "        \"weekend\",\n",
    "        \"temperature\",\n",
    "        \"humid\",\n",
    "        \"particle\",\n",
    "        \"Run\",\n",
    "        \"date.start\",\n",
    "        \"date.end\",\n",
    "        \"ncbi_taxonid\",\n",
    "        \"scientific_name\",\n",
    "        \"taxon\",\n",
    "        \"number_of_fragments_at_or_below_taxon\",\n",
    "        ]]\n",
    "\n",
    "    participant_table[!, \"date.start\"] = Dates.Date.(participant_table[!, \"date.start\"], \"yyyy-mm-dd\")\n",
    "    participant_table[!, \"date.end\"] = Dates.Date.(participant_table[!, \"date.end\"], \"yyyy-mm-dd\")\n",
    "\n",
    "    sort!(participant_table, \"date.start\")\n",
    "\n",
    "    participant_table[!, \"date.start_relative\"] = participant_table[!, \"date.start\"] .- first(participant_table[!, \"date.start\"])\n",
    "\n",
    "    participant_table[!, \"date.end_relative\"] = participant_table[!, \"date.end\"] .- first(participant_table[!, \"date.start\"])\n",
    "\n",
    "    participant_table[!, \"duration\"] = participant_table[!, \"date.end\"] .- participant_table[!, \"date.start\"]\n",
    "\n",
    "    participant = participant_table[1, \"aownership\"]\n",
    "\n",
    "    samples = sort(unique(participant_table[!, \"Run\"]))\n",
    "    taxon = sort(unique(participant_table[!, \"taxon\"]))\n",
    "    samples_map = Dict(sample => i for (i, sample) in enumerate(samples))\n",
    "    counts = zeros(length(samples), length(taxon))\n",
    "    for (column_index, taxon_table) in enumerate(DataFrames.groupby(sort(participant_table, \"taxon\"), \"taxon\"))\n",
    "        for sample_table in DataFrames.groupby(taxon_table, \"Run\")\n",
    "            sample = sample_table[1, \"Run\"]\n",
    "            row_index = samples_map[sample]\n",
    "            @assert DataFrames.nrow(sample_table) == 1\n",
    "            counts[row_index, column_index] = sum(sample_table[!, \"number_of_fragments_at_or_below_taxon\"])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # sort taxa so largest single group is at the bottom\n",
    "    frequency_ordering = sortperm(maximum.(eachcol(counts)))\n",
    "    counts = counts[:, frequency_ordering]\n",
    "    taxon = taxon[frequency_ordering]\n",
    "    # find taxa that have no representation, and filter them out\n",
    "    is_detected = [sum(col) >= 1 for col in eachcol(counts)]\n",
    "    counts = counts[:, is_detected]\n",
    "    taxon = taxon[is_detected]\n",
    "\n",
    "    # # drop samples that have no data, not sure this is relevant now that we dropped negative control samples\n",
    "    # sample_has_classifications = [sum(row) > 0 for row in eachrow(counts)]\n",
    "    # counts = counts[sample_has_classifications, :]\n",
    "    # samples = samples[sample_has_classifications]\n",
    "    \n",
    "    if size(counts, 2) > top_n\n",
    "        counts = counts[:, (end-top_n+1):end]\n",
    "    end\n",
    "    \n",
    "    # unique_taxa = sort(unique(participant_table[!, \"ncbi_taxonid\"]))\n",
    "    # colorscheme = Colors.distinguishable_colors(length(unique_taxa), [Colors.RGB(1,1,1), Colors.RGB(0,0,0)], dropseed=true)\n",
    "\n",
    "    normalized_counts = counts ./ sum(counts, dims=2)\n",
    "\n",
    "    bottommargin = (maximum(length.(samples)) * 5)\n",
    "    leftmargin = 150\n",
    "    rightmargin = 25\n",
    "    topmargin = 25\n",
    "\n",
    "    width = max(1920, (size(counts, 1) * 12) + 300)\n",
    "    height = max(1080, bottommargin + 600)\n",
    "    height = max(height, size(counts, 2)*11)\n",
    "    \n",
    "    legendfontsize=12\n",
    "\n",
    "    xtickdates = sort(unique(participant_table[!, [\"date.end\", \"Run\"]]))[!, \"date.end\"]\n",
    "\n",
    "    plot = StatsPlots.groupedbar(\n",
    "        log10.(counts .+ 1),\n",
    "        title = \"read-classification - $(participant) - kraken - $(kraken_db) - $(taxon_level)\",\n",
    "        xticks = (1:length(samples), xtickdates),\n",
    "        xlims = (0, length(samples)+1),\n",
    "        size=(width, height),\n",
    "        xrotation=90,\n",
    "        ylabel = \"log10(number of reads)\",\n",
    "        labels = hcat(taxon...),\n",
    "        leftmargin = (leftmargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        topmargin = (topmargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        rightmargin = (rightmargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        bottommargin = (bottommargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        legendmargins = 0,\n",
    "        legend = :outertopright,\n",
    "        bar_position = :stack,\n",
    "        bar_width=0.7,\n",
    "        seriescolor = hcat([taxa_to_color[t] for t in taxon]...),\n",
    "    )\n",
    "    display(plot)\n",
    "    for extension in [\".png\"]\n",
    "        file = joinpath(results_dir, \"taxonomic-breakdowns.kraken.$(kraken_db).$(taxon_index).$(taxon_level).by-participant.$(participant).total-reads\") * extension\n",
    "        StatsPlots.savefig(plot, file)\n",
    "    end\n",
    "\n",
    "    plot = StatsPlots.groupedbar(\n",
    "        normalized_counts,\n",
    "        title = \"read-classification - $(participant) - kraken - $(kraken_db) - $(taxon_level)\",\n",
    "        xticks = (1:length(samples), xtickdates),\n",
    "        xlims = (0, length(samples)+1),\n",
    "        size= (width, height),\n",
    "        xrotation=90,\n",
    "        ylabel = \"proportion of reads\",\n",
    "        labels = hcat(taxon...),\n",
    "        leftmargin = (leftmargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        topmargin = (topmargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        rightmargin = (rightmargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        bottommargin = (bottommargin)StatsPlots.Plots.PlotMeasures.px,\n",
    "        legendmargins = 0,\n",
    "        legend = :outertopright,\n",
    "        bar_position = :stack,\n",
    "        bar_width=0.7,\n",
    "        seriescolor = hcat([taxa_to_color[t] for t in taxon]...),\n",
    "    )\n",
    "    display(plot)\n",
    "    for extension in [\".png\"]\n",
    "        file = joinpath(results_dir, \"taxonomic-breakdowns.kraken.$(kraken_db).$(taxon_index).$(taxon_level).by-participant.$(participant).normalized-reads\") * extension\n",
    "        StatsPlots.savefig(plot, file)\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
