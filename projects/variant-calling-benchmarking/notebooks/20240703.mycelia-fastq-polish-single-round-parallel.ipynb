{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335bf35f-c55e-4857-83f0-ed03dc666f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if hit plotting library issues, try resetting LD path for julia\n",
    "# can set in ~/.local/share/jupyter/kernels/\n",
    "haskey(ENV, \"LD_LIBRARY_PATH\") && @assert ENV[\"LD_LIBRARY_PATH\"] == \"\"\n",
    "import Pkg\n",
    "pkgs = [\n",
    "    \"Revise\",\n",
    "    \"FASTX\",\n",
    "    \"BioSequences\",\n",
    "    \"Kmers\",\n",
    "    \"Graphs\",\n",
    "    \"MetaGraphs\",\n",
    "    \"SparseArrays\",\n",
    "    \"ProgressMeter\",\n",
    "    \"Distributions\",\n",
    "    \"HiddenMarkovModels\",\n",
    "    \"BioAlignments\",\n",
    "    \"StatsBase\",\n",
    "    \"Random\",\n",
    "    \"StatsPlots\",\n",
    "    \"Statistics\",\n",
    "    # \"GraphMakie\",\n",
    "    \"IterTools\",\n",
    "    \"Primes\",\n",
    "    \"OnlineStats\",\n",
    "    \"IteratorSampling\",\n",
    "    \"HypothesisTests\",\n",
    "    \"Clustering\",\n",
    "    \"Distances\",\n",
    "    \"BioAlignments\",\n",
    "    \"Statistics\"\n",
    "]\n",
    "# Pkg.add(pkgs)\n",
    "for pkg in pkgs\n",
    "    eval(Meta.parse(\"import $pkg\"))\n",
    "end\n",
    "# Pkg.develop(path=\"/global/cfs/projectdirs/m4269/cjprybol/Mycelia\")\n",
    "# Pkg.develop(path=\"../../..\")\n",
    "import Mycelia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128cc1e1-929a-42e1-8376-4c81832fd40c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_BASEDIR = dirname(pwd())\n",
    "data_dir = joinpath(PROJECT_BASEDIR, \"data\")\n",
    "genome_dir = mkpath(joinpath(data_dir, \"genomes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00736937-92d0-4cb6-a933-0cb068457ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "working_dir = joinpath(data_dir, \"test\")\n",
    "mkpath(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e294dc9-dc3d-4a15-8e15-70e649200874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# short_read_sets = unique(map(x -> match(r\"^(.+\\.\\d+x)\\.\", x).captures[1], filter(x -> occursin(r\"\\.fna\\.art\", x) && occursin(r\"\\.fq\\.gz\", x) && !occursin(\"trimming_report\", x) && !occursin(\"_val_\", x), sort(readdir(genome_dir, join=true), by=x->filesize(x)))))\n",
    "# # forward = short_read_set * \".1_val_1.fq.gz\"\n",
    "# # reverse = short_read_set * \".2_val_2.fq.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab3b27-b540-4f4d-8bd3-093e58e0304d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "long_read_fastqs = sort(filter(x -> occursin(r\"\\.filtlong\\.fq\\.gz$\", x), readdir(genome_dir, join=true)), by=x->filesize(x))\n",
    "fastq = long_read_fastqs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de34fec-79aa-419f-a1a1-dd7dfe664a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_fasta = replace(fastq, r\"\\.badread.*\" => \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579257eb-0de0-49a8-9381-d8938a806165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assembly_k = Mycelia.assess_dnamer_saturation([fastq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f13336-f70e-4df7-9aaa-2d6388eee430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kmer_type = Kmers.DNAKmer{assembly_k, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063d332-0f41-41d2-85b8-dd61b512c5b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_kmer_counts = Mycelia.fasta_to_reference_kmer_counts(kmer_type=kmer_type, fasta=reference_fasta)\n",
    "records = collect(Mycelia.open_fastx(fastq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f9c7a-5fca-4933-bd7f-b3a2bd6d5b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_mean = OnlineStats.fit!(OnlineStats.Mean(), IterTools.chain(FASTX.quality_scores(record) for record in records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5a57d-57e5-4318-8951-a3b08f72695e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_extrema = OnlineStats.fit!(OnlineStats.Extrema(), IterTools.chain(FASTX.quality_scores(record) for record in records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8c62a-c482-43d9-b239-1a9c76151e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_variance = OnlineStats.fit!(OnlineStats.Variance(), IterTools.chain(FASTX.quality_scores(record) for record in records))\n",
    "standard_deviation = sqrt(OnlineStats.value(fit_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb7d9e-ea7e-44df-91a4-974879739076",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using FASTX\n",
    "using Base.Threads\n",
    "using CSV\n",
    "using DataFrames\n",
    "\n",
    "# need to run samtools fqidx first!!!!",
    "\n",
    "println(\"Reading read FASTQ Index for preallocating dictionary size.\")\n",
    "fastq_index = string(fastq, \".fai\")\n",
    "total_records = CSV.read(fastq_index, DataFrame;delim='\\t', header=false, types=[String, Int64, Int64, Int64, Int64, Int64])\n",
    "total_records = length(total_records.Column1)\n",
    "\n",
    "# read_quality_scores = [collect(FASTX.quality_scores(record)) for record in records]\n",
    "\n",
    "# make a dictionary associating all kmers with their quality scores\n",
    "all_kmer_quality_support = Dict{kmer_type, Vector{Float64}}()\n",
    "\n",
    "reader = open(FASTQ.Reader, fastq)\n",
    "record = FASTQ.Record()\n",
    "counter = Atomic{Int}(0)\n",
    "reader_lock = ReentrantLock()\n",
    "record_quality_scores_lock = ReentrantLock()\n",
    "record_quality_scores_slices_lock = ReentrantLock()\n",
    "sequence_lock = ReentrantLock()\n",
    "all_kmer_quality_support_lock = ReentrantLock()\n",
    "\n",
    "println(\"Reading read FASTQ records for adding quality values and k-mers.\")\n",
    "Threads.@threads for i in 1:total_records\n",
    "    local_record = FASTQ.Record()\n",
    "    lock(reader_lock)\n",
    "    read!(reader, local_record)\n",
    "    unlock(reader_lock)\n",
    "    lock(record_quality_scores_lock)\n",
    "    record_quality_scores = collect(FASTX.quality_scores(local_record))\n",
    "    unlock(record_quality_scores_lock)\n",
    "    lock(record_quality_scores_slices_lock)\n",
    "    record_quality_score_slices = [record_quality_scores[i:i+assembly_k-1] for i in 1:length(record_quality_scores)-assembly_k+1]\n",
    "    unlock(record_quality_scores_slices_lock)\n",
    "    lock(sequence_lock)\n",
    "    sequence = BioSequences.LongDNA{2}(FASTX.sequence(local_record))\n",
    "    unlock(sequence_lock)\n",
    "    for ((i, kmer), kmer_base_qualities) in zip(Kmers.EveryKmer{kmer_type}(sequence), record_quality_score_slices)\n",
    "       if haskey(all_kmer_quality_support, kmer)\n",
    "           lock(all_kmer_quality_support_lock)\n",
    "           all_kmer_quality_support[kmer] = all_kmer_quality_support[kmer] .+ kmer_base_qualities\n",
    "           unlock(all_kmer_quality_support_lock)\n",
    "           else\n",
    "           lock(all_kmer_quality_support_lock)\n",
    "           all_kmer_quality_support[kmer] = kmer_base_qualities\n",
    "           unlock(all_kmer_quality_support_lock)\n",
    "       end\n",
    "    end\n",
    "    atomic_add!(counter, 1)\n",
    "    print(\"\\rRead $(counter[]) FASTQ records.\")\n",
    "    flush(stdout)\n",
    "end\n",
    "close(reader)\n",
    "\n",
    "\n",
    "kmer_counts = Mycelia.count_kmers(kmer_type, fastq)\n",
    "kmer_indices = Dict(kmer => i for (i, kmer) in enumerate(keys(kmer_counts)))\n",
    "canonical_kmer_counts = Mycelia.count_canonical_kmers(kmer_type, fastq)\n",
    "canonical_kmer_indices = Dict(kmer => i for (i, kmer) in enumerate(keys(canonical_kmer_counts)))\n",
    "# reference_kmers = sort(collect(keys(reference_kmer_counts)))\n",
    "\n",
    "strand_normalized_quality_support = Dict{kmer_type, Vector{Float64}}()\n",
    "for (kmer, support) in all_kmer_quality_support\n",
    "    strand_normalized_quality_support[kmer] = support\n",
    "    if haskey(all_kmer_quality_support, BioSequences.reverse_complement(kmer))\n",
    "        strand_normalized_quality_support[kmer] .+= all_kmer_quality_support[BioSequences.reverse_complement(kmer)]\n",
    "    end\n",
    "end\n",
    "strand_normalized_quality_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf91e09-a197-47f9-a87d-d3554cb5bbd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordered_kmers = collect(keys(kmer_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaaced0-d9fe-4fc3-8d67-ccd20f8f6b57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kmer_mean_quality = Dict(kmer => strand_normalized_quality_support[kmer] ./ canonical_kmer_counts[BioSequences.canonical(kmer)] for kmer in ordered_kmers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c82410-f0e6-4c29-b392-74d2340fa87d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# strand_normalized_quality_support "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699564fd-a050-415c-b540-5c493b89fb84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kmer_total_quality = Dict(kmer => sum(quality_values) for (kmer, quality_values) in strand_normalized_quality_support)\n",
    "# state_likelihoods = Dict(kmer => kmer_count / total_kmers for (kmer, kmer_count) in kmer_counts)\n",
    "\n",
    "\n",
    "function calculate_state_likelihoods(kmer_total_quality)\n",
    "    state_likelihoods = Dict{eltype(keys(kmer_total_quality)), Float64}()\n",
    "    total_sum = sum(values(kmer_total_quality))\n",
    "    counter = Atomic{Int}(0)\n",
    "    lock1 = ReentrantLock()\n",
    "    \n",
    "    kmer_total_quality_array = collect(kmer_total_quality)\n",
    "    \n",
    "    Threads.@threads for (kmer, total_quality) in kmer_total_quality_array\n",
    "        likelihood = total_quality / total_sum\n",
    "        lock(lock1)\n",
    "        state_likelihoods[kmer] = likelihood\n",
    "        unlock(lock1)\n",
    "        atomic_add!(counter, 1)\n",
    "        print(\"\\rRead $(counter[]) records out of $(length(kmer_total_quality)).\")\n",
    "        flush(stdout)\n",
    "    end\n",
    "    \n",
    "    return state_likelihoods\n",
    "end\n",
    "\n",
    "state_likelihoods = calculate_state_likelihoods(kmer_total_quality)\n",
    "\n",
    "\n",
    "# state_likelihoods = Dict(kmer => total_quality / sum(values(kmer_total_quality)) for (kmer, total_quality) in kmer_total_quality)\n",
    "\n",
    "total_states = length(state_likelihoods)\n",
    "\n",
    "transition_likelihoods = SparseArrays.spzeros(total_states, total_states)\n",
    "\n",
    "\n",
    "reader = open(FASTQ.Reader, fastq)\n",
    "record = FASTQ.Record()\n",
    "counter = Atomic{Int}(0)\n",
    "reader_lock = ReentrantLock()\n",
    "sequence_lock = ReentrantLock()\n",
    "sources_lock = ReentrantLock()\n",
    "destinations_lock = ReentrantLock()\n",
    "source_index_lock = ReentrantLock()\n",
    "destination_index_lock = ReentrantLock()\n",
    "transition_likelihoods_lock = ReentrantLock()\n",
    "\n",
    "Threads.@threads for i in 1:total_records\n",
    "    local_record = FASTQ.Record()\n",
    "    lock(reader_lock)\n",
    "    read!(reader, local_record)\n",
    "    unlock(reader_lock)\n",
    "    lock(sequence_lock)\n",
    "    sequence = BioSequences.LongDNA{4}(FASTX.sequence(local_record))\n",
    "    unlock(sequence_lock)\n",
    "    lock(sources_lock)\n",
    "    sources = Kmers.EveryKmer{kmer_type}(sequence[1:end-1])\n",
    "    unlock(sources_lock)\n",
    "    lock(destinations_lock)\n",
    "    destinations = Kmers.EveryKmer{kmer_type}(sequence[2:end])\n",
    "    unlock(destinations_lock)\n",
    "    for ((source_i, source), (destination_i, destination)) in zip(sources, destinations)\n",
    "        lock(source_index_lock)\n",
    "        source_index = kmer_indices[source]\n",
    "        unlock(source_index_lock)\n",
    "        lock(destination_index_lock)\n",
    "        destination_index = kmer_indices[destination]\n",
    "        unlock(destination_index_lock)\n",
    "        lock(transition_likelihoods_lock)\n",
    "        transition_likelihoods[source_index, destination_index] += 1\n",
    "        unlock(transition_likelihoods_lock)\n",
    "    end\n",
    "    atomic_add!(counter, 1)\n",
    "    print(\"\\rRead $(counter[]) FASTQ records.\")\n",
    "    flush(stdout)\n",
    "end\n",
    "close(reader)\n",
    "\n",
    "\n",
    "outgoing_transition_counts_lock = ReentrantLock()\n",
    "transition_likelihoods_lock2 = ReentrantLock()\n",
    "counter = Atomic{Int}(0)\n",
    "\n",
    "Threads.@threads for source in 1:total_states\n",
    "    lock(outgoing_transition_counts_lock)\n",
    "    outgoing_transition_counts = transition_likelihoods[source, :]\n",
    "    unlock(outgoing_transition_counts_lock)\n",
    "    if sum(outgoing_transition_counts) > 0\n",
    "        lock(transition_likelihoods_lock2)\n",
    "        transition_likelihoods[source, :] .= transition_likelihoods[source, :] ./ sum(transition_likelihoods[source, :]) \n",
    "        unlock(transition_likelihoods_lock2)\n",
    "    end\n",
    "    atomic_add!(counter, 1)\n",
    "    print(\"\\rRead $(counter[]) states of $total_states.\")\n",
    "    flush(stdout)\n",
    "end\n",
    "\n",
    "g = Graphs.SimpleDiGraph(total_states)\n",
    "row_indices, column_indices, cell_values = SparseArrays.findnz(transition_likelihoods)\n",
    "for (row, col) in zip(row_indices, column_indices)\n",
    "    Graphs.add_edge!(g, row, col)\n",
    "end\n",
    "g\n",
    "\n",
    "unbranching_nodes = Set(Int[])\n",
    "for node in Graphs.vertices(g)\n",
    "    if (Graphs.indegree(g, node) <= 1) && (Graphs.outdegree(g, node) <= 1)\n",
    "        push!(unbranching_nodes, node)\n",
    "    end\n",
    "end\n",
    "branching_nodes = setdiff(Graphs.vertices(g), unbranching_nodes)\n",
    "branching_nodes_set = Set(branching_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f6f4c-f749-4889-8b3b-323d281b37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_strand_normalized_quality_support = sum.(collect(values(strand_normalized_quality_support)))\n",
    "# minimum_average = min(Statistics.mean(total_strand_normalized_quality_support), Statistics.median(total_strand_normalized_quality_support))\n",
    "mean_total_support = Statistics.mean(total_strand_normalized_quality_support)\n",
    "Statistics.std(total_strand_normalized_quality_support)\n",
    "test_is_single_distribution = HypothesisTests.ExactOneSampleKSTest(total_strand_normalized_quality_support, Distributions.Normal())\n",
    "if HypothesisTests.pvalue(test_is_single_distribution) < 1e-3\n",
    "    @show \"p = $(HypothesisTests.pvalue(test_is_single_distribution)) rejecting error-free hypothesis & entering error correction\"\n",
    "else\n",
    "    @show \"single distribution detected, this data may be error-free\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3c8ec4-9f3a-4270-a6f9-740d5db79d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_kmer_total_quality = sort(kmer_total_quality)\n",
    "sorted_kmer_total_quality_values = collect(values(sorted_kmer_total_quality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476f8e1-4e6b-4fc6-88ae-120d39c28d50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BEING FLAGGED DOESN'T AUTOMATICALLY MEAN THAT WE WILL DROP IT, IT JUST MEANS THAT WE WILL ATTEMPT TO RESAMPLE IT\n",
    "clustering_k = 2\n",
    "clustering_result = Clustering.kmeans(permutedims(sorted_kmer_total_quality_values), clustering_k)\n",
    "\n",
    "assignments = Clustering.assignments(clustering_result)\n",
    "centroids = clustering_result.centers\n",
    "\n",
    "# println(\"Cluster assignments: \", assignments)\n",
    "# println(\"Cluster centroids: \", centroids)\n",
    "min_cluster_result = findmin(centroids)\n",
    "smaller_cluster = last(last(min_cluster_result).I)\n",
    "\n",
    "ys = [Float64[] for i in 1:clustering_k]\n",
    "xs = [Int[] for i in 1:clustering_k]\n",
    "for (i, (assignment, value)) in enumerate(zip(assignments, sorted_kmer_total_quality_values))\n",
    "    # if assignment == 1\n",
    "    push!(ys[assignment], value)\n",
    "    push!(xs[assignment], i)\n",
    "end\n",
    "# group_values\n",
    "label = smaller_cluster == 1 ? [\"likely sequencing artifacts\" \"likely valid kmers\"] : [\"likely valid kmers\" \"likely sequencing artifacts\"]\n",
    "\n",
    "StatsPlots.scatter(\n",
    "    xs,\n",
    "    ys,\n",
    "    title = \"kmeans error separation\",\n",
    "    ylabel = \"canonical kmer cumulative QUAL value\",\n",
    "    label = label,\n",
    "    legend = :outertopright,\n",
    "    size = (900, 500),\n",
    "    margins=10StatsPlots.Plots.PlotMeasures.mm,\n",
    "    xticks = false\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd00400-b46a-410e-8367-ecdbbc338f5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "likely_sequencing_artifact_indices = xs[smaller_cluster]\n",
    "likely_sequencing_artifact_kmers = Set(ordered_kmers[likely_sequencing_artifact_indices])\n",
    "likely_valid_kmer_indices = xs[first(setdiff([1, 2], smaller_cluster))]\n",
    "likely_valid_kmers = Set(ordered_kmers[likely_valid_kmer_indices])\n",
    "kmer_to_index_map = Dict(kmer => i for (i, kmer) in enumerate(ordered_kmers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e634e7-f49e-4827-a6ac-c0926dc4e4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function find_resampling_stretches(;record_kmer_solidity, solid_branching_kmer_indices)\n",
    "    indices = findall(.!record_kmer_solidity)  # Find the indices of false values\n",
    "    if isempty(indices)\n",
    "        return []\n",
    "    end\n",
    "    \n",
    "    diffs = diff(indices)  # Calculate the differences between consecutive indices\n",
    "    range_starts = [indices[1]]  # Start with the first false index\n",
    "    range_ends = Int[]\n",
    "    \n",
    "    for (i, d) in enumerate(diffs)\n",
    "        if d > 1\n",
    "            push!(range_ends, indices[i])\n",
    "            push!(range_starts, indices[i+1])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    push!(range_ends, indices[end])  # Add the last false index as a range end\n",
    "    \n",
    "    low_quality_runs = [(start, stop) for (start, stop) in zip(range_starts, range_ends)]\n",
    "    \n",
    "    resampling_stretches = UnitRange{Int64}[]\n",
    "    \n",
    "    for low_quality_run in low_quality_runs\n",
    "        nearest_under = maximum(filter(solid_branching_kmer -> solid_branching_kmer < first(low_quality_run), solid_branching_kmer_indices))\n",
    "        nearest_over = minimum(filter(solid_branching_kmer -> solid_branching_kmer > last(low_quality_run), solid_branching_kmer_indices))\n",
    "        push!(resampling_stretches, nearest_under:nearest_over)\n",
    "    end\n",
    "    if !allunique(resampling_stretches)\n",
    "        resampling_stretches = unique!(resampling_stretches)\n",
    "    end\n",
    "    return resampling_stretches\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2205674-1d60-46e7-97fa-d56f343052de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function process_fastq_record(;record, likely_valid_kmers, kmer_to_index_map, branching_nodes_set, assembly_k, transition_likelihoods, kmer_mean_quality, yen_k_shortest_paths_and_weights, yen_k=7)\n",
    "    new_record_identifier = FASTX.identifier(record) * \".k$(assembly_k)\"\n",
    "    record_sequence = BioSequences.LongDNA{4}(FASTX.sequence(record))\n",
    "    record_kmers = last.(collect(Kmers.EveryKmer{kmer_type}(record_sequence)))\n",
    "    record_quality_scores = collect(FASTX.quality_scores(record))\n",
    "    record_kmer_quality_scores = [record_quality_scores[i:i+assembly_k-1] for i in 1:length(record_quality_scores)-assembly_k+1]\n",
    "    \n",
    "    record_kmer_solidity = map(kmer -> kmer in likely_valid_kmers, record_kmers)\n",
    "    record_branching_kmers = [kmer_to_index_map[kmer] in branching_nodes_set for kmer in record_kmers]\n",
    "    record_solid_branching_kmers = record_kmer_solidity .& record_branching_kmers\n",
    "    \n",
    "    # trim beginning of fastq\n",
    "    initial_solid_kmer = findfirst(record_kmer_solidity)\n",
    "    if initial_solid_kmer > 1\n",
    "        record_kmers = record_kmers[initial_solid_kmer:end]\n",
    "        record_kmer_quality_scores = record_kmer_quality_scores[initial_solid_kmer:end]\n",
    "        record_kmer_solidity = map(kmer -> kmer in likely_valid_kmers, record_kmers)\n",
    "        record_branching_kmers = [kmer_to_index_map[kmer] in branching_nodes_set for kmer in record_kmers]\n",
    "        record_solid_branching_kmers = record_kmer_solidity .& record_branching_kmers\n",
    "    end\n",
    "    initial_solid_kmer = 1\n",
    "    \n",
    "    # trim end of fastq\n",
    "    last_solid_kmer = findlast(record_kmer_solidity)\n",
    "    if last_solid_kmer != length(record_kmer_solidity)\n",
    "        record_kmers = record_kmers[1:last_solid_kmer]\n",
    "        record_kmer_quality_scores = record_kmer_quality_scores[1:last_solid_kmer]\n",
    "        record_kmer_solidity = map(kmer -> kmer in likely_valid_kmers, record_kmers)\n",
    "        record_branching_kmers = [kmer_to_index_map[kmer] in branching_nodes_set for kmer in record_kmers]\n",
    "        record_solid_branching_kmers = record_kmer_solidity .& record_branching_kmers\n",
    "    end\n",
    "    \n",
    "    # identify low quality runs and the solid branchpoints we will use for resampling\n",
    "    # low_quality_runs = find_false_ranges(record_kmer_solidity)\n",
    "    solid_branching_kmer_indices = findall(record_solid_branching_kmers)\n",
    "    resampling_stretches = find_resampling_stretches(;record_kmer_solidity, solid_branching_kmer_indices)\n",
    "\n",
    "    trusted_range = 1:max(first(first(resampling_stretches))-1, 1)\n",
    "    \n",
    "    new_record_kmers = record_kmers[trusted_range]\n",
    "    new_record_kmer_qualities = record_kmer_quality_scores[trusted_range]\n",
    "    \n",
    "    \n",
    "    for (i, resampling_stretch) in enumerate(resampling_stretches)\n",
    "        starting_solid_kmer = record_kmers[first(resampling_stretch)]\n",
    "        ending_solid_kmer = record_kmers[last(resampling_stretch)]\n",
    "        \n",
    "        current_quality_scores = record_quality_scores[resampling_stretch]\n",
    "        u = kmer_to_index_map[starting_solid_kmer]\n",
    "        v = kmer_to_index_map[ending_solid_kmer]\n",
    "        if !haskey(yen_k_shortest_paths_and_weights, u => v)\n",
    "            yen_k_result = Graphs.yen_k_shortest_paths(g, u, v, Graphs.weights(g), yen_k)\n",
    "            yen_k_shortest_paths_and_weights[u => v] = Vector{Pair{Vector{Int}, Float64}}()\n",
    "            for path in yen_k_result.paths\n",
    "                path_weight = Statistics.mean([kmer_total_quality[ordered_kmers[node]] for node in path])\n",
    "                path_transition_likelihoods = 1.0\n",
    "                for (a, b) in zip(path[1:end-1], path[2:end])\n",
    "                    path_transition_likelihoods *= transition_likelihoods[a, b]\n",
    "                end\n",
    "                joint_weight = path_weight * path_transition_likelihoods\n",
    "                push!(yen_k_shortest_paths_and_weights[u => v], path => joint_weight)\n",
    "            end\n",
    "        end\n",
    "        yen_k_path_weights = yen_k_shortest_paths_and_weights[u => v]      \n",
    "        if length(yen_k_path_weights) > 1\n",
    "            current_distance = length(resampling_stretch)\n",
    "            initial_weights = last.(yen_k_path_weights)\n",
    "            path_lengths = length.(first.(yen_k_path_weights))\n",
    "            deltas = map(l -> abs(l-current_distance), path_lengths)\n",
    "            adjusted_weights = initial_weights .* map(d -> exp(-d * log(2)), deltas)\n",
    "            \n",
    "            # and a bonus for usually being correct\n",
    "            \n",
    "            selected_path_index = StatsBase.sample(StatsBase.weights(adjusted_weights))\n",
    "            selected_path, selected_path_weights = yen_k_path_weights[selected_path_index]\n",
    "            selected_path_kmers = [ordered_kmers[kmer_index] for kmer_index in selected_path]\n",
    "            \n",
    "            if last(new_record_kmers) == first(selected_path_kmers)\n",
    "                selected_path_kmers = selected_path_kmers[2:end]\n",
    "            end\n",
    "            append!(new_record_kmers, selected_path_kmers)\n",
    "            selected_kmer_qualities = [Int8.(floor.(kmer_mean_quality[kmer])) for kmer in selected_path_kmers]\n",
    "            append!(new_record_kmer_qualities, selected_kmer_qualities)\n",
    "        else\n",
    "            selected_path_kmers = record_kmers[resampling_stretch]\n",
    "            if last(new_record_kmers) == first(selected_path_kmers)\n",
    "                selected_path_kmers = selected_path_kmers[2:end]\n",
    "            end\n",
    "            append!(new_record_kmers, selected_path_kmers)\n",
    "            selected_kmer_qualities = [Int8.(floor.(kmer_mean_quality[kmer])) for kmer in selected_path_kmers]\n",
    "            append!(new_record_kmer_qualities, selected_kmer_qualities)\n",
    "        end\n",
    "        if i < length(resampling_stretches) # append high quality gap\n",
    "            next_solid_start = last(resampling_stretch)+1\n",
    "            next_resampling_stretch = resampling_stretches[i+1]\n",
    "            next_solid_stop = first(next_resampling_stretch)-1\n",
    "            if !isempty(next_solid_start:next_solid_stop)\n",
    "                selected_path_kmers = record_kmers[next_solid_start:next_solid_stop]\n",
    "                append!(new_record_kmers, selected_path_kmers)\n",
    "                selected_kmer_qualities = record_kmer_quality_scores[next_solid_start:next_solid_stop]\n",
    "                append!(new_record_kmer_qualities, selected_kmer_qualities)\n",
    "            end\n",
    "        else # append remainder of sequence\n",
    "            @assert i == length(resampling_stretches)\n",
    "            next_solid_start = last(resampling_stretch)+1\n",
    "            if next_solid_start < length(record_kmers)\n",
    "                selected_path_kmers = record_kmers[next_solid_start:end]\n",
    "                append!(new_record_kmers, selected_path_kmers)\n",
    "                selected_kmer_qualities = record_kmer_quality_scores[next_solid_start:end]\n",
    "                append!(new_record_kmer_qualities, selected_kmer_qualities)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    for (a, b) in zip(new_record_kmers[1:end-1], new_record_kmers[2:end])\n",
    "        @assert a != b\n",
    "    end\n",
    "    new_record_sequence = Mycelia.kmer_path_to_sequence(new_record_kmers)\n",
    "    new_record_quality_scores = new_record_kmer_qualities[1]\n",
    "    for new_record_kmer_quality in new_record_kmer_qualities[2:end]\n",
    "        push!(new_record_quality_scores, last(new_record_kmer_quality))\n",
    "    end\n",
    "    # Fastx wont parse anything higher than 93\n",
    "    new_record_quality_scores = min.(new_record_quality_scores, 93)\n",
    "    # @show length(new_record_sequence) length(new_record_quality_scores)\n",
    "    new_record_string = join([\"@\" * new_record_identifier, new_record_sequence, \"+\", join([Char(x+33) for x in new_record_quality_scores])], \"\\n\")\n",
    "    # @show new_record_string\n",
    "    new_record = FASTX.parse(FASTX.FASTQRecord, new_record_string)\n",
    "    @assert FASTX.sequence(new_record) == string(new_record_sequence)\n",
    "    @assert collect(FASTX.quality_scores(new_record)) == new_record_quality_scores\n",
    "    # BioAlignments.pairalign(BioAlignments.LevenshteinDistance(), FASTX.sequence(record), FASTX.sequence(new_record))\n",
    "    return new_record\n",
    "end\n",
    "\n",
    "# 2:24 renewing yenk weights each time\n",
    "# 2:22 sharing yenk weights\n",
    "ProgressMeter.@showprogress for record in records\n",
    "    yen_k_shortest_paths_and_weights = Dict{Pair{Int, Int}, Vector{Pair{Vector{Int}, Float64}}}()\n",
    "    revised_record = process_fastq_record(;record, likely_valid_kmers, kmer_to_index_map, branching_nodes_set, assembly_k, kmer_mean_quality, transition_likelihoods, yen_k_shortest_paths_and_weights)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0ac1b-2586-4fdb-8fa5-8d8667e1798a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish updating all reads for all k rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b33ac5-5611-4e4b-a97b-0cfcaac49fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out final assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b530abc-7146-4439-872f-12f4aca53ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f38987-1550-4fee-bd1d-135dedc4ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
