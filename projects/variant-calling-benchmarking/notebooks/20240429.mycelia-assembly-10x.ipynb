{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335bf35f-c55e-4857-83f0-ed03dc666f4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if hit plotting library issues, try resetting LD path for julia\n",
    "# can set in ~/.local/share/jupyter/kernels/\n",
    "haskey(ENV, \"LD_LIBRARY_PATH\") && @assert ENV[\"LD_LIBRARY_PATH\"] == \"\"\n",
    "import Pkg\n",
    "pkgs = [\n",
    "    \"Revise\",\n",
    "    \"FASTX\",\n",
    "    \"BioSequences\",\n",
    "    \"Kmers\",\n",
    "    \"Graphs\",\n",
    "    \"MetaGraphs\",\n",
    "    \"SparseArrays\",\n",
    "    \"ProgressMeter\",\n",
    "    \"Distributions\",\n",
    "    \"HiddenMarkovModels\",\n",
    "    \"BioAlignments\",\n",
    "    \"StatsBase\",\n",
    "    \"Random\",\n",
    "    \"StatsPlots\",\n",
    "    \"Statistics\",\n",
    "    # \"GraphMakie\",\n",
    "    \"IterTools\",\n",
    "    \"Primes\",\n",
    "    \"OnlineStats\",\n",
    "    \"IteratorSampling\",\n",
    "    \"HypothesisTests\",\n",
    "    \"Clustering\",\n",
    "    \"Distances\"\n",
    "]\n",
    "# Pkg.add(pkgs)\n",
    "for pkg in pkgs\n",
    "    eval(Meta.parse(\"import $pkg\"))\n",
    "end\n",
    "# Pkg.develop(path=\"/global/cfs/projectdirs/m4269/cjprybol/Mycelia\")\n",
    "# Pkg.develop(path=\"../../..\")\n",
    "import Mycelia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128cc1e1-929a-42e1-8376-4c81832fd40c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_BASEDIR = dirname(pwd())\n",
    "data_dir = joinpath(PROJECT_BASEDIR, \"data\")\n",
    "genome_dir = mkpath(joinpath(data_dir, \"genomes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00736937-92d0-4cb6-a933-0cb068457ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "working_dir = joinpath(data_dir, \"test\")\n",
    "mkpath(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e294dc9-dc3d-4a15-8e15-70e649200874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# short_read_sets = unique(map(x -> match(r\"^(.+\\.\\d+x)\\.\", x).captures[1], filter(x -> occursin(r\"\\.fna\\.art\", x) && occursin(r\"\\.fq\\.gz\", x) && !occursin(\"trimming_report\", x) && !occursin(\"_val_\", x), sort(readdir(genome_dir, join=true), by=x->filesize(x)))))\n",
    "# # forward = short_read_set * \".1_val_1.fq.gz\"\n",
    "# # reverse = short_read_set * \".2_val_2.fq.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab3b27-b540-4f4d-8bd3-093e58e0304d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "long_read_fastqs = sort(filter(x -> occursin(r\"\\.filtlong\\.fq\\.gz$\", x), readdir(genome_dir, join=true)), by=x->filesize(x))\n",
    "fastq = long_read_fastqs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de34fec-79aa-419f-a1a1-dd7dfe664a7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_fasta = replace(fastq, r\"\\.badread.*\" => \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579257eb-0de0-49a8-9381-d8938a806165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = Mycelia.assess_dnamer_saturation([fastq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f13336-f70e-4df7-9aaa-2d6388eee430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kmer_type = Kmers.DNAKmer{k, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063d332-0f41-41d2-85b8-dd61b512c5b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_kmer_counts = Mycelia.fasta_to_reference_kmer_counts(kmer_type=kmer_type, fasta=reference_fasta)\n",
    "records = collect(Mycelia.open_fastx(fastq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279f9c7a-5fca-4933-bd7f-b3a2bd6d5b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_mean = OnlineStats.fit!(OnlineStats.Mean(), IterTools.chain(FASTX.quality_scores(record) for record in records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5a57d-57e5-4318-8951-a3b08f72695e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_extrema = OnlineStats.fit!(OnlineStats.Extrema(), IterTools.chain(FASTX.quality_scores(record) for record in records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8c62a-c482-43d9-b239-1a9c76151e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_variance = OnlineStats.fit!(OnlineStats.Variance(), IterTools.chain(FASTX.quality_scores(record) for record in records))\n",
    "standard_deviation = sqrt(OnlineStats.value(fit_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699564fd-a050-415c-b540-5c493b89fb84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "read_quality_scores = [collect(FASTX.quality_scores(record)) for record in records]\n",
    "\n",
    "# make a dictionary associating all kmers with their quality scores\n",
    "all_kmer_quality_support = Dict{kmer_type, Vector{Float64}}()\n",
    "for record in records\n",
    "    record_quality_scores = collect(FASTX.quality_scores(record))\n",
    "    record_quality_score_slices = [record_quality_scores[i:i+k-1] for i in 1:length(record_quality_scores)-k+1]\n",
    "    sequence = BioSequences.LongDNA{2}(FASTX.sequence(record))\n",
    "    for ((i, kmer), kmer_base_qualities) in zip(Kmers.EveryKmer{kmer_type}(sequence), record_quality_score_slices)\n",
    "        if haskey(all_kmer_quality_support, kmer)\n",
    "            all_kmer_quality_support[kmer] = all_kmer_quality_support[kmer] .+ kmer_base_qualities\n",
    "        else\n",
    "            all_kmer_quality_support[kmer] = kmer_base_qualities\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "kmer_counts = Mycelia.count_kmers(kmer_type, fastq)\n",
    "kmer_indices = Dict(kmer => i for (i, kmer) in enumerate(keys(kmer_counts)))\n",
    "canonical_kmer_counts = Mycelia.count_canonical_kmers(kmer_type, fastq)\n",
    "canonical_kmer_indices = Dict(kmer => i for (i, kmer) in enumerate(keys(canonical_kmer_counts)))\n",
    "reference_kmers = sort(collect(keys(reference_kmer_counts)))\n",
    "\n",
    "strand_normalized_quality_support = Dict{kmer_type, Vector{Float64}}()\n",
    "for (kmer, support) in all_kmer_quality_support\n",
    "    strand_normalized_quality_support[kmer] = support\n",
    "    if haskey(all_kmer_quality_support, BioSequences.reverse_complement(kmer))\n",
    "        strand_normalized_quality_support[kmer] .+= all_kmer_quality_support[BioSequences.reverse_complement(kmer)]\n",
    "    end\n",
    "end\n",
    "\n",
    "kmer_total_quality = Dict(kmer => sum(quality_values) for (kmer, quality_values) in strand_normalized_quality_support)\n",
    "# state_likelihoods = Dict(kmer => kmer_count / total_kmers for (kmer, kmer_count) in kmer_counts)\n",
    "state_likelihoods = Dict(kmer => total_quality / sum(values(kmer_total_quality)) for (kmer, total_quality) in kmer_total_quality)\n",
    "\n",
    "total_states = length(state_likelihoods)\n",
    "\n",
    "transition_likelihoods = SparseArrays.spzeros(total_states, total_states)\n",
    "for record in records\n",
    "    sequence = BioSequences.LongDNA{4}(FASTX.sequence(record))\n",
    "    sources = Kmers.EveryKmer{kmer_type}(sequence[1:end-1])\n",
    "    destinations = Kmers.EveryKmer{kmer_type}(sequence[2:end])\n",
    "    for ((source_i, source), (destination_i, destination)) in zip(sources, destinations)\n",
    "        source_index = kmer_indices[source]\n",
    "        destination_index = kmer_indices[destination]\n",
    "        transition_likelihoods[source_index, destination_index] += 1\n",
    "    end\n",
    "end\n",
    "for source in 1:total_states\n",
    "    # @show source\n",
    "    outgoing_transition_counts = transition_likelihoods[source, :]\n",
    "    if sum(outgoing_transition_counts) > 0\n",
    "        transition_likelihoods[source, :] .= transition_likelihoods[source, :] ./ sum(transition_likelihoods[source, :]) \n",
    "    end\n",
    "end\n",
    "transition_likelihoods\n",
    "\n",
    "g = Graphs.SimpleDiGraph(total_states)\n",
    "row_indices, column_indices, cell_values = SparseArrays.findnz(transition_likelihoods)\n",
    "for (row, col) in zip(row_indices, column_indices)\n",
    "    Graphs.add_edge!(g, row, col)\n",
    "end\n",
    "g\n",
    "\n",
    "unbranching_nodes = Set(Int[])\n",
    "for node in Graphs.vertices(g)\n",
    "    if (Graphs.indegree(g, node) <= 1) && (Graphs.outdegree(g, node) <= 1)\n",
    "        push!(unbranching_nodes, node)\n",
    "    end\n",
    "end\n",
    "branching_nodes = setdiff(Graphs.vertices(g), unbranching_nodes)\n",
    "branching_nodes_set = Set(branching_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f8853-00c7-4d47-8de8-29cf989ac3ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ordered_kmers = collect(keys(kmer_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f6f4c-f749-4889-8b3b-323d281b37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_strand_normalized_quality_support = sum.(collect(values(strand_normalized_quality_support)))\n",
    "# minimum_average = min(Statistics.mean(total_strand_normalized_quality_support), Statistics.median(total_strand_normalized_quality_support))\n",
    "mean_total_support = Statistics.mean(total_strand_normalized_quality_support)\n",
    "Statistics.std(total_strand_normalized_quality_support)\n",
    "test_is_single_distribution = HypothesisTests.ExactOneSampleKSTest(total_strand_normalized_quality_support, Distributions.Normal())\n",
    "if HypothesisTests.pvalue(test_is_single_distribution) < 1e-3\n",
    "    @show \"p = $(HypothesisTests.pvalue(test_is_single_distribution)) rejecting error-free hypothesis & entering error correction\"\n",
    "else\n",
    "    @show \"single distribution detected, this data may be error-free\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d14de17-d4d5-4be3-a678-17bced8610fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_kmer_total_quality = sort(kmer_total_quality)\n",
    "\n",
    "sorted_kmer_total_quality_values = collect(values(sorted_kmer_total_quality))\n",
    "\n",
    "# StatsPlots.scatter(collect(values(kmer_total_quality)))\n",
    "\n",
    "# BEING FLAGGED DOESN'T AUTOMATICALLY MEAN THAT WE WILL DROP IT, IT JUST MEANS THAT WE WILL ATTEMPT TO RESAMPLE IT\n",
    "\n",
    "k = 2\n",
    "results = Clustering.kmeans(permutedims(sorted_kmer_total_quality_values), k)\n",
    "\n",
    "assignments = Clustering.assignments(results)\n",
    "centroids = results.centers\n",
    "\n",
    "# println(\"Cluster assignments: \", assignments)\n",
    "println(\"Cluster centroids: \", centroids)\n",
    "min_cluster_result = findmin(centroids)\n",
    "smaller_cluster = last(last(min_cluster_result).I)\n",
    "\n",
    "ys = [Float64[] for i in 1:k]\n",
    "xs = [Int[] for i in 1:k]\n",
    "for (i, (assignment, value)) in enumerate(zip(assignments, sorted_kmer_total_quality_values))\n",
    "    # if assignment == 1\n",
    "    push!(ys[assignment], value)\n",
    "    push!(xs[assignment], i)\n",
    "end\n",
    "# group_values\n",
    "label = smaller_cluster == 1 ? [\"likely sequencing artifacts\" \"likely valid kmers\"] : [\"likely valid kmers\" \"likely sequencing artifacts\"]\n",
    "\n",
    "StatsPlots.scatter(\n",
    "    xs,\n",
    "    ys,\n",
    "    title = \"kmeans error separation\",\n",
    "    ylabel = \"canonical kmer cumulative QUAL value\",\n",
    "    label = label,\n",
    "    legend = :outertopright,\n",
    "    size = (900, 500),\n",
    "    margins=10StatsPlots.Plots.PlotMeasures.mm,\n",
    "    xticks = false\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd00400-b46a-410e-8367-ecdbbc338f5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "likely_sequencing_artifact_indices = xs[smaller_cluster]\n",
    "likely_sequencing_artifact_kmers = Set(ordered_kmers[likely_sequencing_artifact_indices])\n",
    "likely_valid_kmer_indices = xs[first(setdiff([1, 2], smaller_cluster))]\n",
    "likely_valid_kmers = Set(ordered_kmers[likely_valid_kmer_indices])\n",
    "kmer_to_index_map = Dict(kmer => i for (i, kmer) in enumerate(ordered_kmers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd471cd-ec86-403a-918b-4de249fd2a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "record = first(records)\n",
    "record_sequence = BioSequences.LongDNA{4}(FASTX.sequence(record))\n",
    "record_kmers = last.(collect(Kmers.EveryKmer{kmer_type}(record_sequence)))\n",
    "record_kmer_solidity = map(kmer -> kmer in likely_valid_kmers, record_kmers)\n",
    "record_branching_kmers = [kmer_to_index_map[kmer] in branching_nodes_set for kmer in record_kmers]\n",
    "record_solid_branching_kmers = record_kmer_solidity .& record_branching_kmers\n",
    "\n",
    "# initial_solid_kmer = findfirst(record_solid_branching_kmers)\n",
    "initial_solid_kmer = findfirst(record_kmer_solidity)\n",
    "# trim beginning\n",
    "if initial_solid_kmer > 1\n",
    "    record_kmers = record_kmers[initial_solid_kmer:end]\n",
    "    record_kmer_solidity = map(kmer -> kmer in likely_valid_kmers, record_kmers)\n",
    "    record_branching_kmers = [kmer_to_index_map[kmer] in branching_nodes_set for kmer in record_kmers]\n",
    "    record_solid_branching_kmers = record_kmer_solidity .& record_branching_kmers\n",
    "end\n",
    "initial_solid_kmer = 1\n",
    "# record_kmer_solidity\n",
    "\n",
    "# last_solid_kmer = findlast(record_solid_branching_kmers)\n",
    "last_solid_kmer = findlast(record_kmer_solidity)\n",
    "# trim end\n",
    "if last_solid_kmer != length(record_kmer_solidity)\n",
    "    record_kmers = record_kmers[1:last_solid_kmer]\n",
    "    record_kmer_solidity = map(kmer -> kmer in likely_valid_kmers, record_kmers)\n",
    "    record_branching_kmers = [kmer_to_index_map[kmer] in branching_nodes_set for kmer in record_kmers]\n",
    "    record_solid_branching_kmers = record_kmer_solidity .& record_branching_kmers\n",
    "end\n",
    "record_kmer_solidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1775d5-6a4f-438b-82a1-e9a45a7a1387",
   "metadata": {},
   "outputs": [],
   "source": [
    "function find_false_ranges(vec::Vector{Bool})\n",
    "    indices = findall(.!vec)  # Find the indices of false values\n",
    "    if isempty(indices)\n",
    "        return []\n",
    "    end\n",
    "    \n",
    "    diffs = diff(indices)  # Calculate the differences between consecutive indices\n",
    "    range_starts = [indices[1]]  # Start with the first false index\n",
    "    range_ends = Int[]\n",
    "    \n",
    "    for (i, d) in enumerate(diffs)\n",
    "        if d > 1\n",
    "            push!(range_ends, indices[i])\n",
    "            push!(range_starts, indices[i+1])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    push!(range_ends, indices[end])  # Add the last false index as a range end\n",
    "    \n",
    "    return [(start, stop) for (start, stop) in zip(range_starts, range_ends)]\n",
    "end\n",
    "\n",
    "low_quality_runs = find_false_ranges(record_kmer_solidity)\n",
    "solid_branching_kmer_indices = findall(record_solid_branching_kmers)\n",
    "YEN_K = 3\n",
    "yen_k_shortest_paths_and_weights = Dict{Pair{Int, Int}, Vector{Pair{Vector{Int}, Vector{Float64}}}}()\n",
    "for low_quality_run in low_quality_runs\n",
    "    unders = filter(solid_branching_kmer -> solid_branching_kmer < first(low_quality_run), solid_branching_kmer_indices)\n",
    "    overs = filter(solid_branching_kmer -> solid_branching_kmer > last(low_quality_run), solid_branching_kmer_indices)\n",
    "    nearest_under = maximum(unders)\n",
    "    nearest_over = minimum(overs)\n",
    "    \n",
    "    nearest_under_kmer = record_kmers[nearest_under]\n",
    "    nearest_over_kmer = record_kmers[nearest_over]\n",
    "    current_path = record_kmers[nearest_under:nearest_over]\n",
    "    u = kmer_to_index_map[nearest_under_kmer]\n",
    "    v = kmer_to_index_map[nearest_over_kmer]\n",
    "    if !haskey(yen_k_shortest_paths_and_weights, u => v)\n",
    "        yen_k_result = Graphs.yen_k_shortest_paths(g, u, v, Graphs.weights(g), YEN_K)\n",
    "        yen_k_shortest_paths_and_weights[u => v] = Vector{Pair{Vector{Int}, Float64}}()\n",
    "        for path in yen_k_result.paths\n",
    "            push!(yen_k_shortest_paths_and_weights[u => v], path => [kmer_total_quality[ordered_kmers[node]] for node in path])\n",
    "        end\n",
    "    end\n",
    "    yen_k_path_weights = yen_k_shortest_paths_and_weights[u => v]      \n",
    "    if length(yen_k_path_weights) > 1\n",
    "        current_distance = nearest_over - nearest_under\n",
    "        initial_weights = Statistics.mean.(last.(yen_k_path_weights))\n",
    "        path_lengths = length.(first.(yen_k_path_weights))\n",
    "        deltas = map(l -> abs(l-current_distance), path_lengths)\n",
    "        adjusted_weights = initial_weights .* map(d -> exp(-d * log(2)), deltas)\n",
    "        selected_path_index = StatsBase.sample(StatsBase.weights(adjusted_weights))\n",
    "        selected_path, selected_path_weights = yen_k_path_weights[selected_path_index]\n",
    "        selected_path_kmers = [ordered_kmers[kmer_index] for kmer_index in selected_path]\n",
    "        selected_path_kmer_counts = [canonical_kmer_counts[BioSequences.canonical(kmer)] for kmer in selected_path_kmers]\n",
    "        @show selected_path_average_quality_scores = min.([weight./count for (weight, count) in zip(selected_path_weights, selected_path_kmer_counts)] ./ k, 60.0)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de51817-cc24-43ea-9cd6-85c3155397cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rather than pre-computing all shortest paths between all pairs of nodes, which may require us to solve paths unecessarily\n",
    "# cache the results as we compute them so that we can avoid recomputing if we hit the same query multiple times\n",
    "# adding this as a hunch, may be worth bencharking to see if it's unecessary\n",
    "\n",
    "\n",
    "\n",
    "        # else\n",
    "        #     @info \"no alternate paths found\"\n",
    "        end\n",
    "        # \n",
    "        # if we only have our one path, keep it\n",
    "        # else, compare the relative weights of the paths and choose at random\n",
    "        # slice out the kmers we want to get rid of and put these in\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e340e31-cea5-4ec4-9461-a268654cbae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f630caa-7611-4a83-84d6-30b469adabd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# yen_state.dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d9419e-2ce8-4c50-b1a5-88d4b4d4005c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# yen_state.paths"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
