{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce23d7a1-3e01-467b-8a3b-3af4f2fa92a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert ENV[\"LD_LIBRARY_PATH\"] == \"\"\n",
    "import Pkg\n",
    "Pkg.activate(;temp=true)\n",
    "Pkg.add(\"Revise\")\n",
    "import Revise\n",
    "\n",
    "Pkg.develop(path=\"$(homedir())/workspace/Mycelia\")\n",
    "import Mycelia\n",
    "\n",
    "pkgs = String[\n",
    "    \"JSON\",\n",
    "    \"ProgressMeter\",\n",
    "    \"SHA\"\n",
    "]\n",
    "Pkg.add(pkgs)\n",
    "for pkg in pkgs\n",
    "    eval(Meta.parse(\"import $pkg\"))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457402c5-0c5a-4f91-880c-cc7ddad9b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = dirname(pwd())\n",
    "data_dir = mkpath(joinpath(project_dir, \"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e0eac0-e6ba-47fd-a39a-e0dcef40b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sra_dir = joinpath(data_dir, \"SRA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4333f5bd-0417-4403-9002-703a8fcd002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: List Existing Files on Google Drive\n",
    "\n",
    "# We assume you have rclone installed and configured.\n",
    "# Note: You'll need to have system calls to rclone. Ensure `rclone` is in your PATH.\n",
    "\n",
    "# Run the rclone command to list files from Google Drive\n",
    "drive_file = \"drive_file_list.json\"\n",
    "if !isfile(drive_file)\n",
    "    println(\"run me\")\n",
    "    # several minutes\n",
    "    @time run(pipeline(`/scg/apps/software/rclone/1.67.0/rclone lsjson --hash -R snyder-virome:viral-exposome/data/SRA`, drive_file))\n",
    "else\n",
    "    println(\"$(drive_file) already present\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b357d3-9554-4105-817c-7ab3c58f9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the JSON file\n",
    "# quick 160seconds\n",
    "@time gdrive_files = filter(gf -> gf[\"IsDir\"] == false, JSON.parsefile(drive_file))\n",
    "gdrive_files = convert(Vector{first(unique(typeof.(gdrive_files)))}, gdrive_files)\n",
    "gdrive_files = sort(gdrive_files, by=x->x[\"Size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b48ddf-2159-40ee-8450-1fe280835fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Printf\n",
    "# Function to format file sizes in a human-readable format\n",
    "function human_readable(size)\n",
    "    if size < 1024\n",
    "        return \"$size Bytes\"\n",
    "    elseif size < 1048576\n",
    "        return Printf.@sprintf(\"%.2f KiB\", size / 1024)\n",
    "    elseif size < 1073741824\n",
    "        return Printf.@sprintf(\"%.2f MiB\", size / 1048576)\n",
    "    else\n",
    "        return Printf.@sprintf(\"%.2f GiB\", size / 1073741824)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1acaa-f769-4b10-aeed-dc34f60160a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and remove local files that match Google Drive files\n",
    "local_dir = sra_dir\n",
    "\n",
    "# Initialize counters for total files removed and total disk space reclaimed\n",
    "total_files_removed = 0\n",
    "total_space_freed = 0\n",
    "\n",
    "# Total files removed: 3626\n",
    "# Total space freed: 327.15 GiB\n",
    "\n",
    "# current_stop = 131000\n",
    "current_stop = 140000\n",
    "# current_stop = next_stop\n",
    "next_start = current_stop + 1\n",
    "\n",
    "next_stop = next_start + 2^15\n",
    "next_stop = min(length(gdrive_files), next_stop)\n",
    "# next_stop = next_start + 2^10\n",
    "# 20 minutes in the later stages\n",
    "# next_stop = next_start + 2^12\n",
    "# next_stop = length(gdrive_files)\n",
    "# next_stop = 2^1\n",
    "println(\"current_stop = $(current_stop)\")\n",
    "println(\"next_start = $(next_start)\")\n",
    "println(\"next_stop = $(next_stop)\")\n",
    "\n",
    "ProgressMeter.@showprogress for gdrive_file in gdrive_files[next_start:next_stop]\n",
    "    file_path = gdrive_file[\"Path\"]\n",
    "    local_file_path = joinpath(local_dir, file_path)\n",
    "    local_size = filesize(local_file_path)\n",
    "    if isfile(local_file_path)\n",
    "        # Calculate local file size and hashes\n",
    "        size_match = (local_size == gdrive_file[\"Size\"])\n",
    "        # println()\n",
    "        println(\"file_size = $(human_readable(local_size))\" * \"\\t\" * \"file_path = $(file_path)\")\n",
    "        \n",
    "        # Compare sizes and hashes\n",
    "        if size_match\n",
    "            @time sha256 = SHA.bytes2hex(SHA.sha256(read(local_file_path)))\n",
    "            sha256_match = (sha256 == gdrive_file[\"Hashes\"][\"sha256\"])\n",
    "            if sha256_match\n",
    "                # Remove the local file\n",
    "                rm(local_file_path)\n",
    "                total_files_removed += 1\n",
    "                total_space_freed += local_size\n",
    "                # Print details\n",
    "                println(\"Removed file: $file_path\")\n",
    "                println(\"Freed: $(human_readable(local_size))\")\n",
    "            end\n",
    "        end\n",
    "    else\n",
    "        # println(\"$file_path has already been removed\")\n",
    "    end\n",
    "end\n",
    "println(\"Total files removed: $total_files_removed\")\n",
    "println(\"Total space freed: $(human_readable(total_space_freed))\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4db443-d6d2-4b91-8f56-cd9d7575bf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: List Local Files\n",
    "\n",
    "# Run the rclone command to list local files\n",
    "local_file = \"local_file_list.json\"\n",
    "# this seems much slower - probably because we're computing SHA256 on the fly whereas google drive just has it precomputed?\n",
    "@time run(pipeline(`/scg/apps/software/rclone/1.67.0/rclone lsjson --hash -R $(sra_dir)`, local_file))\n",
    "\n",
    "# time /scg/apps/software/rclone/1.67.0/rclone lsjson --hash -R /oak/stanford/scg/lab_mpsnyder/cjprybol/Mycelia/projects/viral-exposome/data/SRA > local_file_list.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64801351-3ef3-4275-aac3-432d125fb696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data from the JSON file\n",
    "@time local_files = load_json(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a09d7c6-71cc-4b9a-bc32-93606f72fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute File Diff Locally\n",
    "\n",
    "# Extract file paths and hashes from JSON data\n",
    "function get_file_details(file_list)\n",
    "    return Dict(file[\"Path\"] => (file[\"Size\"], file[\"Hashes\"][\"SHA-256\"]) for file in file_list)\n",
    "end\n",
    "\n",
    "# Get details of files\n",
    "local_file_details = get_file_details(local_files)\n",
    "gdrive_file_details = get_file_details(gdrive_files)\n",
    "\n",
    "# Determine the files that need to be uploaded\n",
    "files_to_upload = Set()\n",
    "for (file, (size, hash)) in local_file_details\n",
    "    if haskey(gdrive_file_details, file)\n",
    "        gdrivesize, gdriveshash = gdrive_file_details[file]\n",
    "        if size != gdrivesize || hash != gdriveshash\n",
    "            files_to_upload[file] = (size, hash)\n",
    "        end\n",
    "    else\n",
    "        files_to_upload[file] = (size, hash)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Optional: Write the list of files to upload to a file\n",
    "open(\"files_to_upload.txt\", \"w\") do f\n",
    "    for file in keys(files_to_upload)\n",
    "        write(f, \"$file\\n\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78bd7eb-de01-4dcb-affd-9dab7d57dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Upload Files with Exponential Backoff and Delete After Upload\n",
    "\n",
    "# Define a function to run the rclone copy command with retries\n",
    "function upload_file_with_retry(file, local_dir, remote_dir; retries=10, delay=10)\n",
    "    attempt = 0\n",
    "    success = false\n",
    "    \n",
    "    while attempt < retries && !success\n",
    "        try\n",
    "            run(`rclone copy $local_dir/$file $remote_dir/$file --tpslimit 10 --tpslimit-time 10s`)\n",
    "            success = true\n",
    "        catch e\n",
    "            println(\"Error uploading $file: $e. Retrying in $(delay * (2 ^ attempt)) seconds.\")\n",
    "            sleep(delay * (2 ^ attempt))\n",
    "            attempt += 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if success\n",
    "        # Delete local file\n",
    "        rm(joinpath(local_dir, file))\n",
    "    else\n",
    "        println(\"Failed to upload $file after $(retries) attempts.\")\n",
    "    end\n",
    "end\n",
    "\n",
    "# Read files to upload from the text file\n",
    "files_to_copy = readlines(\"files_to_upload.txt\")\n",
    "\n",
    "# Set local and remote directories\n",
    "local_dir = \"/path/to/your/local/directory\"\n",
    "remote_dir = \"gdrive:your_target_folder\"\n",
    "\n",
    "# Upload the files with exponential backoff and delete after upload\n",
    "for file in files_to_copy\n",
    "    upload_file_with_retry(file, local_dir, remote_dir)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5 1.10.5",
   "language": "julia",
   "name": "julia-1.10.5-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
