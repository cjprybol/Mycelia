{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ec3ac0-e197-418f-86be-f2e8a5fadb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(`conda create --channel conda-forge --channel bioconda --channel defaults --strict-channel-priority --name blast blast`)\n",
    "# run(`conda create --channel conda-forge --channel bioconda --channel defaults --strict-channel-priority --name taxonkit taxonkit`)\n",
    "# run(`conda create --channel conda-forge --channel bioconda --channel defaults --strict-channel-priority --name minimap2 minimap2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e93fe-d82c-45fa-8fee-1e86d080538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't try and install plotting libraries without this\n",
    "# can set in ~/.local/share/jupyter/kernels/\n",
    "@assert ENV[\"LD_LIBRARY_PATH\"] == \"\"\n",
    "import Pkg\n",
    "pkgs = [\n",
    "    \"Revise\",\n",
    "    \"DataFrames\",\n",
    "    \"uCSV\",\n",
    "    \"StatsPlots\",\n",
    "    \"StatsBase\",\n",
    "    \"FreqTables\",\n",
    "    \"Conda\",\n",
    "    \"ProgressMeter\",\n",
    "    \"PrettyTables\",\n",
    "    \"Distances\",\n",
    "    \"Statistics\",\n",
    "    \"Kmers\",\n",
    "    \"Colors\",\n",
    "    \"FASTX\"\n",
    "]\n",
    "# Pkg.add(pkgs)\n",
    "for pkg in pkgs\n",
    "    eval(Meta.parse(\"import $pkg\"))\n",
    "end\n",
    "import Mycelia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f41bbd-6d35-4ce4-8ce2-5cabae63433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = dirname(pwd())\n",
    "data_dir = joinpath(base_dir, \"data\")\n",
    "results_dir = joinpath(data_dir, \"results\")\n",
    "\n",
    "# load in metadata\n",
    "metadata_dir = joinpath(dirname(pwd()), \"metadata\")\n",
    "\n",
    "exposome_environmental_data = DataFrames.DataFrame(uCSV.read(\n",
    "    joinpath(metadata_dir, \"metadata_exposome.rds.tsv\"),\n",
    "    delim='\\t',\n",
    "    header=1,\n",
    "    typedetectrows=300\n",
    "))\n",
    "\n",
    "joint_sample_metadata = DataFrames.DataFrame(uCSV.read(\n",
    "    joinpath(metadata_dir, \"exposome/joint_sample_metadata.tsv\"),\n",
    "    delim='\\t',\n",
    "    header=1,\n",
    "    typedetectrows=300\n",
    "))\n",
    "\n",
    "@assert joint_sample_metadata[!, \"Library Name\"] == joint_sample_metadata[!, \"LibraryName\"]\n",
    "\n",
    "joint_metadata = DataFrames.innerjoin(\n",
    "    joint_sample_metadata,\n",
    "    exposome_environmental_data,\n",
    "    on=\"Library Name\" => \"samplenames\")\n",
    "\n",
    "sample_directories = joinpath.(data_dir, \"SRA\", joint_metadata[!, \"Run\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c59f16-14e7-49a2-af66-4ebff7900b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "viral_contigs_by_tool = Dict{String, Dict{String, Set{String}}}()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c8913-6313-494e-aa11-bd1b30208e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_genomad_results = DataFrames.DataFrame()\n",
    "# sample_directory = first(sample_directories)\n",
    "ProgressMeter.@showprogress for sample_directory in sample_directories\n",
    "    genomad_virus_summary = joinpath(sample_directory, \"genomad\", \"final.contigs.fastg.gfa_summary\", \"final.contigs.fastg.gfa_virus_summary.tsv\")\n",
    "    genomad_results = DataFrames.DataFrame(uCSV.read(genomad_virus_summary, delim='\\t', header=1, typedetectrows=100)...)\n",
    "    genomad_results[!, \"sample_id\"] .= basename(sample_directory)\n",
    "    append!(joint_genomad_results, genomad_results, promote=true)\n",
    "end\n",
    "joint_genomad_results[!, \"seq_name\"] = string.(joint_genomad_results[!, \"seq_name\"])\n",
    "joint_genomad_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5968f35-50d8-49f2-9a6c-fc356ca87a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "viral_contigs_by_tool[\"genomad\"] = Dict{String, Set{String}}()\n",
    "for gdf in DataFrames.groupby(joint_genomad_results, \"sample_id\")\n",
    "    sample_id = gdf[1, \"sample_id\"]\n",
    "    viral_contigs_by_tool[\"genomad\"][sample_id] = Set()\n",
    "    for row in DataFrames.eachrow(gdf)\n",
    "        push!(viral_contigs_by_tool[\"genomad\"][sample_id], row[\"seq_name\"])\n",
    "    end\n",
    "end\n",
    "viral_contigs_by_tool[\"genomad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609f79c-54bf-48ff-8603-4abebe5c7220",
   "metadata": {},
   "outputs": [],
   "source": [
    "blast_task = \"megablast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf44df1-e7e1-46f8-899a-883bc26e3673",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"nt_viruses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dfa381-2cfc-4f32-8c16-2937f1d4d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in metadata\n",
    "metadata_dir = joinpath(dirname(pwd()), \"metadata\")\n",
    "\n",
    "exposome_environmental_data = DataFrames.DataFrame(uCSV.read(\n",
    "    joinpath(metadata_dir, \"metadata_exposome.rds.tsv\"),\n",
    "    delim='\\t',\n",
    "    header=1,\n",
    "    typedetectrows=300\n",
    "))\n",
    "\n",
    "joint_sample_metadata = DataFrames.DataFrame(uCSV.read(\n",
    "    joinpath(metadata_dir, \"exposome/joint_sample_metadata.tsv\"),\n",
    "    delim='\\t',\n",
    "    header=1,\n",
    "    typedetectrows=300\n",
    "))\n",
    "\n",
    "@assert joint_sample_metadata[!, \"Library Name\"] == joint_sample_metadata[!, \"LibraryName\"]\n",
    "\n",
    "joint_metadata = DataFrames.innerjoin(\n",
    "    joint_sample_metadata,\n",
    "    exposome_environmental_data,\n",
    "    on=\"Library Name\" => \"samplenames\")\n",
    "\n",
    "run_ids = sort(joint_metadata[!, \"Run\"])\n",
    "\n",
    "sample_paths = joinpath.(data_dir, \"SRA\", run_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c3d47-d31f-42a9-8e8b-dc0b5c3a9f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCBI host metadata\n",
    "ncbi_metadata_file = joinpath(dirname(pwd()), \"metadata\", \"NCBI-virus-refseq.transformed.tsv\")\n",
    "ncbi_host_metadata = DataFrames.DataFrame(uCSV.read(ncbi_metadata_file, header=1, delim='\\t', encodings=Dict(\"false\" => false, \"true\" => true)))\n",
    "\n",
    "# ICTV host metadata\n",
    "ictv_metadata_file = joinpath(dirname(pwd()), \"metadata\", \"VMR_MSL38_v1 - VMR MSL38 v1.transformed.tsv\")\n",
    "ictv_host_metadata = DataFrames.DataFrame(uCSV.read(ictv_metadata_file, header=1, delim='\\t', typedetectrows=100))\n",
    "ictv_host_metadata = ictv_host_metadata[.!isempty.(ictv_host_metadata[!, \"taxid\"]), :]\n",
    "ictv_host_metadata[!, \"taxid\"] = parse.(Int, ictv_host_metadata[!, \"taxid\"])\n",
    "\n",
    "viral_tax_ids = Set(Mycelia.list_subtaxa(10239))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be83fd9-a483-4c11-ad82-e8db2cf9a8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_top_hits = DataFrames.DataFrame()\n",
    "ProgressMeter.@showprogress for sample_path in sample_paths[1:end]\n",
    "    sample = basename(sample_path)\n",
    "    blastn_directory = mkpath(joinpath(sample_path, \"blastn\"))\n",
    "    assembled_fasta = joinpath(sample_path, \"megahit\", \"final.contigs.fastg.gfa.fna\")\n",
    "    blast_file = joinpath(blastn_directory, basename(assembled_fasta) * \".blastn.$(db).$(blast_task).txt\")\n",
    "    this_blast_table = Mycelia.parse_blast_report(blast_file)\n",
    "    if isempty(this_blast_table)\n",
    "        continue\n",
    "    else\n",
    "        this_blast_table[!, \"sample_id\"] .= sample\n",
    "        # bonferonni correction on raw tests\n",
    "        this_blast_table[!, \"evalue\"] = this_blast_table[!, \"evalue\"] .* DataFrames.nrow(this_blast_table)\n",
    "        \n",
    "        # filter to top hits to avoid ballooning memory just to throw it away later\n",
    "        this_top_hits = DataFrames.DataFrame()\n",
    "        for gdf in DataFrames.groupby(this_blast_table, \"query id\")\n",
    "            push!(this_top_hits, first(sort(gdf, \"bit score\", rev=true)))\n",
    "        end\n",
    "        append!(joint_top_hits, this_top_hits)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947d37a2-1fc6-45db-b211-e9d8bb618534",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxids = unique(joint_top_hits[!, \"subject tax id\"])\n",
    "taxid2name_map = Dict(row[\"taxid\"] => row[\"tax_name\"] for row in DataFrames.eachrow(Mycelia.taxids2lineage_name_and_rank(taxids)))\n",
    "joint_top_hits[!, \"subject tax name\"] = map(taxid -> taxid2name_map[taxid], joint_top_hits[!, \"subject tax id\"])\n",
    "\n",
    "# filter to good hits even after bonferroni correction\n",
    "joint_top_hits = joint_top_hits[joint_top_hits[!, \"evalue\"] .<= 0.001, :]\n",
    "\n",
    "# filter to viral only\n",
    "viral_hits_df = joint_top_hits[map(x -> x in viral_tax_ids, joint_top_hits[!, \"subject tax id\"]), :]\n",
    "\n",
    "viral_contigs_by_tool[\"blast\"] = Dict{String, Set{String}}()\n",
    "for gdf in DataFrames.groupby(viral_hits_df, \"sample_id\")\n",
    "    sample_id = gdf[1, \"sample_id\"]\n",
    "    viral_contigs_by_tool[\"blast\"][sample_id] = Set()\n",
    "    for row in DataFrames.eachrow(gdf)\n",
    "        push!(viral_contigs_by_tool[\"blast\"][sample_id], row[\"query id\"])\n",
    "    end\n",
    "end\n",
    "viral_contigs_by_tool[\"blast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9bb32e-0cc6-40a5-ba24-e7de0648e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"UniRef50\"\n",
    "uniref50_df = DataFrames.DataFrame()\n",
    "ProgressMeter.@showprogress for sample_path in sample_paths\n",
    "    sample_id = basename(sample_path)\n",
    "    mmseqs_lca_file = joinpath(sample_path, \"mmseqs_easy_taxonomy\", \"final.contigs.fastg.gfa.fna.mmseqs_easy_taxonomy.$(db)_lca.tsv\")\n",
    "    mmseqs_lca_table = Mycelia.parse_mmseqs_easy_taxonomy_lca_tsv(mmseqs_lca_file)\n",
    "    mmseqs_lca_table[!, \"sample_id\"] .= sample_id\n",
    "    append!(uniref50_df, mmseqs_lca_table)\n",
    "end\n",
    "uniref50_df\n",
    "uniref50_viral_df = uniref50_df[map(x -> x in viral_tax_ids, uniref50_df[!, \"taxon_id\"]), :]\n",
    "\n",
    "viral_contigs_by_tool[db] = Dict{String, Set{String}}()\n",
    "for gdf in DataFrames.groupby(uniref50_viral_df, \"sample_id\")\n",
    "    sample_id = gdf[1, \"sample_id\"]\n",
    "    viral_contigs_by_tool[db][sample_id] = Set()\n",
    "    for row in DataFrames.eachrow(gdf)\n",
    "        push!(viral_contigs_by_tool[db][sample_id], string(row[\"contig_id\"]))\n",
    "    end\n",
    "end\n",
    "viral_contigs_by_tool[db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56f1ae-b363-4774-9b6c-070c626498a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"UniRef90\"\n",
    "uniref90_df = DataFrames.DataFrame()\n",
    "\n",
    "ProgressMeter.@showprogress for sample_path in sample_paths\n",
    "    sample_id = basename(sample_path)\n",
    "    mmseqs_lca_file = joinpath(sample_path, \"mmseqs_easy_taxonomy\", \"final.contigs.fastg.gfa.fna.mmseqs_easy_taxonomy.$(db)_lca.tsv\")\n",
    "    mmseqs_lca_table = Mycelia.parse_mmseqs_easy_taxonomy_lca_tsv(mmseqs_lca_file)\n",
    "    mmseqs_lca_table[!, \"sample_id\"] .= sample_id\n",
    "    append!(uniref90_df, mmseqs_lca_table)\n",
    "end\n",
    "uniref90_df\n",
    "uniref90_viral_df = uniref90_df[map(x -> x in viral_tax_ids, uniref90_df[!, \"taxon_id\"]), :]\n",
    "\n",
    "viral_contigs_by_tool[db] = Dict{String, Set{String}}()\n",
    "for gdf in DataFrames.groupby(uniref90_viral_df, \"sample_id\")\n",
    "    sample_id = gdf[1, \"sample_id\"]\n",
    "    viral_contigs_by_tool[db][sample_id] = Set()\n",
    "    for row in DataFrames.eachrow(gdf)\n",
    "        push!(viral_contigs_by_tool[db][sample_id], string(row[\"contig_id\"]))\n",
    "    end\n",
    "end\n",
    "viral_contigs_by_tool[db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddc8749-2985-4ead-bb90-7e9fdb3d999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = \"UniRef100\"\n",
    "uniref100_df = DataFrames.DataFrame()\n",
    "\n",
    "ProgressMeter.@showprogress for sample_path in sample_paths\n",
    "    sample_id = basename(sample_path)\n",
    "    mmseqs_lca_file = joinpath(sample_path, \"mmseqs_easy_taxonomy\", \"final.contigs.fastg.gfa.fna.mmseqs_easy_taxonomy.$(db)_lca.tsv\")\n",
    "    mmseqs_lca_table = Mycelia.parse_mmseqs_easy_taxonomy_lca_tsv(mmseqs_lca_file)\n",
    "    mmseqs_lca_table[!, \"sample_id\"] .= sample_id\n",
    "    append!(uniref100_df, mmseqs_lca_table)\n",
    "end\n",
    "uniref100_df\n",
    "uniref100_viral_df = uniref100_df[map(x -> x in viral_tax_ids, uniref100_df[!, \"taxon_id\"]), :]\n",
    "\n",
    "viral_contigs_by_tool[db] = Dict{String, Set{String}}()\n",
    "for gdf in DataFrames.groupby(uniref100_viral_df, \"sample_id\")\n",
    "    sample_id = gdf[1, \"sample_id\"]\n",
    "    viral_contigs_by_tool[db][sample_id] = Set()\n",
    "    for row in DataFrames.eachrow(gdf)\n",
    "        push!(viral_contigs_by_tool[db][sample_id], string(row[\"contig_id\"]))\n",
    "    end\n",
    "end\n",
    "viral_contigs_by_tool[db]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb0568-9b9a-4bea-8b32-2aa3346e5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "viral_contigs_by_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22d966-9401-4277-b36f-1a601e82ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_tools = \n",
    "[\"genomad\",\n",
    "\"blast\",\n",
    "\"UniRef50\",\n",
    "\"UniRef90\",\n",
    "\"UniRef100\"]\n",
    "\n",
    "ordered_samples = basename.(sample_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bedbe-330a-4e23-9b23-c65975292da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unanimous_hits = Dict{String, Set{String}}()\n",
    "for sample in ordered_samples\n",
    "    unanimous_hits[sample] = Set(viral_contigs_by_tool[\"genomad\"][sample])\n",
    "    for other_tool in setdiff(ordered_tools, \"genomad\")\n",
    "        # @show other_tool\n",
    "        unanimous_hits[sample] = intersect(unanimous_hits[sample], viral_contigs_by_tool[\"genomad\"][sample])\n",
    "    end\n",
    "end\n",
    "unanimous_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e5c99-5d87-4682-ac19-8e6e03fc4302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract contigs into a single fasta file\n",
    "fasta_records = []\n",
    "ProgressMeter.@showprogress for (sample_id, contig_ids) in unanimous_hits\n",
    "    sample_path = joinpath(data_dir, \"SRA\", sample_id)\n",
    "    fasta_path = joinpath(sample_path, \"megahit\", \"final.contigs.fastg.gfa.fna\")\n",
    "    open(fasta_path) do io\n",
    "        fastx_io = FASTX.FASTA.Reader(io)\n",
    "        for record in fastx_io\n",
    "            if FASTX.identifier(record) in contig_ids\n",
    "                push!(fasta_records, FASTX.FASTA.Record(sample_id * \"__\" * FASTX.identifier(record), FASTX.sequence(record)))\n",
    "            end\n",
    "        end\n",
    "        close(fastx_io)\n",
    "    end\n",
    "end\n",
    "fasta_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b927b9-cff4-4bd6-85c2-1eb9336707cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_records = sort(fasta_records, by=x->length(FASTX.sequence(x)), rev=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521f454-8d7b-4355-bfde-cb51a34231b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = StatsPlots.histogram(\n",
    "    length.(FASTX.sequence.(fasta_records)),\n",
    "    bins=100,\n",
    "    label=missing,\n",
    "    xlabel = \"contig length\",\n",
    "    ylabel = \"# of contigs\",\n",
    "    title = \"high confidence viral contigs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e1d4e7-dec2-4539-8a13-bf7eb18eaf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StatsBase.describe(length.(FASTX.sequence.(fasta_records)))\n",
    "# # long_records = filter(x -> length(FASTX.sequence(x)) >= 10000, fasta_records)\n",
    "\n",
    "# p = StatsPlots.histogram(\n",
    "#     length.(FASTX.sequence.(long_records)),\n",
    "#     bins=100,\n",
    "#     label=missing,\n",
    "#     xlabel = \"contig length\",\n",
    "#     ylabel = \"# of contigs\",\n",
    "#     title = \"high confidence viral contigs\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103d5ca-30ce-4f11-8825-b7e7a24aa507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StatsPlots.savefig(p, joinpath(results_dir, \"high-confidence-viral-contigs.fna.2k-filtered.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa45d90-2135-4995-9ea9-5621c61d0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_fasta_records = filter(x -> length(FASTX.sequence(x)) >= 2000, fasta_records)\n",
    "filtered_fasta_records = filter(x -> length(FASTX.sequence(x)) >= 5000, fasta_records)\n",
    "# filtered_fasta_records = filter(x -> length(FASTX.sequence(x)) >= 10000, fasta_records)\n",
    "high_confidence_viral_fasta = joinpath(results_dir, \"high-confidence-viral-contigs.fna\")\n",
    "open(high_confidence_viral_fasta, \"w\") do io\n",
    "    fastx_io = FASTX.FASTA.Writer(io)\n",
    "    for record in filtered_fasta_records\n",
    "        write(fastx_io, record)\n",
    "    end\n",
    "    close(fastx_io)\n",
    "end\n",
    "\n",
    "bgzipped_high_confidence_viral_fasta = high_confidence_viral_fasta * \".gz\"\n",
    "if isfile(bgzipped_high_confidence_viral_fasta)\n",
    "    rm(bgzipped_high_confidence_viral_fasta)\n",
    "end\n",
    "run(`conda run --live-stream -n samtools bgzip $(high_confidence_viral_fasta)`)\n",
    "run(`conda run --live-stream -n samtools samtools faidx $(bgzipped_high_confidence_viral_fasta)`)\n",
    "# haplotypes = 2\n",
    "haplotypes = Int(ceil(sqrt(length(filtered_fasta_records))))\n",
    "# run(`conda run --live-stream -n pggb pggb -i $(bgzipped_caudovirales_fasta) -o $(pggb_outdir) -t 4 -n $(haplotypes) -p 70 -s 100 -l 300`)\n",
    "pggb_outdir = joinpath(results_dir, \"pggb_high_confidence_viral\")\n",
    "run(`conda run --live-stream -n pggb pggb -i $(bgzipped_high_confidence_viral_fasta) -o $(pggb_outdir) -t 4 -n $(haplotypes)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deb9f81-cbb2-4e23-8600-ca88133d3bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pggb_sensitive_outdir = joinpath(results_dir, \"pggb_high_confidence_viral_sensitive\")\n",
    "# # 1/10 the default segment length\n",
    "# # 20% less stringent than default 90% identity requirement\n",
    "# run(`conda run --live-stream -n pggb pggb -i $(bgzipped_high_confidence_viral_fasta) -o $(pggb_sensitive_outdir) -t 4 -n $(haplotypes) -p 70 -s 500`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.7",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
