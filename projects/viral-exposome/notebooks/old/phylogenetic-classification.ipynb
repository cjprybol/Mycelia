{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "ictv_vmr_file = \"reference_databases:Phylogenic-Databases/ICTV/VMR/VMR_21-221122_MSL37.xlsx\"\n",
    "genome_type_regex = \"DNA\"\n",
    "host_type = \"bacteria\"\n",
    "\n",
    "# I was unable to download the entire DB in one go\n",
    "# when asked for help, NCBI recommended that we download by date range and periodically download the next batch\n",
    "# ncbi_viruses_file = \"reference_databases:NCBI/Viruses/20221018-ncbi-viruses-metadata.csv\"\n",
    "# when subsetting to bacteriophage, I was not getting a set that sufficiently overlapped with ICTV\n",
    "ncbi_viruses_directory = \"reference_databases:Phylogenic-Databases/NCBI/Viruses\"\n",
    "\n",
    "k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATE_TASK = \"2023-02-23-INFO-488-phage-phylogenetic-classification\"\n",
    "DIR = mkpath(\"$(homedir())/workspace/scratch/$DATE_TASK\")\n",
    "cd(DIR)\n",
    "TODAY, TASK = match(r\"^(\\d{4}-\\d{2}-\\d{2})-(.*)$\", DATE_TASK).captures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.update()\n",
    "pkgs = [\n",
    "    \"Revise\",\n",
    "    \"uCSV\",\n",
    "    \"DataFrames\",\n",
    "    \"StatsBase\",\n",
    "    \"ProgressMeter\",\n",
    "    \"FASTX\",\n",
    "    \"BioSequences\",\n",
    "    \"JSON\",\n",
    "    \"Kmers\",\n",
    "    \"Clustering\",\n",
    "    \"Random\",\n",
    "    # \"Arrow\"\n",
    "]\n",
    "Pkg.add(pkgs)\n",
    "for pkg in pkgs\n",
    "    eval(Meta.parse(\"import $pkg\"))\n",
    "end\n",
    "\n",
    "Pkg.develop(path=\"$(homedir())/workspace/Mycelia\")\n",
    "import Mycelia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if isdir - need to add a check here or just comment out\n",
    "# run(`rclone copy locus_google_drive:scratch/$(DATE_TASK) $(DIR)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ncbi_viruses_directory_local = mkpath(joinpath(DIR, \"ncbi-viruses\"))\n",
    "run(`rclone copy $(ncbi_viruses_directory) $(ncbi_viruses_directory_local)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "types=Dict(\n",
    "    \"Accession\" => Union{String, Missing},\n",
    "    \"SRA_Accession\" => Union{String, Missing},\n",
    "    \"Submitters\" => Union{String, Missing},\n",
    "    \"Organization\" => Union{String, Missing},\n",
    "    \"Org_location\" => Union{String, Missing},\n",
    "    \"Release_Date\" => Union{String, Missing},\n",
    "    \"Isolate\" => Union{String, Missing},\n",
    "    \"Species\" => Union{String, Missing},\n",
    "    \"Genus\" => Union{String, Missing},\n",
    "    \"Family\" => Union{String, Missing},\n",
    "    \"Molecule_type\" => Union{String, Missing},\n",
    "    \"Length\" => Union{Int, Missing},\n",
    "    \"Sequence_Type\" => Union{String, Missing},\n",
    "    \"Nuc_Completeness\" => Union{String, Missing},\n",
    "    \"Genotype\" => Union{String, Missing},\n",
    "    \"Segment\" => Union{String, Missing},\n",
    "    \"Publications\" => Union{Int, Missing},\n",
    "    \"Geo_Location\" => Union{String, Missing},\n",
    "    \"Country\" => Union{String, Missing},\n",
    "    \"USA\" => Union{String, Missing},\n",
    "    \"Host\" => Union{String, Missing},\n",
    "    \"Isolation_Source\" => Union{String, Missing},\n",
    "    \"Collection_Date\" => Union{String, Missing},\n",
    "    \"BioSample\" => Union{String, Missing},\n",
    "    \"GenBank_Title\" => Union{String, Missing}\n",
    ")\n",
    "\n",
    "ncbi_viruses_table = DataFrames.DataFrame()\n",
    "ncbi_viruses_files = filter(x -> occursin(r\"\\.ncbi-viruses\\.csv\", x), readdir(ncbi_viruses_directory_local, join=true))\n",
    "ProgressMeter.@showprogress for f in ncbi_viruses_files\n",
    "    df = DataFrames.DataFrame(uCSV.read(open(`mlr --c2t cat $(f)`), types=types, header=1, delim='\\t', encodings=Dict(\"\" => missing))...)\n",
    "    append!(ncbi_viruses_table, df, promote=true)\n",
    "end\n",
    "unique!(ncbi_viruses_table);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# acquire metadata\n",
    "ictv_vmr_file_local = joinpath(DIR, basename(ictv_vmr_file))\n",
    "if !isfile(ictv_vmr_file_local)\n",
    "    run(`rclone copy $(ictv_vmr_file) $(dirname(ictv_vmr_file_local))`)\n",
    "end\n",
    "# the two sheets are written out to the _0 and _1 files, respectively\n",
    "@assert readlines(`in2csv --names $(ictv_vmr_file_local)`) == [\"VMRb37\", \"Column definitions\"]\n",
    "run(pipeline(`in2csv --write-sheets - $(ictv_vmr_file_local)`, devnull))\n",
    "ictv_vmr_table = DataFrames.DataFrame(uCSV.read(replace(ictv_vmr_file_local, \".xlsx\" => \"_0.csv\"), header=1, quotes='\"')...)\n",
    "# some have multiple equivalent genome submissions, only take first\n",
    "ictv_vmr_table[!, \"Virus GENBANK accession\"] = string.(first.(split.(ictv_vmr_table[!, \"Virus GENBANK accession\"], ';')));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# join ICTV & NCBI\n",
    "conflict_columns = intersect(names(ictv_vmr_table), names(ncbi_viruses_table))\n",
    "DataFrames.rename!(ictv_vmr_table, [column => column * \"_ICTV\" for column in conflict_columns])\n",
    "DataFrames.rename!(ncbi_viruses_table, [column => column * \"_NCBI\" for column in conflict_columns])\n",
    "\n",
    "# 3707\n",
    "joint_metadata_table = DataFrames.innerjoin(ictv_vmr_table, ncbi_viruses_table, on = \"Virus GENBANK accession\" => \"Accession\")\n",
    "# 3720\n",
    "# joint_metadata_table = DataFrames.leftjoin(ictv_vmr_table, ncbi_viruses_table, on = \"Virus GENBANK accession\" => \"Accession\")\n",
    "joint_metadata_table = DataFrames.rename!(joint_metadata_table, \"Virus GENBANK accession\" => \"Accession\")\n",
    "\n",
    "# clear the prior tables from memory\n",
    "ncbi_viruses_table = ictv_vmr_table = nothing\n",
    "GC.gc()\n",
    "\n",
    "# filter down to phage with DNA genomes since we don't work with RNA phage\n",
    "is_right_host = joint_metadata_table[!, \"Host source\"] .== \"bacteria\"\n",
    "is_right_genome_type = map(x -> occursin(Regex(genome_type_regex), x), joint_metadata_table[!, \"Genome composition\"])\n",
    "has_genbank_accession = map(x -> !isempty(x), joint_metadata_table[!, \"Accession\"])\n",
    "filter_mask = is_right_host .& is_right_genome_type .& has_genbank_accession\n",
    "joint_metadata_table = joint_metadata_table[filter_mask, :]\n",
    "sort!(joint_metadata_table, \"Accession\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fasta_directory = mkpath(joinpath(DIR, \"reference-fastas\"))\n",
    "reference_fastas = String[]\n",
    "ProgressMeter.@showprogress for accession in joint_metadata_table[!, \"Accession\"]\n",
    "    fastx_file = joinpath(fasta_directory, accession * \".fna\")\n",
    "    if !isfile(fastx_file) || (filesize(fastx_file) == 0)\n",
    "        try\n",
    "            fastx_records = collect(Mycelia.get_sequence(db=\"nuccore\", accession=accession))\n",
    "            if isempty(fastx_records)\n",
    "                @info \"trying again\"\n",
    "                fastx_records = collect(Mycelia.get_sequence(db=\"nuccore\", accession=accession))\n",
    "            end\n",
    "            @assert !isempty(fastx_records)\n",
    "            open(fastx_file, \"w\") do io\n",
    "                fastx_io = FASTX.FASTA.Writer(io)\n",
    "                for record in fastx_records\n",
    "                    write(fastx_io, record)\n",
    "                end\n",
    "                close(fastx_io)\n",
    "            end\n",
    "        catch e\n",
    "            display(e)\n",
    "        end\n",
    "    end\n",
    "    if isfile(fastx_file) && (filesize(fastx_file) != 0)\n",
    "        push!(reference_fastas, fastx_file)\n",
    "    end\n",
    "end\n",
    "\n",
    "reference_list = joinpath(DIR, \"reference_list.txt\")\n",
    "open(reference_list, \"w\") do io\n",
    "    for x in reference_fastas\n",
    "        println(io, x)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pull in Benchling file\n",
    "@time benchling_sequences_json = [JSON.parse(line) for line in eachline(benchling_dna_sequences_jsonl_local)];\n",
    "\n",
    "@time benchling_sequences_json = filter!(x -> \n",
    "    (x[\"registryId\"] != nothing) && # should be registered\n",
    "    (x[\"schema\"][\"name\"] in keys(benchling_schema_of_interest)) && # should be in schema of interest\n",
    "    (!isempty(x[\"bases\"])) # should have bases\n",
    "    , benchling_sequences_json)\n",
    "\n",
    "# we checked against the keys, so let's confirm that the schema values match too\n",
    "@assert all(x -> x[\"schema\"][\"id\"] in values(benchling_schema_of_interest), benchling_sequences_json)\n",
    "\n",
    "function benchling_json_to_fasta(json_record)\n",
    "    identifier = json_record[\"entityRegistryId\"]\n",
    "    description = json_record[\"name\"]\n",
    "    sequence = json_record[\"bases\"]\n",
    "    return FASTX.FASTA.Record(identifier, description, sequence)\n",
    "end\n",
    "\n",
    "locus_records = benchling_json_to_fasta.(benchling_sequences_json)\n",
    "sort!(locus_records, by=x->FASTX.identifier(x))\n",
    "\n",
    "query_fastas_dir = mkpath(joinpath(DIR, \"query-fastas\"))\n",
    "locus_fasta_files = String[]\n",
    "for locus_record in locus_records\n",
    "    locus_record_identifier = FASTX.identifier(locus_record)\n",
    "    fastx_file = joinpath(query_fastas_dir, locus_record_identifier * \".fna\")\n",
    "    open(fastx_file, \"w\") do io\n",
    "        fastx_io = FASTX.FASTA.Writer(io)\n",
    "        write(fastx_io, locus_record)\n",
    "        close(fastx_io)\n",
    "    end\n",
    "    push!(locus_fasta_files, fastx_file)\n",
    "end\n",
    "\n",
    "query_list = joinpath(DIR, \"query_list.txt\")\n",
    "open(query_list, \"w\") do io\n",
    "    for f in locus_fasta_files\n",
    "        println(io, f)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE, THIS SHOULD BE THE TIE-IN POINT FOR A COMMAND LINE CALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fasta_ani_outfile = joinpath(DIR, \"fastani.txt\")\n",
    "# 7 min\n",
    "Mycelia.fastani(query_list=query_list, reference_list=reference_list, outfile=fasta_ani_outfile)\n",
    "ani_table = Mycelia.read_fastani(fasta_ani_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani_top_hits = DataFrames.DataFrame()\n",
    "for g in DataFrames.groupby(ani_table, \"identifier\")\n",
    "    push!(ani_top_hits, sort(g, \"% identity\", rev=true)[1, :])\n",
    "end\n",
    "ani_top_hits[!, \"identifier\"] = map(x -> replace(basename(x), \".fna\" => \"\"), ani_top_hits[!, \"identifier\"])\n",
    "ani_top_hits[!, \"closest_reference\"] = map(x -> replace(basename(x), \".fna\" => \"\"), ani_top_hits[!, \"closest_reference\"])\n",
    "ani_top_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# determine kmer saturation rate of reference genomes\n",
    "# Mycelia.assess_dnamer_saturation(readdir(fasta_directory, join=true))\n",
    "# don't hit predicted saturation until k=29 which is way too high\n",
    "# just use 7, 8192 is plenty of features for classification. Could probably even get away with 5 but we've been using 7 historically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_records = FASTX.FASTA.Record[]\n",
    "for (i, reference_fasta) in enumerate(reference_fastas)\n",
    "    records = collect(Mycelia.open_fastx(reference_fasta))\n",
    "    if length(records) != 1\n",
    "        @show reference_fasta\n",
    "        @show i\n",
    "        display(records)\n",
    "    else\n",
    "        record = first(records)\n",
    "        push!(reference_records, record)\n",
    "    end\n",
    "end\n",
    "reference_records\n",
    "unique!(reference_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joint_reference_sequences_file = joinpath(DIR, \"joint-reference-sequences.fna\")\n",
    "open(joint_reference_sequences_file, \"w\") do io\n",
    "    fastx_writer = FASTX.FASTA.Writer(io)\n",
    "    for record in reference_records\n",
    "        write(fastx_writer, record)\n",
    "    end\n",
    "    close(fastx_writer)\n",
    "end\n",
    "\n",
    "run(`makeblastdb -parse_seqids -dbtype nucl -in $(joint_reference_sequences_file) -out $(joint_reference_sequences_file)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joint_query_sequences_file = joinpath(DIR, \"joint-query-sequences.fna\")\n",
    "\n",
    "open(joint_query_sequences_file, \"w\") do io\n",
    "    fastx_writer = FASTX.FASTA.Writer(io)\n",
    "    for record in locus_records\n",
    "        write(fastx_writer, record)\n",
    "    end\n",
    "    close(fastx_writer)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3 min\n",
    "blast_report = Mycelia.run_blast(out_dir = DIR, fasta = joint_query_sequences_file, blast_db = joint_reference_sequences_file, blast_command = \"blastn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blast_hits = Mycelia.parse_blast_report(blast_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # take only the best hit for each\n",
    "blast_top_hits = DataFrames.DataFrame()\n",
    "for g in DataFrames.groupby(blast_hits, \"query id\")\n",
    "    sorted_g = sort!(g, [\"bit score\", \"% identity\"], rev=true)\n",
    "    top_hit = sorted_g[1, :]\n",
    "    push!(blast_top_hits, top_hit)\n",
    "end\n",
    "blast_top_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, here is where we would read back in locus records from fastas but we already have them in memory from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_records = vcat(reference_records, locus_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_record_range = 1:length(reference_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "locus_record_range = length(reference_records)+1:length(joint_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert issorted(joint_metadata_table[!, \"Accession\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's make an index map for fast association\n",
    "accession_index_map = Dict(accession => i for (i, accession) in enumerate(joint_metadata_table[!, \"Accession\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts_matrix, counts_matrix_file = Mycelia.fasta_list_to_counts_table(fasta_list=joint_records, k=k, alphabet=:DNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "closest_match_table = DataFrames.DataFrame(\n",
    "    identifier = String[],\n",
    "    name = String[],\n",
    "    distance_metric = String[],\n",
    "    closest_reference = String[],\n",
    "    distance = Float64[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# euclidiean_distance_matrix\n",
    "# consider writing me out, looks like I'll take 10 minutes for Endeavor reference phage 2022-10-21 (420 phage)\n",
    "# consider writing me out, looks like I'll take 12 minutes for all reference phage 2022-10-21 (1400 phage)\n",
    "@time euclidean_distance_matrix = Mycelia.frequency_matrix_to_euclidean_distance_matrix(counts_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distance_matrix = euclidean_distance_matrix\n",
    "distance_metric = \"euclidean\"\n",
    "\n",
    "for locus_record_index in locus_record_range\n",
    "    locus_record = joint_records[locus_record_index]\n",
    "    value, index = findmin(distance_matrix[reference_record_range, locus_record_index])\n",
    "    record_identifier = FASTX.identifier(reference_records[index])\n",
    "    unversioned_record_identifier = first(split(record_identifier, '.'))\n",
    "    row = (\n",
    "        identifier = FASTX.identifier(locus_record),\n",
    "        name = FASTX.description(locus_record),\n",
    "        distance_metric = distance_metric,\n",
    "        closest_reference = unversioned_record_identifier,\n",
    "        distance = value\n",
    "    )\n",
    "    push!(closest_match_table, row)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13 minutes for 5k phage\n",
    "@time cosine_distance_matrix = Mycelia.frequency_matrix_to_cosine_distance_matrix(counts_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "distance_matrix = cosine_distance_matrix\n",
    "distance_metric = \"cosine\"\n",
    "\n",
    "for locus_record_index in locus_record_range\n",
    "    locus_record = joint_records[locus_record_index]\n",
    "    value, index = findmin(distance_matrix[reference_record_range, locus_record_index])\n",
    "    record_identifier = FASTX.identifier(reference_records[index])\n",
    "    unversioned_record_identifier = first(split(record_identifier, '.'))\n",
    "    row = (\n",
    "        identifier = FASTX.identifier(locus_record),\n",
    "        name = FASTX.description(locus_record),\n",
    "        distance_metric = distance_metric,\n",
    "        closest_reference = unversioned_record_identifier,\n",
    "        distance = value\n",
    "    )\n",
    "    push!(closest_match_table, row)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_match_table[!, \"% identity\"] = \n",
    "map(row -> \n",
    "    occursin(r\"cosine\"i, row[\"distance_metric\"]) ? \n",
    "    (1 - row[\"distance\"]) * 100 : \n",
    "    missing,\n",
    "    collect(DataFrames.eachrow(closest_match_table)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ani_top_hits[!, \"distance_metric\"] .= \"fastANI\"\n",
    "\n",
    "blast_top_hits[!, \"distance_metric\"] .= \"blast\"\n",
    "\n",
    "blast_top_hits = DataFrames.rename!(\n",
    "    blast_top_hits,\n",
    "    [\"query id\" => \"identifier\",\n",
    "    \"subject id\" => \"closest_reference\"]\n",
    ")\n",
    "\n",
    "blast_top_hits[!, \"closest_reference\"] = map(x -> string(first(split(x, '.'))), blast_top_hits[!, \"closest_reference\"])\n",
    "\n",
    "joint_top_hits_table = vcat(\n",
    "    ani_top_hits[!, [\"identifier\", \"closest_reference\", \"% identity\", \"distance_metric\"]],\n",
    "    blast_top_hits[!, [\"identifier\", \"closest_reference\", \"% identity\", \"distance_metric\"]])\n",
    "\n",
    "joint_top_hits_table[!, \"distance\"] = map(x -> (100 - x) / 100, joint_top_hits_table[!, \"% identity\"])\n",
    "\n",
    "locus_id_to_name_map = Dict(FASTX.identifier(x) => FASTX.description(x) for x in locus_records)\n",
    "joint_top_hits_table[!, \"name\"] = map(x -> locus_id_to_name_map[x], joint_top_hits_table[!, \"identifier\"])\n",
    "\n",
    "joint_match_table = vcat(closest_match_table, joint_top_hits_table)\n",
    "\n",
    "# merge joint lineage table with joint metadata data & write out to disk\n",
    "joint_lineage_table = DataFrames.innerjoin(joint_match_table, joint_metadata_table, on=:closest_reference => :Accession)\n",
    "\n",
    "sort!(joint_lineage_table, \"identifier\")\n",
    "\n",
    "for col in names(joint_lineage_table)\n",
    "    joint_lineage_table[!, col] = map(x -> ismissing(x) ? \"\" : string(x), joint_lineage_table[!, col])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phylogenetic_classifications_table_file = joinpath(DIR, \"$(TODAY)-phage-phylogenetic-classifications.tsv\")\n",
    "uCSV.write(phylogenetic_classifications_table_file, joint_lineage_table, delim='\\t')\n",
    "# uCSV.write(joinpath(DIR, \"$(TODAY)-phage-phylogenetic-classifications.csv\"), joint_lineage_table, quotes='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# looks like Species ICTV has duplicates, so just take the first\n",
    "# for g in DataFrames.groupby(joint_lineage_table[joint_lineage_table[!, \"distance_metric\"] .== \"euclidean\", :], \"identifier\")\n",
    "#     if DataFrames.nrow(g) > 1\n",
    "#         display(g)\n",
    "#     end\n",
    "# end\n",
    "\n",
    "euclidean_joint_lineage_table = DataFrames.DataFrame()\n",
    "for g in DataFrames.groupby(joint_lineage_table[joint_lineage_table[!, \"distance_metric\"] .== \"euclidean\", :], \"identifier\")\n",
    "    push!(euclidean_joint_lineage_table, g[1, :])\n",
    "end\n",
    "@assert issorted(euclidean_joint_lineage_table[!, \"identifier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@assert all(euclidean_joint_lineage_table[!, \"identifier\"] .== FASTX.identifier.(locus_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "euclidean_distance_matrix_subset = euclidean_distance_matrix[locus_record_range, locus_record_range]\n",
    "# UPGMA\n",
    "# can also do linkage = single\n",
    "@time hclust_result = Clustering.hclust(euclidean_distance_matrix_subset, linkage=:average, branchorder=:optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@assert hclust_result.heights == hclust_result.height\n",
    "\n",
    "@assert hclust_result.merge == hclust_result.merges\n",
    "\n",
    "@assert hclust_result.method == hclust_result.linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "node_labels = [replace(join([row[\"identifier\"], row[\"name\"], row[\"Genus_ICTV\"]], \"__\"), \" \" => \"_\") for row in DataFrames.eachrow(euclidean_joint_lineage_table)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newick = Dict()\n",
    "for row in 1:size(hclust_result.merges, 1)\n",
    "    left, right = hclust_result.merges[row, :]\n",
    "    if left < 0\n",
    "        phage_name = node_labels[abs(left)]\n",
    "        l = \"$phage_name\"\n",
    "    else\n",
    "        l = newick[left]\n",
    "    end\n",
    "    if right < 0\n",
    "        phage_name = node_labels[abs(right)]\n",
    "        r = \"$phage_name\"\n",
    "    else\n",
    "        r = newick[right]\n",
    "    end\n",
    "    height = hclust_result.heights[row]\n",
    "    newick[row] = \"($l:$height, $r:$height)\"\n",
    "end\n",
    "\n",
    "newick_file = \"$DIR/$(TODAY)-reference-phage.newick\"\n",
    "open(newick_file, \"w\") do io\n",
    "    println(io, newick[size(hclust_result.merges, 1)] * \";\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run(`rclone lsf locus_genomics_storefront:Phylogenies`)\n",
    "# copy results to the storefront under phylogenies\n",
    "run(`rclone copy $(newick_file) locus_genomics_storefront:Phylogenies`)\n",
    "run(`rclone copy $(phylogenetic_classifications_table_file) locus_genomics_storefront:Phylogenies`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all nearly identical by blast, cosine distance, fastANI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blastn has lots of multi-map hits that I'm not sure how to handle immediately, so skipping for now\n",
    "# redo the blast steps above but reciprocal blast of internal phage\n",
    "\n",
    "run(`makeblastdb -parse_seqids -dbtype nucl -in $(joint_query_sequences_file) -out $(joint_query_sequences_file)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3 min\n",
    "reciprocal_blast_report = Mycelia.run_blast(out_dir = DIR, fasta = joint_query_sequences_file, blast_db = joint_query_sequences_file, blast_command = \"blastn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reciprocal_blast_hits = Mycelia.parse_blast_report(reciprocal_blast_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # take only the best hit for each PAIR\n",
    "reciprocal_blast_top_hits = DataFrames.DataFrame()\n",
    "for g in DataFrames.groupby(reciprocal_blast_hits, [\"query id\", \"subject id\"])\n",
    "    sorted_g = sort!(g, [\"bit score\", \"% identity\"], rev=true)\n",
    "    top_hit = sorted_g[1, :]\n",
    "    push!(reciprocal_blast_top_hits, top_hit)\n",
    "end\n",
    "reciprocal_blast_top_hits\n",
    "\n",
    "locus_id_to_name_map = Dict(FASTX.identifier(x) => FASTX.description(x) for x in locus_records)\n",
    "\n",
    "DataFrames.rename!(reciprocal_blast_top_hits,\n",
    "    [\"query id\" => \"query_identifier\",\n",
    "     \"subject id\" => \"reference_identifier\",\n",
    "     \"subject title\" => \"reference_name\",\n",
    "     \"% identity\" => \"%_identity\"])\n",
    "\n",
    "reciprocal_blast_top_hits[!, \"query_name\"] = map(x -> locus_id_to_name_map[x], reciprocal_blast_top_hits[!, \"query_identifier\"])    \n",
    "reciprocal_blast_top_hits[!, \"distance_metric\"] .= \"blast\"\n",
    "reciprocal_blast_top_hits[!, \"distance\"] = map(x -> 100 - x, reciprocal_blast_top_hits[!, \"%_identity\"])\n",
    "reciprocal_blast_top_hits = reciprocal_blast_top_hits[!, [\"query_identifier\", \"reference_identifier\", \"distance_metric\", \"%_identity\", \"query_name\", \"reference_name\", \"distance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# redo the ani steps but reciprocal blast of internal phage\n",
    "reciprocal_fasta_ani_outfile = joinpath(DIR, \"reciprocal-fastani.txt\")\n",
    "Mycelia.fastani(query_list=query_list, reference_list=query_list, outfile=reciprocal_fasta_ani_outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reciprocal_ani_table = Mycelia.read_fastani(reciprocal_fasta_ani_outfile)\n",
    "\n",
    "# only take the first example of each pair, since there should be reciprocal matches\n",
    "# reciprocal_ani_table = reciprocal_ani_table[reciprocal_ani_table[!, \"query identifier\"] .< reciprocal_ani_table[!, \"reference identifier\"], :]\n",
    "reciprocal_ani_table[!, \"query_identifier\"] = map(x -> replace(basename(x), \".fna\" => \"\"), reciprocal_ani_table[!, \"query_identifier\"])\n",
    "reciprocal_ani_table[!, \"reference_identifier\"] = map(x -> replace(basename(x), \".fna\" => \"\"), reciprocal_ani_table[!, \"reference_identifier\"])\n",
    "sort!(reciprocal_ani_table);\n",
    "\n",
    "reciprocal_ani_table[!, \"distance_metric\"] .= \"fastANI\"\n",
    "reciprocal_ani_table = reciprocal_ani_table[!, [\"query_identifier\", \"reference_identifier\", \"distance_metric\", \"%_identity\"]]\n",
    "\n",
    "\n",
    "reciprocal_ani_table[!, \"query_name\"] = map(x -> locus_id_to_name_map[x], reciprocal_ani_table[!, \"query_identifier\"])\n",
    "reciprocal_ani_table[!, \"reference_name\"] = map(x -> locus_id_to_name_map[x], reciprocal_ani_table[!, \"reference_identifier\"])\n",
    "reciprocal_ani_table[!, \"distance\"] = map(x -> 100 - x, reciprocal_ani_table[!, \"%_identity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cosine_distance_table = DataFrames.DataFrame()\n",
    "\n",
    "for i1 in locus_record_range\n",
    "    record_1 = joint_records[i1]\n",
    "    for i2 in locus_record_range\n",
    "        record_2 = joint_records[i2]\n",
    "        record_identifier = \n",
    "        row = (\n",
    "            query_identifier = FASTX.identifier(record_1),\n",
    "            query_name = FASTX.description(record_1),\n",
    "            reference_identifier = FASTX.identifier(record_2),\n",
    "            reference_name = FASTX.description(record_2),\n",
    "            distance_metric = \"cosine\",\n",
    "            distance = cosine_distance_matrix[i1, i2]\n",
    "        )\n",
    "        push!(cosine_distance_table, row)\n",
    "    end\n",
    "end\n",
    "cosine_distance_table[!, \"%_identity\"] = map(x -> ((1 - x) * 100), cosine_distance_table[!, \"distance\"])\n",
    "cosine_distance_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phage_similarity_table = vcat(cosine_distance_table, reciprocal_ani_table, reciprocal_blast_top_hits)\n",
    "sort!(phage_similarity_table, [\"query_identifier\", \"reference_identifier\", \"distance_metric\"])\n",
    "phage_similarity_table = phage_similarity_table[phage_similarity_table[!, \"query_identifier\"] .!= phage_similarity_table[!, \"reference_identifier\"], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# includes the p00jc & 7225 similarity that the team was frustrated by\n",
    "# # /home/jovyan/workspace/scratch/2022-11-22-INFO-488-phylogenetic-classification-benchling-upload/query-fastas/rPHAGE000150.fna\n",
    "# # /home/jovyan/workspace/scratch/2022-11-22-INFO-488-phylogenetic-classification-benchling-upload/query-fastas/rPHAGE007225.fna\n",
    "# # 99.9983\n",
    "# reciprocal_ani_table[findall(x -> occursin(\"rPHAGE000150\", x), reciprocal_ani_table[!, \"identifier\"]), :]\n",
    "\n",
    "# reciprocal_ani_table[reciprocal_ani_table[!, \"% identity\"] .>= 99.99, :]\n",
    "\n",
    "# phage_similarity_table = phage_similarity_table[phage_similarity_table[!, \"% identity\"] .>= 99.99, :]\n",
    "# 95% identity is the batch release cutoff, so set that as the minimum hard filter and then we can increase filtering stringency later\n",
    "phage_similarity_table = phage_similarity_table[phage_similarity_table[!, \"%_identity\"] .>= 95, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# only take groups where all 3 metrics hit the threshold\n",
    "num_distance_metrics = length(unique(phage_similarity_table[!, \"distance_metric\"]))\n",
    "phage_similarity_table_subset = DataFrames.DataFrame()\n",
    "for g in DataFrames.groupby(phage_similarity_table, [\"query_identifier\", \"reference_identifier\"])\n",
    "    if DataFrames.nrow(g) == num_distance_metrics\n",
    "        for row in DataFrames.eachrow(g)\n",
    "            push!(phage_similarity_table_subset, row)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "phage_similarity_table_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phage_similarity_table_subset_file = joinpath(DIR, \"$(TODAY)-highly-similar-reference-phage.tsv\")\n",
    "uCSV.write(phage_similarity_table_subset_file, phage_similarity_table_subset, delim='\\t')\n",
    "run(`rclone copy $(phage_similarity_table_subset_file) locus_genomics_storefront:Phylogenies`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# phage_to_archive = sort(unique(phage_similarity_table_subset[!, [\"reference_identifier\", \"reference_name\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# phage_to_archive_file = joinpath(DIR, \"$(TODAY)-phage-to-archive.tsv\")\n",
    "# uCSV.write(phage_to_archive_file, phage_to_archive, delim='\\t')\n",
    "# run(`rclone copy $(phage_to_archive_file) locus_genomics_storefront:Phylogenies`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each entity, if we have uniform agreement on ID, upload the genus and species information to Benchling for that reference phage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO write classifications to Benchling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO flag redundant phage in benchling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(`rclone copy $(DIR) locus_google_drive:scratch/$(DATE_TASK)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run(`rclone copy $(DIR) locus_google_drive:scratch/$(DATE_TASK)`)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "e1c5def0-417c-492c-9f95-7ebb02ff6f77",
   "lastKernelId": "2e8da3ed-de43-45b2-883e-263efa7d5229"
  },
  "kernelspec": {
   "display_name": "Julia 1.6.7",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
